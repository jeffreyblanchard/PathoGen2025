---
title: "Learning R with Generative AI in a Metagenomic Data Science Course - Survey Results"
#date: "`r format(Sys.time(), '%d %B, %Y')`"
#author:
#  - name: Jeffrey L Blanchard
#    orcid: 0000-0002-7310-9678
#    email: jlb@umass.edu
#    affiliation: 
#      - name: University of Massachusetts Amherst
#        city: Amherst
#        state: MA
#        url: https://jeffreyblanchard.github.io/lab/
#format:
#  pdf:
#    toc: true
#    number-sections: true
#    colorlinks: true
#execute:
#  echo: false
---

```{r}
library(tidyverse) 
library(janitor)
library(scales)
library(patchwork)   
library(sessioninfo)
library(knitr) # this is needed for rendering
```
### Overview

These graphs, tables and open responses are from an anonymous Google forms survey that was designed to solicit students’ personal experience on the effectiveness of using generative AI in this course. The resulting [csv file](https://github.com/jeffreyblanchard/PathoGen2025/tree/main/survey/bio478_survey_responses.csv) with the survey results is in the course GitHub repository. These results are generated from this csv file and the underlying R code can also be found in the above GitHub repo and are rendered on this [survey page](https://jeffreyblanchard.github.io/PathoGen2025/survey.html). The R code for producing many of these graphs was developed interactively using the [UMass Amherst GenAI platform](https://www.umass.edu/it/genai/platform).

### Prior Coding Experience 

```{r single-stacked-color-palette}
# 5 color likert palette for single stacked bar plots
cols5 <- c("#d73027","#fc8d59","#fee090","#91bfdb","#1a9850")
```


```{r single-stacked-read-clean}
# Read CSV for single stacked bar plots
df_survey <- readr::read_csv("survey/bio478_survey_responses.csv") |>
  clean_names() 
```

```{r prior_coding_experience}
#| fig-height: 2 
#| fig-width: 10

experience_levels = c(
"Extensive (multiple courses or projects)",
"Moderate (regular use in another language)",
"Some (one course or self-study)",
"Very limited (a few tutorials or labs)",
"None"
)

df_survey |>
  count(prior_coding_experience, name = "n") |>
  complete(prior_coding_experience = experience_levels, fill = list(n = 0)) |>
  mutate(prior_coding_experience = factor(prior_coding_experience, levels = experience_levels)) |>
  mutate(pct = n / sum(n)) |>

ggplot(aes(x = 1, y = n, fill = prior_coding_experience)) +
  geom_col(position = "fill") +          
  scale_fill_manual(values = cols5) +
  coord_flip() +                                                    
  scale_y_continuous(labels = percent_format(accuracy = 1),
                     expand = expansion(mult = c(0, 0.05))) +
  labs(title = "Prior coding experience",
       x = NULL, y = "Percentage of respondents", fill = NULL) +
  theme_minimal(base_size = 12) +
  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major.y = element_blank())
```

### Frequency of AI Use

```{r frequency_of_ai_use}
#| fig-height: 2 
#| fig-width: 10

experience_levels <- c(
"I did not use AI",
"I tried it once or twice",
"About once per week",
"A few times per week",
"Daily"
)

df_survey |>
  count(frequency_of_ai_use_in_this_course, name = "n") |>
  complete(frequency_of_ai_use_in_this_course = experience_levels, fill = list(n = 0))  |>
  mutate(frequency_of_ai_use_in_this_course = factor(frequency_of_ai_use_in_this_course, levels = experience_levels))  |>
  mutate(pct = n / sum(n)) |>

ggplot(aes(x = 1, y = n, fill = frequency_of_ai_use_in_this_course)) +
  geom_col(position = "fill") +          
  scale_fill_manual(values = cols5) +
  coord_flip() +                                                   
  scale_y_continuous(labels = percent_format(accuracy = 1),
                     expand = expansion(mult = c(0, 0.05))) +
  labs(title = "Frequency of AI Use",
       x = NULL, y = "Percentage of respondents", fill = NULL) +
  theme_minimal(base_size = 12) +
  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major.y = element_blank())
```

### How much time did using AI save me?

```{r}
#| fig-height: 2 
#| fig-width: 10

experience_levels <- c(
"< 0.5 hr total",
"0.5-1 hrs",
"1-2 hrs",
"2-3 hrs",
"3+ hrs"
)

df_survey |>
  count(how_much_time_did_using_ai_save_me, name = "n") |>
  complete(how_much_time_did_using_ai_save_me = experience_levels, fill = list(n = 0))  |>
  mutate(how_much_time_did_using_ai_save_me = factor(how_much_time_did_using_ai_save_me, levels = experience_levels))  |>
  mutate(pct = n / sum(n)) |>

ggplot(aes(x = 1, y = n, fill = how_much_time_did_using_ai_save_me)) +
  geom_col(position = "fill") +          
  scale_fill_manual(values = cols5) +
# stacked to 100%
  coord_flip() +                                                     # horizontal bar
  scale_y_continuous(labels = percent_format(accuracy = 1),
                     expand = expansion(mult = c(0, 0.05))) +
  labs(title = "How much time did using AI save me?",
       x = NULL, y = "Percentage of respondents", fill = NULL) +
  theme_minimal(base_size = 12) +
  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major.y = element_blank())
```

### Frequency of incorrect AI output

```{r}
#| fig-height: 2
#| fig-width: 10

experience_levels <- c(
"Never",
"Rarely",
"Sometimes",
"Often",
"Very Often"
)

df_survey |>
  count(frequency_of_incorrect_ai_output, name = "n") |>
  complete(frequency_of_incorrect_ai_output = experience_levels, fill = list(n = 0))  |>
  mutate(frequency_of_incorrect_ai_output = factor(frequency_of_incorrect_ai_output, levels = experience_levels))  |>
mutate(pct = n / sum(n)) |>

ggplot(aes(x = 1, y = n, fill = frequency_of_incorrect_ai_output)) +
  geom_col(position = "fill") +          
  scale_fill_manual(values = cols5) +
# stacked to 100%
  coord_flip() +                                                     # horizontal bar
  scale_y_continuous(labels = percent_format(accuracy = 1),
                     expand = expansion(mult = c(0, 0.05))) +
  labs(title = "Frequency of incorrect AI output",
       x = NULL, y = "Percentage of respondents", fill = NULL) +
  theme_minimal(base_size = 12) +
  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major.y = element_blank())

```

### Did you become more engaged or interactive in solving problems using AI?

```{r}
#| fig-height: 2 
#| fig-width: 10

experience_levels <- c(
"Much less engaged",
"Slightly less engaged",
"No change",
"Slightly more engaged",
"Much more engaged"
)

df_survey |>
  count(did_you_become_more_engaged_or_interactive_in_solving_problems_using_ai, name = "n") |>
  complete(did_you_become_more_engaged_or_interactive_in_solving_problems_using_ai = experience_levels, fill = list(n = 0))  |>
  mutate(did_you_become_more_engaged_or_interactive_in_solving_problems_using_ai = factor(did_you_become_more_engaged_or_interactive_in_solving_problems_using_ai, levels = experience_levels))  |>
mutate(pct = n / sum(n)) |>

  ggplot(aes(x = 1, y = n, fill = did_you_become_more_engaged_or_interactive_in_solving_problems_using_ai)) +
  geom_col(position = "fill") +          
  scale_fill_manual(values = cols5) +
# stacked to 100%
  coord_flip() +                                                     # horizontal bar
  scale_y_continuous(labels = percent_format(accuracy = 1),
                     expand = expansion(mult = c(0, 0.05))) +
  labs(title = "Did you become more engaged or interactive in solving problems using AI?",
       x = NULL, y = "Percentage of respondents", fill = NULL) +
  theme_minimal(base_size = 12) +
  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major.y = element_blank())

```

###  Confidence change in programming in R 

```{r}
#| fig-height: 2 
#| fig-width: 10

experience_levels <- c(
"Much lower",
"Lower",
"About the same",
"Higher",
"Much higher"
)

df_survey |>
  count(confidence_change_in_programming_in_r, name = "n") |>
  complete(confidence_change_in_programming_in_r = experience_levels, fill = list(n = 0))  |>
  mutate(confidence_change_in_programming_in_r = factor(confidence_change_in_programming_in_r, levels = experience_levels))  |>
mutate(pct = n / sum(n)) |>

  ggplot(aes(x = 1, y = n, fill = confidence_change_in_programming_in_r)) +
  geom_col(position = "fill") +          
  scale_fill_manual(values = cols5) +
# stacked to 100%
  coord_flip() +                                                     # horizontal bar
  scale_y_continuous(labels = percent_format(accuracy = 1),
                     expand = expansion(mult = c(0, 0.05))) +
  labs(title = "Confidence change in programming in R",
       x = NULL, y = "Percentage of respondents", fill = NULL) +
  theme_minimal(base_size = 12) +
  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major.y = element_blank())
  
```

###  Clarity of instructions on AI use

```{r}
#| fig-height: 2
#| fig-width: 10

experience_levels <- c(
"Very unclear",
"Unclear",
"Neutral",
"Clear",
"Very clear"
)

df_survey |>
  count(clarity_of_instructions_on_ai_use, name = "n") |>
  complete(clarity_of_instructions_on_ai_use = experience_levels, fill = list(n = 0))  |>
  mutate(clarity_of_instructions_on_ai_use = factor(clarity_of_instructions_on_ai_use, levels = experience_levels))  |>
mutate(pct = n / sum(n)) |>

    ggplot(aes(x = 1, y = n, fill = clarity_of_instructions_on_ai_use)) +
  geom_col(position = "fill") +          
  scale_fill_manual(values = cols5) +
# stacked to 100%
  coord_flip() +                                                     # horizontal bar
  scale_y_continuous(labels = percent_format(accuracy = 1),
                     expand = expansion(mult = c(0, 0.05))) +
  labs(title = "Clarity of instructions on AI use",
       x = NULL, y = "Percentage of respondents", fill = NULL) +
  theme_minimal(base_size = 12) +
  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major.y = element_blank())
```

### Combined likert graph of multiple choice grids

```{r combined-likert-read-org}
# Read CSV
df <- readr::read_csv("survey/bio478_survey_responses.csv")

# Domain order (used to control facet/plot sequence)
domains <- c(
  "Helpfulness of generative AI",
  "Inquiry & exploration",
  "Impact on learning",
  "Code quality outcomes using AI",
  "\"Vibe code\" outcomes",
  "Impact on metagenomics learning",
  "Trust calibration",
  "Ethical alignment"
)

# find columns that match any domain substring
col_matches <- names(df)[sapply(names(df), function(nm) any(sapply(domains, function(d) str_detect(nm, fixed(d)))))]
if (length(col_matches) == 0) stop("No matching columns found. Check column names or adjust domain patterns.")
raw_help <- df |> select(all_of(col_matches))
```

```{r combined-likert-col-info}
# helper to detect domain and extract item text inside brackets if present
detect_domain <- function(colname, domain_vec) {
  idx <- which(sapply(domain_vec, function(d) str_detect(colname, fixed(d))))
  if (length(idx) == 0) return(NA_character_)
  domain_vec[idx[1]]
}

col_info <- tibble(orig_name = names(raw_help)) |>
  mutate(domain = map_chr(orig_name, ~ detect_domain(.x, domains)),
         item = if_else(str_detect(orig_name, "\\[.*\\]"),
                        str_extract(orig_name, "(?<=\\[).+?(?=\\])"),
                        str_remove(orig_name, fixed(domain))),
         item = str_trim(item),
         item = if_else(item == "" | is.na(item), orig_name, item))
```

```{r combined-likert-pivot-map}
# Agreement levels and robust mapping function
agree_levels <- c("Strongly disagree", "Disagree", "Neutral", "Agree", "Strongly agree")

map_to_agree <- function(x) {
  x <- stringr::str_squish(as.character(x))
  x_lower <- tolower(x)
  case_when(
    # helpfulness -> agreement mapping
    x_lower %in% c("not at all helpful", "not helpful", "not at all helpful to not helpful") ~ "Strongly disagree",
    x_lower %in% c("slightly helpful") ~ "Disagree",
    x_lower %in% c("moderately helpful") ~ "Neutral",
    x_lower %in% c("very helpful") ~ "Agree",
    x_lower %in% c("extremely helpful") ~ "Strongly agree",
    # direct agreement variants
    x_lower %in% c("strongly disagree", "strong disagree") ~ "Strongly disagree",
    x_lower %in% c("disagree") ~ "Disagree",
    x_lower %in% c("neutral", "neither agree nor disagree", "neither") ~ "Neutral",
    x_lower %in% c("agree") ~ "Agree",
    x_lower %in% c("strongly agree", "strong agree") ~ "Strongly agree",
    # already canonical
    x %in% agree_levels ~ x,
    TRUE ~ NA_character_
  )
}

# pivot to long, join col_info, map responses, compute counts and percentages
agree_levels <- c("Strongly disagree","Disagree","Neutral","Agree","Strongly agree")

long <- raw_help %>%
  pivot_longer(cols = everything(), names_to = "orig_name", values_to = "response_raw") %>%
  left_join(col_info, by = "orig_name") %>%
  mutate(response_mapped = map_to_agree(response_raw)) %>%
  group_by(domain, item, response_mapped) %>%
  summarise(n = n(), .groups = "drop_last") %>%
  group_by(domain, item) %>%
  # add rows for any missing response levels per domain/item
  complete(response_mapped = agree_levels, fill = list(n = 0)) %>%
  # make sure response_mapped is an ordered factor with the exact levels
  mutate(response_mapped = factor(response_mapped, levels = agree_levels, ordered = TRUE),
         total_n = sum(n),
         pct = ifelse(total_n > 0, n / total_n, 0)) %>%
  ungroup()
```

```{r combined-likert-item-summary}
# compute per-item positive proportion (Agree + Strongly agree) per domain
item_summary <- long |>
  filter(!is.na(response_mapped)) |>
  group_by(domain, item) |>
  summarize(total_n = sum(n, na.rm = TRUE),
            positive_n = sum(n[response_mapped %in% c("Agree", "Strongly agree")], na.rm = TRUE),
            positive_pct = if_else(total_n > 0, positive_n / total_n, 0),
            .groups = "drop")
```

```{r combined-likert-build-plots, message=FALSE, warning=FALSE}
# Prepare per-domain data frames (only domains present)
domain_dfs <- long |>
  filter(!is.na(response_mapped)) |>
  group_split(domain)
names(domain_dfs) <- map_chr(domain_dfs, ~ unique(.x$domain))

# keep only requested domains that actually exist in data
present_domains <- intersect(domains, names(domain_dfs))
domain_dfs <- domain_dfs[present_domains]

# count items per domain for relative heights
item_counts <- map_int(domain_dfs, ~ length(unique(.x$item)))

# color palette and common y-limits
cols <- c("Strongly disagree" = "#d73027",
          "Disagree" = "#fc8d59",
          "Neutral" = "#fee090",
          "Agree" = "#91bfdb",
          "Strongly agree" = "#1a9850")
y_limits <- c(0, 1)

# Build one ggplot per domain. Ensure scale_fill includes all five categories and uses a one-row legend.
plot_list <- imap(domain_dfs, function(df_dom, dom_name) {
  # determine ordering by positive_pct (descending), tie-break by total_n (descending)
  item_order <- item_summary |>
    filter(domain == dom_name) |>
    arrange(-desc(positive_pct), desc(total_n)) |>
    pull(item)
  if (length(item_order) == 0) item_order <- unique(df_dom$item)

  df_dom2 <- df_dom |>
    mutate(item = factor(item, levels = item_order, ordered = TRUE))

  ggplot(df_dom2, aes(x = item, y = pct, fill = response_mapped)) +
    geom_col(width = 0.75, color = NA) +
    coord_flip() +
    scale_y_continuous(labels = percent_format(accuracy = 1), limits = y_limits, expand = c(0,0)) +
    scale_fill_manual(
        values = cols,
        breaks = agree_levels,
        limits = agree_levels,    # ensure every plot's scale has the same keys
        drop = FALSE,             # don't drop unused factor levels
        guide = guide_legend(nrow = 1, byrow = TRUE),
        name = "Response"
    ) +
    labs(title = dom_name, x = NULL, y = NULL) +
    theme_minimal(base_size = 12) +
    theme(plot.title = element_text(size = 12, face = "bold", hjust = 0.5),
          axis.text.y = element_text(size = 10),
          panel.grid.major.y = element_blank(),
          plot.margin = margin(6,6,6,6),
          text = element_text(color = "black"),
          legend.position = "bottom")
})
```

```{r combined-likert-combine-display}
#| fig-height: 14 
#| fig-width: 11

# Combine vertically with a single collected legend at bottom
combined <- wrap_plots(plot_list, ncol = 1, guides = "collect") +
  plot_layout(heights = item_counts, guides = "collect") & theme(legend.position = "bottom")

combined
```

###  When AI was wrong, I typically… - multiple response

```{r when_ai_wrong-clear}
# remove all objects from the environment - ha!
rm(list = ls())
```

```{r when_ai_wrong-read}
# Choose whether percentages should be relative to respondents who answered this question ("answerers") or relative to all survey respondents ("all"):
percent_base <- "answerers" # "answerers" or "all"

## Read data and detect the column
df <- read_csv("survey/bio478_survey_responses.csv")

# detect the multi-response column (flexible by partial name)
resp_col <- names(df)[str_detect(names(df), regex("When AI was wrong", ignore_case = TRUE))][1]
if(is.na(resp_col)) stop("Could not find a column matching 'When AI was wrong' in the CSV.")
# resp_col
```

```{r when_ai_wrong-prepare}
# Prepare answers (split multi-response entries)
# ensure respondent id exists
if(!"respondent_id" %in% names(df)) df <- df |> mutate(respondent_id = row_number())

df_answers <- df |>
  select(respondent_id, all_of(resp_col)) |>
  rename(raw = all_of(resp_col)) |>
  filter(!is.na(raw) & str_trim(raw) != "") |>               # only respondents who answered this question
  mutate(respondent_id = as.character(respondent_id)) |>
  # split by comma or semicolon (adjust sep if your data uses a different delimiter)
  separate_rows(raw, sep = "\\s*[,;]\\s*") |>
  # treat "Other: ..." as "Other" (if you want to inspect free text, modify this)
  mutate(answer = str_remove(raw, regex("^Other[:\\-]\\s*", ignore_case = TRUE)) |> str_trim()) |>
  mutate(answer = if_else(str_detect(raw, regex("^Other[:\\-]", ignore_case = TRUE)), "Other", answer)) |>
  distinct(respondent_id, answer) |>   # avoid double-count within same respondent
  filter(answer != "" & !is.na(answer))

# quick look at distinct answers found
# df_answers |> distinct(answer) |> arrange(answer)
```

```{r when_ai_wrong-options-order}
# If custom order not provided, infer from observed answers:
options_order <- if(exists("options_order")) options_order else df_answers |> distinct(answer) |> pull(answer)
```

```{r when_ai_wrong-counts}
# Count and compute percentages
counts <- df_answers |>
  count(answer, name = "n") |>
  complete(answer = options_order, fill = list(n = 0)) |>
  mutate(pct = n / sum(n),
         answer = forcats::fct_reorder(answer, -n))  # order by frequency

if(tolower(percent_base) == "all"){
  counts <- counts |> mutate(pct = n / nrow(df))
  y_label <- "Percent of all respondents"
} else {
  counts <- counts |> mutate(pct = n / n_distinct(df_answers$respondent_id))
  y_label <- "Percent of respondents who answered this question"
}
```

```{r when_ai_wrong-plot}
#| fig-height: 4 
#| fig-width: 10

p <- ggplot(counts, aes(x = fct_rev(answer), y = pct)) +
  geom_col(fill = "#881c1c", width = 0.7) +
  coord_flip() +
  scale_y_continuous(labels = percent_format(accuracy = 1), expand = expansion(mult = c(0, 0.12))) +
  geom_text(aes(label = paste0(n, " (", scales::percent(pct, accuracy = 1), ")")),
            hjust = -0.02, size = 3.2) +
  labs(title = "When AI was wrong, I typically…",
       x = NULL,
       y = y_label) +
  theme_minimal(base_size = 12) +
  theme(panel.grid.major.y = element_blank())

p
```

###  Common issues encountered - multiple response

```{r}
# remove all objects from the environment
rm(list = ls())
```

```{r common_issues-read}
# Choose whether percentages should be relative to respondents who answered this question ("answerers") or relative to all survey respondents ("all"):
percent_base <- "answerers" # "answerers" or "all"

## Read data and detect the column
df <- read_csv("survey/bio478_survey_responses.csv")

resp_col <- names(df)[str_detect(names(df), regex("Common issues encountered", ignore_case = TRUE))][1]
if(is.na(resp_col)) stop("Could not find a column matching 'Common issues encountered' in the CSV.")
# resp_col
```

```{r common_issues-prepare}
# Prepare answers (split multi-response entries)
# ensure respondent id exists
if(!"respondent_id" %in% names(df)) df <- df |> mutate(respondent_id = row_number())

df_answers <- df |>
  select(respondent_id, all_of(resp_col)) |>
  rename(raw = all_of(resp_col)) |>
  filter(!is.na(raw) & str_trim(raw) != "") |>               # only respondents who answered this question
  mutate(respondent_id = as.character(respondent_id)) |>
  # split by comma or semicolon (adjust sep if your data uses a different delimiter)
  separate_rows(raw, sep = "\\s*[,;]\\s*") |>
  # treat "Other: ..." as "Other" (if you want to inspect free text, modify this)
  mutate(answer = str_remove(raw, regex("^Other[:\\-]\\s*", ignore_case = TRUE)) |> str_trim()) |>
  mutate(answer = if_else(str_detect(raw, regex("^Other[:\\-]", ignore_case = TRUE)), "Other", answer)) |>
  distinct(respondent_id, answer) |>   # avoid double-count within same respondent
  filter(answer != "" & !is.na(answer))

# quick look at distinct answers found
# df_answers |> distinct(answer) |> arrange(answer)
```

```{r common_issues-order}
# If custom order not provided, infer from observed answers:
options_order <- if(exists("options_order")) options_order else df_answers |> distinct(answer) |> pull(answer)
```

```{r common_issues-count}
# Count and compute percentages
counts <- df_answers |>
  count(answer, name = "n") |>
  complete(answer = options_order, fill = list(n = 0)) |>
  mutate(pct = n / sum(n),
         answer = forcats::fct_reorder(answer, -n))  # order by frequency

if(tolower(percent_base) == "all"){
  counts <- counts |> mutate(pct = n / nrow(df))
  y_label <- "Percent of all respondents"
} else {
  counts <- counts |> mutate(pct = n / n_distinct(df_answers$respondent_id))
  y_label <- "Percent of respondents who answered this question"
}

```

```{r common_issues-plot}
#| fig-height: 4
#| fig-width: 10

p <- ggplot(counts, aes(x = fct_rev(answer), y = pct)) +
  geom_col(fill = "#881c1c", width = 0.7) +
  coord_flip() +
  scale_y_continuous(labels = percent_format(accuracy = 1), expand = expansion(mult = c(0, 0.12))) +
  geom_text(aes(label = paste0(n, " (", scales::percent(pct, accuracy = 1), ")")),
            hjust = -0.02, size = 3.2) +
  labs(title = "Common issues encountered",
       x = NULL,
       y = y_label) +
  theme_minimal(base_size = 12) +
  theme(panel.grid.major.y = element_blank())

p
```

###  Where more support would help - multiple response

```{r}
# remove all objects from the environment
rm(list = ls())
```

```{r support_would_help-read}
# Choose whether percentages should be relative to respondents who answered this question ("answerers") or relative to all survey respondents ("all"):
percent_base <- "answerers" # "answerers" or "all"

## Read data and detect the column
df <- read_csv("survey/bio478_survey_responses.csv")

resp_col <- names(df)[str_detect(names(df), regex("Where more support would help", ignore_case = TRUE))][1]
if(is.na(resp_col)) stop("Could not find a column matching 'Where more support would help' in the CSV.")
# resp_col
```

```{r support_would_help-prepare}
# Prepare answers (split multi-response entries)
# ensure respondent id exists
if(!"respondent_id" %in% names(df)) df <- df |> mutate(respondent_id = row_number())

df_answers <- df |>
  select(respondent_id, all_of(resp_col)) |>
  rename(raw = all_of(resp_col)) |>
  filter(!is.na(raw) & str_trim(raw) != "") |>               # only respondents who answered this question
  mutate(respondent_id = as.character(respondent_id)) |>
  # split by comma or semicolon (adjust sep if your data uses a different delimiter)
  separate_rows(raw, sep = "\\s*[,;]\\s*") |>
  # treat "Other: ..." as "Other" (if you want to inspect free text, modify this)
  mutate(answer = str_remove(raw, regex("^Other[:\\-]\\s*", ignore_case = TRUE)) |> str_trim()) |>
  mutate(answer = if_else(str_detect(raw, regex("^Other[:\\-]", ignore_case = TRUE)), "Other", answer)) |>
  distinct(respondent_id, answer) |>   # avoid double-count within same respondent
  filter(answer != "" & !is.na(answer))

# quick look at distinct answers found
# df_answers |> distinct(answer) |> arrange(answer)
```

```{r support_would_help-order}
# If custom order not provided, infer from observed answers:
options_order <- if(exists("options_order")) options_order else df_answers |> distinct(answer) |> pull(answer)
```

```{r support_would_help-count}
# Count and compute percentages
counts <- df_answers |>
  count(answer, name = "n") |>
  complete(answer = options_order, fill = list(n = 0)) |>
  mutate(pct = n / sum(n),
         answer = forcats::fct_reorder(answer, -n))  # order by frequency

if(tolower(percent_base) == "all"){
  counts <- counts |> mutate(pct = n / nrow(df))
  y_label <- "Percent of all respondents"
} else {
  counts <- counts |> mutate(pct = n / n_distinct(df_answers$respondent_id))
  y_label <- "Percent of respondents who answered this question"
}
```


```{r support_would_help-plot}
#| fig-height: 4 
#| fig-width: 10

p <- ggplot(counts, aes(x = fct_rev(answer), y = pct)) +
  geom_col(fill = "#881c1c", width = 0.7) +
  coord_flip() +
  scale_y_continuous(labels = percent_format(accuracy = 1), expand = expansion(mult = c(0, 0.12))) +
  geom_text(aes(label = paste0(n, " (", scales::percent(pct, accuracy = 1), ")")),
            hjust = -0.02, size = 3.2) +
  labs(title = "Where more support would help",
       x = NULL,
       y = y_label) +
  theme_minimal(base_size = 12) +
  theme(panel.grid.major.y = element_blank())

p
```

### Examples of helpful AI responses - Open response

```{r open-response}
# Read CSV for open_response
df_survey <- readr::read_csv("survey/bio478_survey_responses.csv") |>
  clean_names() 
```

```{r could_you_give_short_examples_of_a_helpful_ai_response}
wrapped_text <- str_wrap(df_survey$could_you_give_short_examples_of_a_helpful_ai_response, width = 80, indent = 0, exdent = 0, whitespace_only = TRUE)
cat(wrapped_text, sep = "\n\n")
```

### Examples of unhelpful or incorrect AI responses - Open response

```{r could_you_give_short_examples_of_unhelpful}
wrapped_text <- str_wrap(df_survey$could_you_give_short_examples_of_unhelpful_or_incorrect_ai_responses, width = 80, indent = 0, exdent = 0, whitespace_only = TRUE)
cat(wrapped_text, sep = "\n\n")
```

### Suggested changes for future offering - Open response

```{r suggested_changes_for_future_offerings}
wrapped_text <- str_wrap(df_survey$suggested_changes_for_future_offerings, width = 80, indent = 0, exdent = 0, whitespace_only = TRUE)
cat(wrapped_text, sep = "\n\n")
```

### Final comments and suggestions - Open response

```{r final_comments_and_suggestions}
wrapped_text <- str_wrap(df_survey$final_comments_and_suggestions, width = 80, indent = 0, exdent = 0, whitespace_only = TRUE)
cat(wrapped_text, sep = "\n\n")
```

### Table - Overall effectiveness / Likelihood to recommend AI

```{r overall_effectiveness}
cols <- c(
  "Overall effectiveness of AI in this course",
  "Likelihood to recommend AI use in similar courses"
)

res <- df |>
  select(any_of(cols)) |>
  pivot_longer(everything(), names_to = "column", values_to = "value") |>
  mutate(value = as.numeric(value)) |>                # convert to numeric
  group_by(column) |>
  summarise(
    mean = mean(value, na.rm = TRUE),
    sd   = sd(value, na.rm = TRUE),
    n    = sum(!is.na(value)),
    .groups = "drop"
  ) |>
  mutate(mean = round(mean, 2), sd = round(sd, 2))

kable(res)
```