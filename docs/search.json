[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Human [Environmental] Pathogen [Meta]Genome Analysis Fall 2025",
    "section": "",
    "text": "“Metagnomes! They’re always on hand to help with mining sequence from those complicated microbiomes” - redpenblackpen by Jason Mcdermott\n\n\nThis is a rendering of files from the course repository for Biology 478/678 Pathogen Genome Analysis Lab taught at the University of Massachusetts Amherst by Prof. Jeffrey Blanchard."
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Pathogen Genome Analysis Fall 2025",
    "section": "",
    "text": "Sept 3 (Wed) - Course Introduction & Lab 1: Introduction to Unity, R and RStudio\nSept 8 (Mon) - Discussion of research project possibilities\nSept 10 (Wed) - Lab 2: Coding in R with generative AI\nSept 15 (Mon) - Project background research - Adding references to Quarto documents using Zotero\nSept 17 (Wed) - Lab 3: Data Transformation with dyplr\nSept 22 (Mon) - Discussion of research project possibilities\nSept 24 (Wed) - Lab 4: Coding Basics, Style and Data Read/Write\nSept 29 (Mon) - Discussion of project methods and the scope of what is possible (in 10 weeks)\nOct 1 (Wed) - Lab 5: NEON Data Visualization\nOct 6 (Mon) - TBD\nOct 8 (Wed) - Lab 6: Table joins of NEON MAG, metagenomic and chemistry data\nOct 13 (Mon) Holiday – Indigenous People’s Day\nOct 15 (Wed) - Lab 7: Geographic mapping the NEON data\nOct 20 (Mon) - Dr. Jennifer DeBruyn - All Ooze Considered\nOct 22 (Wed) - Lab 8: Genome representations\nOct 27 (Mon) - TBD\nOct 29 (Wed) - Lab 9: Phylogenetic tree visualization using ggtree\nNov 3 (Mon) - TBD\nNov 5 (Wed) - Lab 10: Read abundance - normalization and statistics\nNov 10 (Mon) - TBD\nNov 12 (Wed) - Lab 11: TBD based on research project directions\nNov 17 (Mon) - TBD\nNov 19 (Wed) - Lab 12: TBD based on research project directions\nNov 24 (Mon) - Research project workday\nNov 26 (Wed) Holiday - Thanksgiving\nDec 1 (Mon) - Research project workday\nDec 3 (Wed) - Research project presentations\nDec 8 (Mon) - Research project presentations"
  },
  {
    "objectID": "methods.html",
    "href": "methods.html",
    "title": "CURE Project Specific Methods",
    "section": "",
    "text": "phyloNEON\nAccess_NEON_Data_for_Metagenomics\nVisualizing NEON samples within a plot"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Project Space",
    "section": "",
    "text": "For our course projects we will work with the One Health framework. “One Health is a collaborative, multisectoral, and transdisciplinary approach — working at the local, regional, national, and global levels — with the goal of achieving optimal health outcomes recognizing the interconnection between people, animals, plants, and their shared environment.” -Center for Disease Control (CDC) One Health. In addition to the CDC One Health, the One Health perspective is supported by the One Health Commission (OHC), One Health Initiative, One Health Platform, CDC One Health Office, the Food and Agriculture Organization of the United Nations (FAO), the United Nations Environment Programme (UNEP), the World Organisation for Animal Health (WOAH, founded as OIE), and the World Health Organization (WHO) – One Health Joint Plan of Action, 2022–2026. “One Health issues include emerging, re-emerging, and endemic zoonotic diseases, neglected tropical diseases, vector-borne diseases, antimicrobial resistance, food safety and food security, environmental contamination, climate change and other health threats shared by people, animals, and the environment.” - Center for Disease Control (CDC) One Health\n\n\n\nOne Health - https://en.wikipedia.org/wiki/One_Health\n\n\n\n\n\nOur environmental data will come from the National Ecological Observatory Network (NEON) funded through the National Science Foundation. NEON’s mission is to “To collect and freely share critical ecological data, samples, and infrastructure with researchers and the public to advance understanding of ecological processes and inform the sustainable management of U.S. ecosystems.” NEON’s data are an important part of the One Health framework.\n\n\n\nNEON Field Sites - https://www.neonscience.org/field-sites/about-field-sites\n\n\nThe NEON Harvard Forest and Quabbin Watershed sites are of particular interest to us in Massachusetts. The Quabbin Reservoir is the primary water supply for Boston, 40 towns in the Greater Boston area and several surrounding towns. There is a rich history of the river valley. The name Quabbin, meaning meeting of many waters, is after Native American chief Nani-Quaben. Artifacts show that people (ancestors of the Nipmucs) were living in the Swift River Valley as far back as 12,000 years - Ref. Here is a timeline of events including the removal of the towns of Dana, Prescott, Enfield and Greenwich. Today the Massachusetts Department of Conservation and Recreation (DCR) manages the forests surrounding the watershed which provide a living green bio-filter. The watershed “catches the rain, stores it, and releases it slowly, soaking up nutrients, keeping erosion to a minimum, and yielding a consistent supply of clean water.”\n\n\n\nNEON Harvard Forest and Quabbin sites\n\n\nHere are some of the NEON data portals we may work with\n\nNEON Soils\nNEON Soil Microbes\nNEON Aquatic Microbes\nNEON Pathogens\nNEON Biorepository\n\n\n\n\nOur metagenomic data comes from a collaboration between NEON and the Joint Genome Institute at the Lawrence Berkeley National Laboratory and supported by the US Department of Energy. We can browse the data at the Integrated Microbial Genome & Metagenome (IMG/M) system which supports the annotation, analysis, and distribution of microbial genome and microbiome datasets sequenced at JGI.\nJGI has done all lot of data processing for us, but there is much still to do.\n\n\n\nDOE JGI Metagenome Workflow - https://journals.asm.org/doi/10.1128/msystems.00804-20"
  },
  {
    "objectID": "projects.html#one-health",
    "href": "projects.html#one-health",
    "title": "Project Space",
    "section": "",
    "text": "For our course projects we will work with the One Health framework. “One Health is a collaborative, multisectoral, and transdisciplinary approach — working at the local, regional, national, and global levels — with the goal of achieving optimal health outcomes recognizing the interconnection between people, animals, plants, and their shared environment.” -Center for Disease Control (CDC) One Health. In addition to the CDC One Health, the One Health perspective is supported by the One Health Commission (OHC), One Health Initiative, One Health Platform, CDC One Health Office, the Food and Agriculture Organization of the United Nations (FAO), the United Nations Environment Programme (UNEP), the World Organisation for Animal Health (WOAH, founded as OIE), and the World Health Organization (WHO) – One Health Joint Plan of Action, 2022–2026. “One Health issues include emerging, re-emerging, and endemic zoonotic diseases, neglected tropical diseases, vector-borne diseases, antimicrobial resistance, food safety and food security, environmental contamination, climate change and other health threats shared by people, animals, and the environment.” - Center for Disease Control (CDC) One Health\n\n\n\nOne Health - https://en.wikipedia.org/wiki/One_Health"
  },
  {
    "objectID": "projects.html#the-national-science-foudation-nsf-national-ecological-observatory-network-neon",
    "href": "projects.html#the-national-science-foudation-nsf-national-ecological-observatory-network-neon",
    "title": "Project Space",
    "section": "The National Science Foudation (NSF) National Ecological Observatory Network (NEON)",
    "text": "The National Science Foudation (NSF) National Ecological Observatory Network (NEON)\nOur environmental data will come from the National Ecological Observatory Network (NEON) funded by the National Science Foundation."
  },
  {
    "objectID": "projects.html#the-department-of-energy-doe-joint-genome-institute",
    "href": "projects.html#the-department-of-energy-doe-joint-genome-institute",
    "title": "Project Space",
    "section": "The Department of Energy (DOE) Joint Genome Institute",
    "text": "The Department of Energy (DOE) Joint Genome Institute\n\nOverview\nOur metagenomic data comes from a collaboration between NEON and the Joint Genome Institute at the Lawrence Berkeley National Laboratory and supported by the US Department of Energy. We can browse the data at the Integrated Microbial Genome & Metagenome (IMG/M) system which supports the annotation, analysis, and distribution of microbial genome and microbiome datasets sequenced at JGI.\n\n\nOur metagenome data\nWe will work with the Gs0166454 and Gs0161344 study sets. JGI has done all lot of data processing for us, but there is much still to do.\n\n\n\nDOE JGI Metagenome Workflow - https://journals.asm.org/doi/10.1128/msystems.00804-20"
  },
  {
    "objectID": "projects.html#the-national-ecological-observatory-network-neon",
    "href": "projects.html#the-national-ecological-observatory-network-neon",
    "title": "Project Space",
    "section": "The National Ecological Observatory Network (NEON)",
    "text": "The National Ecological Observatory Network (NEON)\n\nOverview\nOur environmental data will come from the National Ecological Observatory Network (NEON) funded through the National Science Foundation. NEON’s mission is to “To collect and freely share critical ecological data, samples, and infrastructure with researchers and the public to advance understanding of ecological processes and inform the sustainable management of U.S. ecosystems.” NEON’s data are an important part of the One Health framework.\n\n\n\nNEON Field Sites - https://www.neonscience.org/field-sites/about-field-sites\n\n\n\n\nNEON Harvard Forest and Quabbin Watershed sites\nThe NEON Harvard Forest and Quabbin Watershed sites are of particular interest to us in Massachusetts. The Quabbin Reservoir is the primary water supply for Boston, 40 towns in the Greater Boston area and several surrounding towns. There is a rich history of the river valley. The name Quabbin, meaning meeting of many waters, is after Native American chief Nani-Quaben. Artifacts show that people (ancestors of the Nipmucs) were living in the Swift River Valley as far back as 12,000 years - Ref. Here is a timeline of events including the removal of the towns of Dana, Prescott, Enfield and Greenwich. Today the Massachusetts Department of Conservation and Recreation (DCR) manages the forests surrounding the watershed which provide a living green bio-filter. The watershed “catches the rain, stores it, and releases it slowly, soaking up nutrients, keeping erosion to a minimum, and yielding a consistent supply of clean water.”\n\n\n\nNEON Harvard Forest and Quabbin sites\n\n\n\n\nNEON Data Portals\n\nNEON Soils\nNEON Soil Microbes\nNEON Aquatic Microbes\nNEON Pathogens\nNEON Biorepository"
  },
  {
    "objectID": "labs.html",
    "href": "labs.html",
    "title": "Labs",
    "section": "",
    "text": "R Labs\n\nLab 1 : Overview & Getting Started\nLab 2 : Learning R with the Help of AI tools Starting with Graphing using ggplot\nLab 3 : Data Transformation with dplyr\nLab 4 : Coding Basics, Style and Data Read/Write\nLab 5 : Working with NEON Metagenome Assembled Genomes (MAGs / bins)\nLab 6 : ggplotting with NEON MAG data\nLab 7 : Data Tidying, Transformation and Visualization with COVID-19 reporting data\nLab 8: Catch up, What will viruses do next?, the first AI genomes and metagenome brainstorming\nLab 9 : Phylogenetic tree visualization using ggtree\nLab 10 : Read abundance - normalization and statistics\n\nUnity Labs\n\nLab : Running bioinformatics software on Unity (Blast, Read mapping)\n\nSharing and Publishing\n\nLab S1 : Quarto\nLab S2 : Adding References to Your Report with Zotero\nLab : Connecting a Github repo site with a RStudio project\nLab : Quarto Manuscripts\nLab : Building a 5 tab web site with Quarto\nLab : R Shiny\n\nManuscript\n\nPathoGen manuscript : Deadline Dec 10"
  },
  {
    "objectID": "report.html",
    "href": "report.html",
    "title": "Pathogen Genome Analysis Fall 2025",
    "section": "",
    "text": "Report\nManuscript style with Title Abstract Intro Methods Results Discussion Future Directions\nPublic communication Poems"
  },
  {
    "objectID": "projects.html#the-joint-genome-institute",
    "href": "projects.html#the-joint-genome-institute",
    "title": "Project Space",
    "section": "The Joint Genome Institute",
    "text": "The Joint Genome Institute\n\nOverview\nOur metagenomic data comes from a collaboration between NEON and the Joint Genome Institute at the Lawrence Berkeley National Laboratory and supported by the US Department of Energy. We can browse the data at the Integrated Microbial Genome & Metagenome (IMG/M) system which supports the annotation, analysis, and distribution of microbial genome and microbiome datasets sequenced at JGI.\n\n\nOur metagenome data\nWe will work with the Gs0166454 and Gs0161344 study sets. JGI has done all lot of data processing for us, but there is much still to do.\n\n\n\nDOE JGI Metagenome Workflow - https://journals.asm.org/doi/10.1128/msystems.00804-20"
  },
  {
    "objectID": "manuscripts.html",
    "href": "manuscripts.html",
    "title": "Manuscripts",
    "section": "",
    "text": "Should labs be in Manuscript form too?\nQuarto documentation on manuscripts https://quarto.org/docs/manuscripts/\nSee Quarto section on RStudio IDE for spell checking https://quarto.org/docs/visual-editor/content.html\nReproducible publishing with Quarto Dr. Mine Çetinkaya-Rundel Dr. Charlotte Wickham https://mine-cetinkaya-rundel.github.io/quarto-jsm24/4-manuscripts/4-manuscripts.html#/title-slide https://mine.quarto.pub/quarto-manuscripts-rmed/#/title-slide\nCut the tyranny of copy-and-paste with these coding tools https://www.nature.com/articles/d41586-022-00563-z\nNotebooks now! https://data.agu.org/notebooks-now/\nDecent example with references - https://jperkel.github.io/computed_quarto_manuscript/\nIntroducing eLife’s first computationally reproducible article https://elifesciences.org/labs/ad58f08d/introducing-elife-s-first-computationally-reproducible-article\nPioneering ‘live-code’ article allows scientists to play with each other’s results https://www.nature.com/articles/d41586-019-00724-7"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "A Zotero Workflow for R - https://www.anthonyschmidt.co/post/2021-10-25-a-zotero-workflow-for-r/"
  },
  {
    "objectID": "phyloNEON.html",
    "href": "phyloNEON.html",
    "title": "phyloNEON",
    "section": "",
    "text": "This is from https://github.com/NEONScience/phyloNEON/blob/main/README.md and https://github.com/NEONScience/phyloNEON/blob/main/docs/metagenomic/README.md\nA set of tools in R and Python to run phylogenetic and taxonomic analyses on NEON and related data"
  },
  {
    "objectID": "phyloNEON.html#installation",
    "href": "phyloNEON.html#installation",
    "title": "phyloNEON",
    "section": "Installation",
    "text": "Installation\nTo install phyloNEON, you will need the devtools package.\nlibrary(devtools)\n\ninstall_github(\"NEONScience/phyloNEON/phyloNEON\")"
  },
  {
    "objectID": "phyloNEON.html#accessing-and-using-neon-genetic-data",
    "href": "phyloNEON.html#accessing-and-using-neon-genetic-data",
    "title": "phyloNEON",
    "section": "Accessing and using NEON genetic data",
    "text": "Accessing and using NEON genetic data\nNEON offers several data products that include genetic data. This repository is being developed to include tools and guidelines to help users of NEON data to better utilize the genetic data.\n\nNEON metagenomic data\nDNA is extracted from NEON soil and aquatic samples and sequenced with a shotgun sequence library prep. Through collaborations with the Joint Genome Institute (JGI) and the National Microbime Collaborative Network (NMDC), most of the metagenomic sequencing data are available on the data portals of these organizations. Connections to these external data sources are being built into NEON data releases. The phyloNEON package also offers some tools and guidelines to help the user find and analyze NEON metagenomic data on the JGI/NMDC data portals.\nThis page on the repo (in docs/metagenomic/README.md) will help you get started"
  },
  {
    "objectID": "phyloNEON.html#accessing-neon-samples-on-the-jgi-img-data-portal",
    "href": "phyloNEON.html#accessing-neon-samples-on-the-jgi-img-data-portal",
    "title": "phyloNEON",
    "section": "Accessing NEON samples on the JGI IMG data portal",
    "text": "Accessing NEON samples on the JGI IMG data portal\n\nNEON metagenome database\nA table (neon.metaDB) has been added to the phyloNEON package that contains over 1,800 NEON metagenome samples that are on the JGI IMG data portal. This includes legacy data as well as all samples that are part of the JGI CSP award, which covers deep sequencing and analysis by JGI of all NEON metagenome samples collected in 2023 and 2024. Included in the table are several fields with JGI metadata and statistics for each sample, such as Sequencing Method, GenomeSize, GeneCount, and number of bins (metaBATbinCount). Also included are some NEON variables such as siteID and collectDate, as well as multiple environmental terms assigned to each sample according to ENVO specifications (e.g. Ecosystem Category, Ecosystem Type, Specific Ecosystem). The table also has reference codes for the Genome Online Database (GOLD), including GOLD Analysis Project ID and GOLD Study ID; and the taxon OID (imgGenomeID) that allows accessing the sample on the JGI IMG data portal.\nThis table is available when you load the package phyloNEON.\n\n\nR code\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(phyloNEON)\nlibrary(DT)\nlibrary(viridis)\n\n\nSave file to have version used\n\n\nR code\nwrite_csv(neon.metaDB, \"data/NEON_metadata/neon.metaDB_20250701.csv\")\n\n\nTo view the table neon.metaDB (Note set eval = FALSE or do not include in your R code or you will get an error when rendering)\n\n\nR code\nView(neon.metaDB)\n\n\nTo view the structure of the neon.metaDB\n\n\nR code\nstr(neon.metaDB)\n\n\ntibble [1,834 × 32] (S3: tbl_df/tbl/data.frame)\n $ dnaSampleID               : chr [1:1834] \"ONAQ_044-M-20190619-COMP-DNA1\" \"PUUM_031-O-20210104-COMP-DNA1\" \"TECR.20230821.EPILITHON.8.DNA-DNA1\" \"KONZ_003-M-20170710-COMP-DNA1\" ...\n $ imgGenomeID               : num [1:1834] 3.3e+09 3.3e+09 3.3e+09 3.3e+09 3.3e+09 ...\n $ jgiProjectID              : num [1:1834] NA NA 1506438 0 1500369 ...\n $ ITS Proposal ID           : num [1:1834] NA NA 509938 NA 509938 ...\n $ Sequencing Status         : chr [1:1834] \"Permanent Draft\" \"Permanent Draft\" \"Permanent Draft\" \"Permanent Draft\" ...\n $ Study Name                : chr [1:1834] \"Terrestrial soil microbial communities from various locations - NEON\" \"Terrestrial soil microbial communities from various locations - NEON\" \"Soil and water microbial communities from various NEON Field Sites across the United States\" \"Terrestrial soil microbial communities from various locations - NEON\" ...\n $ GenomeName                : chr [1:1834] \"Terrestrial soil microbial communities from Onaqui, Utah, USA - ONAQ_044-M-20190619-COMP-DNA1\" \"Terrestrial soil microbial communities from Puu Makaala Natural Area Reserve, Hawaii, USA - PUUM_031-O-20210104-COMP-DNA1\" \"Freshwater microbial communities from Teakettle 2 Creek NEON Field Site, Sierra National Forest, CA, USA - TECR\"| __truncated__ \"Terrestrial soil microbial communities from Konza Prairie Biological Station, Prairie Peninsula, KS, USA - KONZ\"| __truncated__ ...\n $ Sequencing Center         : chr [1:1834] \"Battelle Memorial Institute\" \"Battelle Memorial Institute\" \"DOE Joint Genome Institute  (JGI)\" \"Battelle Memorial Institute\" ...\n $ GOLD Analysis Project ID  : chr [1:1834] \"Ga0620072\" \"Ga0619546\" \"Ga0672972\" \"Ga0428256\" ...\n $ GOLD Analysis Project Type: chr [1:1834] \"Metagenome Analysis\" \"Metagenome Analysis\" \"Metagenome Analysis\" \"Metagenome Analysis\" ...\n $ GOLD Sequencing Project ID: chr [1:1834] \"Gp0766640\" \"Gp0766114\" \"Gp0812633\" \"Gp0476824\" ...\n $ GOLD Study ID             : chr [1:1834] \"Gs0144570\" \"Gs0144570\" \"Gs0166454\" \"Gs0144570\" ...\n $ Funding Program           : chr [1:1834] NA NA \"CSP\" NA ...\n $ Sequencing Method         : chr [1:1834] \"Illumina NextSeq 550\" \"Illumina NextSeq 550\" \"Illumina NovaSeq X 10B\" \"Illumina NextSeq 550\" ...\n $ Sequencing Quality        : chr [1:1834] \"Level 1: Standard Draft\" \"Level 1: Standard Draft\" \"Level 1: Standard Draft\" \"Level 1: Standard Draft\" ...\n $ siteID                    : chr [1:1834] \"ONAQ\" \"PUUM\" \"TECR\" \"KONZ\" ...\n $ collectDate               : chr [1:1834] \"20190619\" \"20210104\" \"20230821\" \"20170710\" ...\n $ Ecosystem                 : chr [1:1834] \"Environmental\" \"Environmental\" \"Environmental\" \"Environmental\" ...\n $ Ecosystem Category        : chr [1:1834] \"Terrestrial\" \"Terrestrial\" \"Aquatic\" \"Terrestrial\" ...\n $ Ecosystem Subtype         : chr [1:1834] \"Unclassified\" \"Forest\" \"Creek\" \"Unclassified\" ...\n $ Ecosystem Type            : chr [1:1834] \"Soil\" \"Soil\" \"Freshwater\" \"Soil\" ...\n $ Specific Ecosystem        : chr [1:1834] \"Unclassified\" \"Unclassified\" \"Unclassified\" \"Unclassified\" ...\n $ GenomeSize                : num [1:1834] 3.57e+06 8.86e+04 8.33e+08 2.23e+07 7.62e+08 ...\n $ GeneCount                 : num [1:1834] 11955 313 1296700 63840 1113040 ...\n $ ScaffoldCount             : num [1:1834] 10633 277 671686 56485 522571 ...\n $ metaBATbinCount           : num [1:1834] 0 0 11 0 23 5 0 7 0 0 ...\n $ eukCCbinCount             : num [1:1834] 0 0 2 0 2 0 0 0 0 0 ...\n $ estNumberGenomes          : num [1:1834] 0 0 147 0 151 215 0 132 0 0 ...\n $ avgGenomeSize             : num [1:1834] 0 0 5663975 0 5046004 ...\n $ numberFilteredReads       : num [1:1834] 0.00 0.00 1.87e+08 0.00 3.15e+08 ...\n $ numberMappedReads         : num [1:1834] 0.00 0.00 1.03e+08 0.00 2.78e+08 ...\n $ pctAssembledReads         : num [1:1834] 0 0 55.4 0 88.2 ...\n\n\nConvert the collectDate from character to date format\n\n\nR code\nneon.metaDB.my &lt;- neon.metaDB\nneon.metaDB.my$collectDate &lt;- as.numeric(neon.metaDB.my$collectDate)\nneon.metaDB.my$collectDate &lt;- ymd(neon.metaDB.my$collectDate)\nstr(neon.metaDB.my$collectDate)\n\n\n Date[1:1834], format: \"2019-06-19\" \"2021-01-04\" \"2023-08-21\" \"2017-07-10\" \"2023-07-12\" ...\n\n\n\n\nTable of mean genome size per year\n\n\nR code\nneon.metaDB.my |&gt; \n  filter(`GOLD Analysis Project Type` != \"Combined Assembly\") |&gt; \n  group_by(year = lubridate::year(collectDate)) |&gt; \n  summarize(mean_GenomeSize = mean(GenomeSize))\n\n\n# A tibble: 9 × 2\n   year mean_GenomeSize\n  &lt;dbl&gt;           &lt;dbl&gt;\n1  2013        8635723.\n2  2014        7670580.\n3  2016       16242281.\n4  2017       17172060.\n5  2018       14100181.\n6  2019       16735397.\n7  2020       37402350.\n8  2021     1334660078.\n9  2023     1310246892.\n\n\n\n\nTable HARV mean genome size per year\n\n\nR code\nneon.metaDB.my |&gt; \n  filter(siteID == \"HARV\") |&gt; \n  group_by(year = lubridate::year(collectDate)) |&gt; \n  summarize(mean_GenomeSize = mean(GenomeSize))\n\n\n# A tibble: 6 × 2\n   year mean_GenomeSize\n  &lt;dbl&gt;           &lt;dbl&gt;\n1  2013        4721159.\n2  2016       17096867.\n3  2017       29942423.\n4  2019       13990976.\n5  2020       30567005.\n6  2023     2236533461.\n\n\n\n\nPlot of genome size per year\n\n\nR code\nneon.metaDB.my |&gt; \n  ggplot(aes(x=collectDate, y = GenomeSize)) +\n  geom_col(colour = \"maroon\", fill = \"maroon\") +\n  coord_flip()\n\n\n\n\n\n\n\n\n\nTo reformat dnasampleID column for terrestrial samples (This does not work for the aquatic samples)\n\n\nR code\nneon.metaDB.my.soil &lt;- neon.metaDB.my |&gt; \n  filter(`Ecosystem Category` == \"Terrestrial\") |&gt; \n  filter(`GOLD Analysis Project Type` != \"Combined Assembly\") |&gt; \n  \n  separate(`dnaSampleID`, c(\"dnaSampleID.site\",\"dnaSampleID.sub\"), \"_\", remove=FALSE) |&gt; \n  \n  mutate_at(\"dnaSampleID.sub\", str_replace, \"-COMP\", \"_COMP\") |&gt;\n  mutate_at(\"dnaSampleID.sub\", str_replace, \"-GEN\", \"_GEN\") |&gt;\n  separate(`dnaSampleID.sub`, c(\"dnaSampleID.sub\",\"dnaSampleID.type\"), \"_\") |&gt; \n  \n  mutate_at(\"dnaSampleID.sub\", str_replace, \"-M\", \"_M\") |&gt;\n  mutate_at(\"dnaSampleID.sub\", str_replace, \"-O\", \"_O\") |&gt;\n  separate(`dnaSampleID.sub`, c(\"dnaSampleID.plot\",\"dnaSampleID.sub\"), \"_\") |&gt; \n  \n  mutate_at(\"dnaSampleID.sub\", str_replace, \"M-\", \"M_\") |&gt;\n  mutate_at(\"dnaSampleID.sub\", str_replace, \"O-\", \"O_\") |&gt;\n  separate(`dnaSampleID.sub`, c(\"dnaSampleID.layer\",\"dnaSampleID.sub\"), \"_\") |&gt; \n\n  mutate_at(\"dnaSampleID.sub\", str_replace, \"-201\", \"201\") |&gt;\n  mutate_at(\"dnaSampleID.sub\", str_replace, \"-202\", \"202\") |&gt;\n  mutate_at(\"dnaSampleID.sub\", str_replace, \"201\", \"_201\") |&gt;\n  mutate_at(\"dnaSampleID.sub\", str_replace, \"202\", \"_202\") |&gt;\n  separate(`dnaSampleID.sub`, c(\"dnaSampleID.subplot\",\"dnaSampleID.date\"), \"_\") |&gt; \n\n  unite(plotID, c(dnaSampleID.site, dnaSampleID.plot), sep='_', remove=FALSE)\n\nneon.metaDB.my.soil$dnaSampleID.data &lt;- as.numeric(neon.metaDB.my.soil$dnaSampleID.date)\nneon.metaDB.my.soil$dnaSampleID.date &lt;- ymd(neon.metaDB.my.soil$dnaSampleID.date)\n\n\nTo reformat dnasampleID column for aquatic samples\n\n\nR code\nneon.metaDB.my.aquatic &lt;- neon.metaDB.my |&gt; \n  filter(`Ecosystem Category` == \"Aquatic\") |&gt; \n  filter(`GOLD Analysis Project Type` != \"Combined Assembly\") |&gt; \n  \n  mutate(dnaSampleID.sub = dnaSampleID) |&gt; \n  mutate_at(\"dnaSampleID.sub\", str_replace, \".202\", \"_202\") |&gt;\n  separate(`dnaSampleID.sub`, c(\"dnaSampleID.site\",\"dnaSampleID.sub\"), \"_\") |&gt; \n  separate(`dnaSampleID.site`, c(\"dnaSampleID.site\",\"dnaSampleID.code\"), \"\\\\.\") |&gt; \n  \n  mutate_at(\"dnaSampleID.sub\", str_replace, \".DNA\", \"_DNA\") |&gt;\n  separate(`dnaSampleID.sub`, c(\"dnaSampleID.sub\",\"dnaSampleID.type\"), \"_\") |&gt; \n  \n  separate(`dnaSampleID.sub`, c(\"dnaSampleID.data\",\"dnaSampleID.niche\", \"dnaSampleID.num\"), \"\\\\.\") |&gt; \n\n  unite(dnaSampleID.niche, c(dnaSampleID.code, dnaSampleID.niche)) |&gt; \n  mutate_at(\"dnaSampleID.niche\", str_replace, \"NA_\", \"\") |&gt;\n  mutate_at(\"dnaSampleID.niche\", str_replace, \"_NA\", \"\")\n\n\n\n\nHARV metagenomes by year and plot\n\n\nR code\ndatatable(\nneon.metaDB.my.soil |&gt; \n  filter(siteID == \"HARV\") |&gt; \n  group_by(Year = lubridate::year(collectDate), dnaSampleID.plot) |&gt; \n  count() |&gt; \n  pivot_wider(names_from = dnaSampleID.plot, values_from = n) |&gt; \n  mutate_all(funs(replace_na(.,0)))\n)\n\n\n\n\n\n\n\n\nWREF metagenomes by year and plot\n\n\nR code\ndatatable(\nneon.metaDB.my.soil |&gt; \n  filter(siteID == \"WREF\") |&gt; \n  group_by(Year = lubridate::year(collectDate), dnaSampleID.plot) |&gt; \n  count() |&gt; \n  pivot_wider(names_from = dnaSampleID.plot, values_from = n) |&gt; \n  mutate_all(funs(replace_na(.,0)))\n)\n\n\n\n\n\n\n\n\nPlot of HARV samples per plot per year\n\n\nR code\nneon.metaDB.my.soil |&gt; \n  filter(siteID == \"HARV\") |&gt; \n  group_by(Year = lubridate::year(collectDate), dnaSampleID.plot) |&gt; \n  count() |&gt; \n  pivot_wider(names_from = dnaSampleID.plot, values_from = n) |&gt; \n  mutate_all(funs(replace_na(.,0))) |&gt; \n  pivot_longer(!Year, names_to = \"plot\", values_to = \"metagenomes\") |&gt; \n  ggplot(aes(x=Year, y = plot)) +\n  geom_tile(aes(fill = metagenomes)) +\n  scale_fill_viridis(discrete=FALSE, direction = -1) +\n  scale_x_continuous(breaks = seq(2013, 2023, by = 1)) \n\n\n\n\n\n\n\n\n\n\n\nMissing years at HARV\nAll sites are missing data from 2021 and 2022. That should be in IMG soon. What about 2018?\n\nCollectDate\n\n\nR code\nneon.metaDB.my.soil |&gt; \n  group_by(Year = lubridate::year(collectDate)) |&gt; \n  count() \n\n\n# A tibble: 9 × 2\n# Groups:   Year [9]\n   Year     n\n  &lt;dbl&gt; &lt;int&gt;\n1  2013    63\n2  2014   106\n3  2016   229\n4  2017   326\n5  2018    45\n6  2019   231\n7  2020   185\n8  2021   117\n9  2023   303\n\n\n\n\ndnaSampleID.date\n\n\nR code\nneon.metaDB.my.soil |&gt; \n  group_by(Year = lubridate::year(dnaSampleID.date)) |&gt; \n  count() \n\n\n# A tibble: 9 × 2\n# Groups:   Year [9]\n   Year     n\n  &lt;dbl&gt; &lt;int&gt;\n1  2013    63\n2  2014   106\n3  2016   229\n4  2017   326\n5  2018    45\n6  2019   231\n7  2020   185\n8  2021   117\n9  2023   303\n\n\n\n\n\nPlot of samples per plot per year at all sites\n\n\nR code\nneon.metaDB.my.soil |&gt; \n  group_by(siteID, Year = lubridate::year(collectDate), dnaSampleID.plot) |&gt; \n  count() |&gt; \n  pivot_wider(names_from = Year, values_from = n) |&gt; \n  mutate_all(funs(replace_na(.,0))) |&gt; \n  pivot_longer(!c(siteID, dnaSampleID.plot), names_to = \"Year\", values_to = \"metagenomes\") |&gt; \n  ggplot(aes(x=Year, y = dnaSampleID.plot)) +\n  geom_tile(aes(fill = metagenomes)) +\n  scale_fill_viridis(discrete=FALSE, direction = -1) +\n # scale_x_continuous(breaks = seq(2013, 2023, by = 1)) +\n  facet_wrap(~siteID, scales =\"free_y\", ncol = 3) +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))"
  },
  {
    "objectID": "project_opps.html",
    "href": "project_opps.html",
    "title": "Project Opportunities",
    "section": "",
    "text": "We need to randomly pull 1/3 reads from each individual core then combine and assemble\n\n\nhttps://www.neonscience.org/field-sites/harv\n\nHARV_001-O-20230705-COMP-DNA1\nHARV_002-O-20230706-COMP-DNA1\nHARV_005-O-20230710-COMP-DNA1\nHARV_013-O-20230704-COMP-DNA1\nHARV_021-O-20230706-COMP-DNA1\nHARV_033-O-20230703-COMP-DNA1\nHARV_035-O-20230704-COMP-DNA1\n\n\n\n\nhttps://www.neonscience.org/field-sites/sjer\n\nSJER_001-M-20230227-COMP-DNA1\nSJER_002-M-20230228-COMP-DNA1\nSJER_005-M-20230306-COMP-DNA1\nSJER_025-M-20230302-COMP-DNA1\nSJER_045-M-20230227-COMP-DNA1\nSJER_046-M-20230227-COMP-DNA1\n\n\n\n\n\nPossibility of combined assembly and mapping\n\n\nhttps://www.neonscience.org/field-sites/hopb\n\nFreshwater microbial communities from Lower Hop Brook NEON Field Site, New Salem, MA, USA - HOPB.SS.20230117.DNA-DNA1\nFreshwater microbial communities from Lower Hop Brook NEON Field Site, New Salem, MA, USA - HOPB.SS.20230221.DNA-DNA1\nFreshwater microbial communities from Lower Hop Brook NEON Field Site, New Salem, MA, USA - HOPB.SS.20230419.DNA-DNA1\nFreshwater microbial communities from Lower Hop Brook NEON Field Site, New Salem, MA, USA - HOPB.SS.20230620.DNA-DNA1\nFreshwater microbial communities from Hop Brook NEON Field Site, New Salem, MA, USA - HOPB.SS.20230719.DNA-DNA1 (version 2)\nFreshwater microbial communities from Lower Hop Brook NEON Field Site, New Salem, MA, USA - HOPB.SS.20230815.DNA-DNA1\nFreshwater microbial communities from Lower Hop Brook NEON Field Site, New Salem, MA, USA - HOPB.SS.20231017.DNA-DNA1\n\n\n\n\nhttps://www.neonscience.org/field-sites/cari\n\nFreshwater microbial communities from Caribou Creek NEON Field Site, Chatanika, Alaska, USA - CARI.SS.20230110.DNA-DNA1\nFreshwater microbial communities from Caribou Creek NEON Field Site, Chatanika, Alaska, USA - CARI.SS.20230314.DNA-DNA1e\nFreshwater microbial communities from Caribou Creek NEON Field Site, Chatanika, Alaska, USA - CARI.SS.20230502.DNA-DNA1\nFreshwater microbial communities from Caribou Creek NEON Field Site, Chatanika, Alaska, USA - CARI.SS.20230731.DNA-DNA1\nFreshwater microbial communities from Caribou Creek NEON Field Site, Chatanika, Alaska, USA - CARI.SS.20230905.DNA-DNA1\nFreshwater microbial communities from Caribou Creek NEON Field Site, Chatanika, Alaska, USA - CARI.SS.20231031.DNA-DNA1"
  },
  {
    "objectID": "project_opps.html#projects",
    "href": "project_opps.html#projects",
    "title": "Project Opportunities",
    "section": "",
    "text": "We need to randomly pull 1/3 reads from each individual core then combine and assemble\n\n\nhttps://www.neonscience.org/field-sites/harv\n\nHARV_001-O-20230705-COMP-DNA1\nHARV_002-O-20230706-COMP-DNA1\nHARV_005-O-20230710-COMP-DNA1\nHARV_013-O-20230704-COMP-DNA1\nHARV_021-O-20230706-COMP-DNA1\nHARV_033-O-20230703-COMP-DNA1\nHARV_035-O-20230704-COMP-DNA1\n\n\n\n\nhttps://www.neonscience.org/field-sites/sjer\n\nSJER_001-M-20230227-COMP-DNA1\nSJER_002-M-20230228-COMP-DNA1\nSJER_005-M-20230306-COMP-DNA1\nSJER_025-M-20230302-COMP-DNA1\nSJER_045-M-20230227-COMP-DNA1\nSJER_046-M-20230227-COMP-DNA1\n\n\n\n\n\nPossibility of combined assembly and mapping\n\n\nhttps://www.neonscience.org/field-sites/hopb\n\nFreshwater microbial communities from Lower Hop Brook NEON Field Site, New Salem, MA, USA - HOPB.SS.20230117.DNA-DNA1\nFreshwater microbial communities from Lower Hop Brook NEON Field Site, New Salem, MA, USA - HOPB.SS.20230221.DNA-DNA1\nFreshwater microbial communities from Lower Hop Brook NEON Field Site, New Salem, MA, USA - HOPB.SS.20230419.DNA-DNA1\nFreshwater microbial communities from Lower Hop Brook NEON Field Site, New Salem, MA, USA - HOPB.SS.20230620.DNA-DNA1\nFreshwater microbial communities from Hop Brook NEON Field Site, New Salem, MA, USA - HOPB.SS.20230719.DNA-DNA1 (version 2)\nFreshwater microbial communities from Lower Hop Brook NEON Field Site, New Salem, MA, USA - HOPB.SS.20230815.DNA-DNA1\nFreshwater microbial communities from Lower Hop Brook NEON Field Site, New Salem, MA, USA - HOPB.SS.20231017.DNA-DNA1\n\n\n\n\nhttps://www.neonscience.org/field-sites/cari\n\nFreshwater microbial communities from Caribou Creek NEON Field Site, Chatanika, Alaska, USA - CARI.SS.20230110.DNA-DNA1\nFreshwater microbial communities from Caribou Creek NEON Field Site, Chatanika, Alaska, USA - CARI.SS.20230314.DNA-DNA1e\nFreshwater microbial communities from Caribou Creek NEON Field Site, Chatanika, Alaska, USA - CARI.SS.20230502.DNA-DNA1\nFreshwater microbial communities from Caribou Creek NEON Field Site, Chatanika, Alaska, USA - CARI.SS.20230731.DNA-DNA1\nFreshwater microbial communities from Caribou Creek NEON Field Site, Chatanika, Alaska, USA - CARI.SS.20230905.DNA-DNA1\nFreshwater microbial communities from Caribou Creek NEON Field Site, Chatanika, Alaska, USA - CARI.SS.20231031.DNA-DNA1"
  },
  {
    "objectID": "projects.html#overview",
    "href": "projects.html#overview",
    "title": "Project Space",
    "section": "",
    "text": "For our course projects we will work with the One Health framework. “One Health is a collaborative, multisectoral, and transdisciplinary approach — working at the local, regional, national, and global levels — with the goal of achieving optimal health outcomes recognizing the interconnection between people, animals, plants, and their shared environment.” -Center for Disease Control (CDC) One Health. In addition to the CDC One Health, the One Health perspective is supported by the One Health Commission (OHC), One Health Initiative, One Health Platform, CDC One Health Office, the Food and Agriculture Organization of the United Nations (FAO), the United Nations Environment Programme (UNEP), the World Organisation for Animal Health (WOAH, founded as OIE), and the World Health Organization (WHO) – One Health Joint Plan of Action, 2022–2026. “One Health issues include emerging, re-emerging, and endemic zoonotic diseases, neglected tropical diseases, vector-borne diseases, antimicrobial resistance, food safety and food security, environmental contamination, climate change and other health threats shared by people, animals, and the environment.” - Center for Disease Control (CDC) One Health\n\n\n\nOne Health - https://en.wikipedia.org/wiki/One_Health\n\n\n\n\n\nOur environmental data will come from the National Ecological Observatory Network (NEON) funded through the National Science Foundation. NEON’s mission is to “To collect and freely share critical ecological data, samples, and infrastructure with researchers and the public to advance understanding of ecological processes and inform the sustainable management of U.S. ecosystems.” NEON’s data are an important part of the One Health framework.\n\n\n\nNEON Field Sites - https://www.neonscience.org/field-sites/about-field-sites\n\n\nThe NEON Harvard Forest and Quabbin Watershed sites are of particular interest to us in Massachusetts. The Quabbin Reservoir is the primary water supply for Boston, 40 towns in the Greater Boston area and several surrounding towns. There is a rich history of the river valley. The name Quabbin, meaning meeting of many waters, is after Native American chief Nani-Quaben. Artifacts show that people (ancestors of the Nipmucs) were living in the Swift River Valley as far back as 12,000 years - Ref. Here is a timeline of events including the removal of the towns of Dana, Prescott, Enfield and Greenwich. Today the Massachusetts Department of Conservation and Recreation (DCR) manages the forests surrounding the watershed which provide a living green bio-filter. The watershed “catches the rain, stores it, and releases it slowly, soaking up nutrients, keeping erosion to a minimum, and yielding a consistent supply of clean water.”\n\n\n\nNEON Harvard Forest and Quabbin sites\n\n\nHere are some of the NEON data portals we may work with\n\nNEON Soils\nNEON Soil Microbes\nNEON Aquatic Microbes\nNEON Pathogens\nNEON Biorepository\n\n\n\n\nOur metagenomic data comes from a collaboration between NEON and the Joint Genome Institute at the Lawrence Berkeley National Laboratory and supported by the US Department of Energy. We can browse the data at the Integrated Microbial Genome & Metagenome (IMG/M) system which supports the annotation, analysis, and distribution of microbial genome and microbiome datasets sequenced at JGI.\nJGI has done all lot of data processing for us, but there is much still to do.\n\n\n\nDOE JGI Metagenome Workflow - https://journals.asm.org/doi/10.1128/msystems.00804-20"
  },
  {
    "objectID": "projects.html#our-project-space",
    "href": "projects.html#our-project-space",
    "title": "Project Space",
    "section": "Our Project Space",
    "text": "Our Project Space\nNEON has produced metagenomic data as data product since 2014. The Joint Genome Institute has recently annotated version all reads prior to 20222 Gs0144570. However, these metagenomes have a low sequencing depth and therefore are difficult to use for assembling bacterial genomes.\nLast year JGI and NEON collaborated to produce metagenomes which are ~10-fold deeper which allow for better assemble of reads into gene length and greater fragments. We will work with the NEON 2023 Gs0166454 study set. Although some of the data for 2024 is available, JGI is still processing the data and producing annotations (see above illustration)."
  },
  {
    "objectID": "projects.html#projects",
    "href": "projects.html#projects",
    "title": "Project Space",
    "section": "Projects",
    "text": "Projects\n\nSeparate Core vs Combined Core Metagenomes\nWe need to randomly pull 1/3 reads from each individual core then combine and assemble\n\nHarvard Forest & Quabbin (HARV), Worcester County, MA\nhttps://www.neonscience.org/field-sites/harv\n\nHARV_001-O-20230705-COMP-DNA1\nHARV_002-O-20230706-COMP-DNA1\nHARV_005-O-20230710-COMP-DNA1\nHARV_013-O-20230704-COMP-DNA1\nHARV_021-O-20230706-COMP-DNA1\nHARV_033-O-20230703-COMP-DNA1\nHARV_035-O-20230704-COMP-DNA1\n\n\n\nSan Joaquin Experimental Range (SJER), Madera County, CA\nhttps://www.neonscience.org/field-sites/sjer\n\nSJER_001-M-20230227-COMP-DNA1\nSJER_002-M-20230228-COMP-DNA1\nSJER_005-M-20230306-COMP-DNA1\nSJER_025-M-20230302-COMP-DNA1\nSJER_045-M-20230227-COMP-DNA1\nSJER_046-M-20230227-COMP-DNA1\n\n\n\n\nAquatic time series\nPossibility of combined assembly and mapping\n\nHop Brook, New Salem, MA (Quabbin)\nhttps://www.neonscience.org/field-sites/hopb\n\nFreshwater microbial communities from Lower Hop Brook NEON Field Site, New Salem, MA, USA - HOPB.SS.20230117.DNA-DNA1\nFreshwater microbial communities from Lower Hop Brook NEON Field Site, New Salem, MA, USA - HOPB.SS.20230221.DNA-DNA1\nFreshwater microbial communities from Lower Hop Brook NEON Field Site, New Salem, MA, USA - HOPB.SS.20230419.DNA-DNA1\nFreshwater microbial communities from Lower Hop Brook NEON Field Site, New Salem, MA, USA - HOPB.SS.20230620.DNA-DNA1\nFreshwater microbial communities from Hop Brook NEON Field Site, New Salem, MA, USA - HOPB.SS.20230719.DNA-DNA1 (version 2)\nFreshwater microbial communities from Lower Hop Brook NEON Field Site, New Salem, MA, USA - HOPB.SS.20230815.DNA-DNA1\nFreshwater microbial communities from Lower Hop Brook NEON Field Site, New Salem, MA, USA - HOPB.SS.20231017.DNA-DNA1\n\n\n\nCaribou Creek, Chatanika, Alaska\nhttps://www.neonscience.org/field-sites/cari\n\nFreshwater microbial communities from Caribou Creek NEON Field Site, Chatanika, Alaska, USA - CARI.SS.20230110.DNA-DNA1\nFreshwater microbial communities from Caribou Creek NEON Field Site, Chatanika, Alaska, USA - CARI.SS.20230314.DNA-DNA1\nFreshwater microbial communities from Caribou Creek NEON Field Site, Chatanika, Alaska, USA - CARI.SS.20230502.DNA-DNA1\nFreshwater microbial communities from Caribou Creek NEON Field Site, Chatanika, Alaska, USA - CARI.SS.20230731.DNA-DNA1\nFreshwater microbial communities from Caribou Creek NEON Field Site, Chatanika, Alaska, USA - CARI.SS.20230905.DNA-DNA1\nFreshwater microbial communities from Caribou Creek NEON Field Site, Chatanika, Alaska, USA - CARI.SS.20231031.DNA-DNA1"
  },
  {
    "objectID": "Access_NEON_Data_for_Metagenomics.html",
    "href": "Access_NEON_Data_for_Metagenomics.html",
    "title": "Access NEON Data for Metagenomics",
    "section": "",
    "text": "From Access NEON Data for Metagenomics See * Update on the changing NEON microbial data * Soil microbe metagenome sequences\nInstall packages\n\n\nR code\ninstall.packages(\"neonUtilities\")\ninstall.packages(\"neonOS\")\n\n\n\n\nR code\nlibrary(neonUtilities)\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(DT)\nlibrary(viridis)\n\n\n\n\nR code\nsoilTrialSites = c(\"BONA\",\"DEJU\",\"HEAL\",\"TOOL\",\"BARR\")\nsoilTrialSites = c(\"HARV\")\n\n\nsoilChem &lt;- loadByProduct(\n  dpID='DP1.10086.001',\n  startdate = \"2017-01\",\n  enddate = \"2019-12\",\n  check.size = FALSE,\n  site = soilTrialSites,\n  package='expanded')\n\n\n\n\nR code\nView(soilChem$sls_metagenomicsPooling)\n\n\n\n\nR code\nmetaGdata &lt;- loadByProduct(dpID = 'DP1.10107.001',\n\n                          check.size = FALSE,\n\n                          package = 'expanded') \n\n\n\n\nR code\nmetaGdata_mms_metagenomeSequencing &lt;- metaGdata$mms_metagenomeSequencing\nwrite_csv(metaGdata_mms_metagenomeSequencing, \"data/NEON_metadata/metaGdata_mms_metagenomeSequencing.csv\")\n\n\nThis has HARV data collected up until 2022. The 2021 and 2022 data are not in the phyloNEON data.\n\n\nR code\nmetaGdata_mms_metagenomeSequencing_HARV &lt;- metaGdata$mms_metagenomeSequencing |&gt; \nwrite_csv(metaGdata_mms_metagenomeSequencing_HARV, \"data/NEON_metadata/metaGdata_mms_metagenomeSequencing_HARV.csv\")\n\n\n\nRead in saved file (all above in eval = FALSE)\n\n\nR code\nmetaGdata_mms_metagenomeSequencing &lt;- read_csv(\"data/NEON_metadata/metaGdata_mms_metagenomeSequencing.csv\")\n\n\n\n\nCreate data frame from dnaSampleID\n\n\nR code\nmetaGdata_dnaSampleID &lt;- metaGdata_mms_metagenomeSequencing |&gt; \n  select(dnaSampleID)\n\n# Read in 2023 and 2024 data that is not in the metagenome data product yet\n\nneon_ay23_jgi_samples &lt;- read_csv(\"data/NEON_metadata/neon_ay23_jgi_samples_soil.csv\")\nneon_ay24_jgi_samples &lt;- read_csv(\"data/NEON_metadata/neon_ay24_jgi_samples_soil.csv\")\n\nneon_dnaSampleID &lt;- rbind(metaGdata_dnaSampleID, neon_ay23_jgi_samples, neon_ay24_jgi_samples)\n\n\n\nFull table\n\n\nR code\nneon_dnaSampleID_split &lt;- neon_dnaSampleID |&gt; \n\n  separate(`dnaSampleID`, c(\"dnaSampleID.site\",\"dnaSampleID.sub\"), \"_\", remove=FALSE) |&gt; \n  \n  mutate_at(\"dnaSampleID.sub\", str_replace, \"-comp\", \"_COMP\") |&gt;\n  mutate_at(\"dnaSampleID.sub\", str_replace, \"-COMP\", \"_COMP\") |&gt;\n  mutate_at(\"dnaSampleID.sub\", str_replace, \"-GEN\", \"_GEN\") |&gt;\n  separate(`dnaSampleID.sub`, c(\"dnaSampleID.sub\",\"dnaSampleID.type\"), \"_\") |&gt; \n  \n  mutate_at(\"dnaSampleID.sub\", str_replace, \"-M\", \"_M\") |&gt;\n  mutate_at(\"dnaSampleID.sub\", str_replace, \"-O\", \"_O\") |&gt;\n  separate(`dnaSampleID.sub`, c(\"dnaSampleID.plot\",\"dnaSampleID.sub\"), \"_\") |&gt; \n  \n  mutate_at(\"dnaSampleID.sub\", str_replace, \"M-\", \"M_\") |&gt;\n  mutate_at(\"dnaSampleID.sub\", str_replace, \"O-\", \"O_\") |&gt;\n  separate(`dnaSampleID.sub`, c(\"dnaSampleID.layer\",\"dnaSampleID.sub\"), \"_\") |&gt; \n\n  mutate_at(\"dnaSampleID.sub\", str_replace, \"-201\", \"201\") |&gt;\n  mutate_at(\"dnaSampleID.sub\", str_replace, \"-202\", \"202\") |&gt;\n  mutate_at(\"dnaSampleID.sub\", str_replace, \"2013\", \"_2013\") |&gt;\n  mutate_at(\"dnaSampleID.sub\", str_replace, \"2014\", \"_2014\") |&gt;\n  mutate_at(\"dnaSampleID.sub\", str_replace, \"2015\", \"_2015\") |&gt;\n  mutate_at(\"dnaSampleID.sub\", str_replace, \"2016\", \"_2016\") |&gt;\n  mutate_at(\"dnaSampleID.sub\", str_replace, \"2017\", \"_2017\") |&gt;\n  mutate_at(\"dnaSampleID.sub\", str_replace, \"2018\", \"_2018\") |&gt;\n  mutate_at(\"dnaSampleID.sub\", str_replace, \"2019\", \"_2019\") |&gt;\n  mutate_at(\"dnaSampleID.sub\", str_replace, \"2020\", \"_2020\") |&gt;\n  mutate_at(\"dnaSampleID.sub\", str_replace, \"2021\", \"_2021\") |&gt;\n  mutate_at(\"dnaSampleID.sub\", str_replace, \"2022\", \"_2022\") |&gt;\n  mutate_at(\"dnaSampleID.sub\", str_replace, \"2023\", \"_2023\") |&gt;\n  mutate_at(\"dnaSampleID.sub\", str_replace, \"2024\", \"_2024\") |&gt;\n  separate(`dnaSampleID.sub`, c(\"dnaSampleID.subplot\",\"dnaSampleID.date\"), \"_\") |&gt; \n\n  unite(plotID, c(dnaSampleID.site, dnaSampleID.plot), sep='_', remove=FALSE)\n\nneon_dnaSampleID_split$dnaSampleID.date &lt;- as.numeric(neon_dnaSampleID_split$dnaSampleID.date)\nneon_dnaSampleID_split$dnaSampleID.date &lt;- ymd(neon_dnaSampleID_split$dnaSampleID.date)\n\n\n\n\nFull table\n\n\nR code\nmetaGdata_mms_metagenomeSequencing &lt;- metaGdata_mms_metagenomeSequencing |&gt; \n\n  separate(`dnaSampleID`, c(\"dnaSampleID.site\",\"dnaSampleID.sub\"), \"_\", remove=FALSE) |&gt; \n  \n  mutate_at(\"dnaSampleID.sub\", str_replace, \"-comp\", \"_COMP\") |&gt;\n  mutate_at(\"dnaSampleID.sub\", str_replace, \"-COMP\", \"_COMP\") |&gt;\n  mutate_at(\"dnaSampleID.sub\", str_replace, \"-GEN\", \"_GEN\") |&gt;\n  separate(`dnaSampleID.sub`, c(\"dnaSampleID.sub\",\"dnaSampleID.type\"), \"_\") |&gt; \n  \n  mutate_at(\"dnaSampleID.sub\", str_replace, \"-M\", \"_M\") |&gt;\n  mutate_at(\"dnaSampleID.sub\", str_replace, \"-O\", \"_O\") |&gt;\n  separate(`dnaSampleID.sub`, c(\"dnaSampleID.plot\",\"dnaSampleID.sub\"), \"_\") |&gt; \n  \n  mutate_at(\"dnaSampleID.sub\", str_replace, \"M-\", \"M_\") |&gt;\n  mutate_at(\"dnaSampleID.sub\", str_replace, \"O-\", \"O_\") |&gt;\n  separate(`dnaSampleID.sub`, c(\"dnaSampleID.layer\",\"dnaSampleID.sub\"), \"_\") |&gt; \n\n  mutate_at(\"dnaSampleID.sub\", str_replace, \"-201\", \"201\") |&gt;\n  mutate_at(\"dnaSampleID.sub\", str_replace, \"-202\", \"202\") |&gt;\n  mutate_at(\"dnaSampleID.sub\", str_replace, \"201\", \"_201\") |&gt;\n  mutate_at(\"dnaSampleID.sub\", str_replace, \"202\", \"_202\") |&gt;\n  separate(`dnaSampleID.sub`, c(\"dnaSampleID.subplot\",\"dnaSampleID.date\"), \"_\") |&gt; \n\n  unite(plotID, c(dnaSampleID.site, dnaSampleID.plot), sep='_', remove=FALSE)\n\nmetaGdata_mms_metagenomeSequencing$dnaSampleID.data &lt;- as.numeric(metaGdata_mms_metagenomeSequencing$dnaSampleID.date)\nmetaGdata_mms_metagenomeSequencing$dnaSampleID.date &lt;- ymd(metaGdata_mms_metagenomeSequencing$dnaSampleID.date)\n\n\n\n\n\nPlot of HARV samples per plot per year\n\n\nR code\nneon_dnaSampleID_split |&gt; \n  filter(dnaSampleID.site == \"HARV\") |&gt; \n  group_by(Year = lubridate::year(dnaSampleID.date), dnaSampleID.plot) |&gt; \n  count() |&gt; \n  pivot_wider(names_from = dnaSampleID.plot, values_from = n) |&gt; \n  mutate_all(funs(replace_na(.,0))) |&gt; \n  pivot_longer(!Year, names_to = \"plot\", values_to = \"metagenomes\") |&gt; \n  ggplot(aes(x=Year, y = plot)) +\n  geom_tile(aes(fill = metagenomes)) +\n  scale_fill_viridis(discrete=FALSE, direction = -1) +\n  scale_x_continuous(breaks = seq(2013, 2024, by = 1)) \n\n\n\n\n\n\n\n\n\n\n\nPlot of samples per plot per year at all sites\n\n\nR code\nneon_dnaSampleID_split |&gt; \n  group_by(dnaSampleID.site, Year = lubridate::year(dnaSampleID.date), dnaSampleID.plot) |&gt; \n  count() |&gt; \n  pivot_wider(names_from = Year, values_from = n) |&gt; \n  mutate_all(funs(replace_na(.,0))) |&gt; \n  pivot_longer(!c(dnaSampleID.site, dnaSampleID.plot), names_to = \"Year\", values_to = \"metagenomes\") |&gt; \n  ggplot(aes(x=Year, y = dnaSampleID.plot)) +\n  geom_tile(aes(fill = metagenomes)) +\n  scale_fill_viridis(discrete=FALSE, direction = -1) +\n  facet_wrap(~dnaSampleID.site, scales =\"free_y\", ncol = 3) +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) \n\n\n\n\n\n\n\n\n\n\n\nTable of mean sampleFilteredReadNumber\nAbout 3-5x increase in reads in 2021 and 2022 About 10-20x increase in 2023 over 2021 and 2022\n\n\nR code\nmetaGdata_mms_metagenomeSequencing |&gt; \n  filter(dnaSampleID.site == \"HARV\") |&gt; \n  group_by(Year = lubridate::year(collectDate)) |&gt; \n  summarize(mean_sampleFilteredReadNumber = mean(sampleFilteredReadNumber))\n\n\n# A tibble: 8 × 2\n   Year mean_sampleFilteredReadNumber\n  &lt;dbl&gt;                         &lt;dbl&gt;\n1  2013                           NA \n2  2016                      6643162.\n3  2017                      5038437 \n4  2018                      2633512.\n5  2019                      4560748.\n6  2020                      3468523.\n7  2021                     16005210.\n8  2022                     19339618.\n\n\n\n\nTable of mean sampleTotalReadNumber\nAbout 3-5x increase in reads in 2021 and 2022 About 10-20x increase in 2023 over 2021 and 2022\n\n\nR code\nmetaGdata_mms_metagenomeSequencing |&gt; \n  filter(dnaSampleID.site == \"HARV\") |&gt; \n  group_by(Year = lubridate::year(collectDate)) |&gt; \n  summarize(mean_sampleTotalReadNumber = mean(sampleTotalReadNumber))\n\n\n# A tibble: 8 × 2\n   Year mean_sampleTotalReadNumber\n  &lt;dbl&gt;                      &lt;dbl&gt;\n1  2013                   9270681.\n2  2016                  10802077.\n3  2017                  11456008.\n4  2018                   6664285.\n5  2019                   5442366.\n6  2020                   4674903 \n7  2021                  27270286.\n8  2022                  31374636."
  },
  {
    "objectID": "lab_AI_R.html",
    "href": "lab_AI_R.html",
    "title": "Learning R with the help of AI tools",
    "section": "",
    "text": "AI won’t take your job, but someone using who knows how to use AI might. Think of AI as a force multiplier. You have to learn to code first before you can use AI to help you. Y Combinator reports that over 25% of its startups are now relying on AI for 95% of their code base, while Google recently reported that about 25% of its new code is AI-generated.\nMicrosoft designed Copilot to work off of the latest version of OpenAI’s GPT model, GPT-4,\n\ngithub co-pilot - https://github.com/copilot\ngithub education - https://github.com/education\nRStudio github copilot - https://docs.posit.co/ide/user/ide/guide/tools/copilot.html\nMicrosoft Introduction to GitHub Copilot - https://learn.microsoft.com/en-us/training/modules/introduction-to-github-copilot/\nIntroduction to GitHub CoPilot videos - https://learn.microsoft.com/en-us/shows/introduction-to-github-copilot/\nSet up co-pilot for learning - https://docs.github.com/en/get-started/learning-to-code/setting-up-copilot-for-learning-to-code\nHow to write better prompts for GitHub Copilot - https://github.blog/developer-skills/github/how-to-write-better-prompts-for-github-copilot/\nAI Assisted Coding in RStudio - https://research-it.manchester.ac.uk/news/2024/11/29/ai-assisted-coding-in-rstudio/\nRTutor AI - https://rtutor.ai/\nSyntha AI - https://syntha.ai/code-generators/r\nR Code Generator - https://codingfleet.com/code-generator/r/\nLearning the tidyverse with the help of AI tools - https://www.tidyverse.org/blog/2025/04/learn-tidyverse-ai/\nIntroducing vitals, a toolkit for evaluating LLM products in R - https://www.tidyverse.org/blog/2025/06/vitals-0-1-0/\nUsing AI with R - https://rfortherestofus.com/courses/ai\nBoost Your R Skills with AI - https://artscience.ai/boost-your-r-skills-with-ai/\nBeginner’s Tutorial for the OpenAI API in R - https://tilburg.ai/2024/03/tutorial-openai-api-in-r/\nCodex - https://chatgpt.com/codex\n\nAI Assisted Coding in RStudio - https://research-it.manchester.ac.uk/news/2024/11/29/ai-assisted-coding-in-rstudio/ Integrating OpenAI’s ChatGPT into RStudio is now possible with “Chattr”, “GPT Studio” and “GitHub Copilot”. These new tools will help you find the right functions and commands and to quickly generate code snippets to save you time.\n8 ChatGPT packages for R - https://www.infoworld.com/article/2338386/8-chatgpt-tools-for-r-programming.html\n\nVibe coding https://www.geeksforgeeks.org/techtips/what-is-vibe-coding/\nWhat is vibe coding, exactly? - https://www.technologyreview.com/2025/04/16/1115135/what-is-vibe-coding-exactly/\nWhat Is Vibe Coding? Definition, Tools, Pros, and Cons - https://www.datacamp.com/blog/vibe-coding\nYou can use GitHub and Git to collaborate on work. https://docs.github.com/en/get-started/start-your-journey/about-github-and-git\nUsing co-pilot as your tutor - https://docs.github.com/en/get-started/learning-to-code/setting-up-copilot-for-learning-to-code\nchattr - https://mlverse.github.io/chattr/\n\nBioinformatics and AI * A data-intelligence-intensive bioinformatics copilot system for large-scale omics research and scientific insights - https://academic.oup.com/bib/article/26/4/bbaf312/8196318?login=true * Bioinformatics AI: Driving Future Biological Breakthroughs - https://biologyinsights.com/bioinformatics-ai-driving-future-biological-breakthroughs/"
  },
  {
    "objectID": "methods/phyloNEON.html",
    "href": "methods/phyloNEON.html",
    "title": "phyloNEON",
    "section": "",
    "text": "This is from https://github.com/NEONScience/phyloNEON/blob/main/README.md and https://github.com/NEONScience/phyloNEON/blob/main/docs/metagenomic/README.md\nA set of tools in R and Python to run phylogenetic and taxonomic analyses on NEON and related data"
  },
  {
    "objectID": "methods/phyloNEON.html#installation",
    "href": "methods/phyloNEON.html#installation",
    "title": "phyloNEON",
    "section": "Installation",
    "text": "Installation\nTo install phyloNEON, you will need the devtools package.\nlibrary(devtools)\n\ninstall_github(\"NEONScience/phyloNEON/phyloNEON\")"
  },
  {
    "objectID": "methods/phyloNEON.html#accessing-and-using-neon-genetic-data",
    "href": "methods/phyloNEON.html#accessing-and-using-neon-genetic-data",
    "title": "phyloNEON",
    "section": "Accessing and using NEON genetic data",
    "text": "Accessing and using NEON genetic data\nNEON offers several data products that include genetic data. This repository is being developed to include tools and guidelines to help users of NEON data to better utilize the genetic data.\n\nNEON metagenomic data\nDNA is extracted from NEON soil and aquatic samples and sequenced with a shotgun sequence library prep. Through collaborations with the Joint Genome Institute (JGI) and the National Microbime Collaborative Network (NMDC), most of the metagenomic sequencing data are available on the data portals of these organizations. Connections to these external data sources are being built into NEON data releases. The phyloNEON package also offers some tools and guidelines to help the user find and analyze NEON metagenomic data on the JGI/NMDC data portals.\nThis page on the repo (in docs/metagenomic/README.md) will help you get started"
  },
  {
    "objectID": "methods/phyloNEON.html#accessing-neon-samples-on-the-jgi-img-data-portal",
    "href": "methods/phyloNEON.html#accessing-neon-samples-on-the-jgi-img-data-portal",
    "title": "phyloNEON",
    "section": "Accessing NEON samples on the JGI IMG data portal",
    "text": "Accessing NEON samples on the JGI IMG data portal\n\nNEON metagenome database\nA table (neon.metaDB) has been added to the phyloNEON package that contains over 1,800 NEON metagenome samples that are on the JGI IMG data portal. This includes legacy data as well as all samples that are part of the JGI CSP award, which covers deep sequencing and analysis by JGI of all NEON metagenome samples collected in 2023 and 2024. Included in the table are several fields with JGI metadata and statistics for each sample, such as Sequencing Method, GenomeSize, GeneCount, and number of bins (metaBATbinCount). Also included are some NEON variables such as siteID and collectDate, as well as multiple environmental terms assigned to each sample according to ENVO specifications (e.g. Ecosystem Category, Ecosystem Type, Specific Ecosystem). The table also has reference codes for the Genome Online Database (GOLD), including GOLD Analysis Project ID and GOLD Study ID; and the taxon OID (imgGenomeID) that allows accessing the sample on the JGI IMG data portal.\nThis table is available when you load the package phyloNEON.\n\n\nR code\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(phyloNEON)\nlibrary(DT)\nlibrary(viridis)\n\n\nSave file to have version used\n\n\nR code\nwrite_csv(neon.metaDB, \"../data/NEON_metadata/neon.metaDB_20250701.csv\")\n\n\n\n\nR code\nneon.metaDB <- read_csv(\"../data/NEON_metadata/neon.metaDB_20250701.csv\")\n\n\nTo view the table neon.metaDB (Note set eval = FALSE or do not include in your R code or you will get an error when rendering)\n\n\nR code\nView(neon.metaDB)\n\n\nTo view the structure of the neon.metaDB\n\n\nR code\nstr(neon.metaDB)\n\n\ntibble [1,834 × 32] (S3: tbl_df/tbl/data.frame)\n $ dnaSampleID               : chr [1:1834] \"ONAQ_044-M-20190619-COMP-DNA1\" \"PUUM_031-O-20210104-COMP-DNA1\" \"TECR.20230821.EPILITHON.8.DNA-DNA1\" \"KONZ_003-M-20170710-COMP-DNA1\" ...\n $ imgGenomeID               : num [1:1834] 3.3e+09 3.3e+09 3.3e+09 3.3e+09 3.3e+09 ...\n $ jgiProjectID              : num [1:1834] NA NA 1506438 0 1500369 ...\n $ ITS Proposal ID           : num [1:1834] NA NA 509938 NA 509938 ...\n $ Sequencing Status         : chr [1:1834] \"Permanent Draft\" \"Permanent Draft\" \"Permanent Draft\" \"Permanent Draft\" ...\n $ Study Name                : chr [1:1834] \"Terrestrial soil microbial communities from various locations - NEON\" \"Terrestrial soil microbial communities from various locations - NEON\" \"Soil and water microbial communities from various NEON Field Sites across the United States\" \"Terrestrial soil microbial communities from various locations - NEON\" ...\n $ GenomeName                : chr [1:1834] \"Terrestrial soil microbial communities from Onaqui, Utah, USA - ONAQ_044-M-20190619-COMP-DNA1\" \"Terrestrial soil microbial communities from Puu Makaala Natural Area Reserve, Hawaii, USA - PUUM_031-O-20210104-COMP-DNA1\" \"Freshwater microbial communities from Teakettle 2 Creek NEON Field Site, Sierra National Forest, CA, USA - TECR\"| __truncated__ \"Terrestrial soil microbial communities from Konza Prairie Biological Station, Prairie Peninsula, KS, USA - KONZ\"| __truncated__ ...\n $ Sequencing Center         : chr [1:1834] \"Battelle Memorial Institute\" \"Battelle Memorial Institute\" \"DOE Joint Genome Institute  (JGI)\" \"Battelle Memorial Institute\" ...\n $ GOLD Analysis Project ID  : chr [1:1834] \"Ga0620072\" \"Ga0619546\" \"Ga0672972\" \"Ga0428256\" ...\n $ GOLD Analysis Project Type: chr [1:1834] \"Metagenome Analysis\" \"Metagenome Analysis\" \"Metagenome Analysis\" \"Metagenome Analysis\" ...\n $ GOLD Sequencing Project ID: chr [1:1834] \"Gp0766640\" \"Gp0766114\" \"Gp0812633\" \"Gp0476824\" ...\n $ GOLD Study ID             : chr [1:1834] \"Gs0144570\" \"Gs0144570\" \"Gs0166454\" \"Gs0144570\" ...\n $ Funding Program           : chr [1:1834] NA NA \"CSP\" NA ...\n $ Sequencing Method         : chr [1:1834] \"Illumina NextSeq 550\" \"Illumina NextSeq 550\" \"Illumina NovaSeq X 10B\" \"Illumina NextSeq 550\" ...\n $ Sequencing Quality        : chr [1:1834] \"Level 1: Standard Draft\" \"Level 1: Standard Draft\" \"Level 1: Standard Draft\" \"Level 1: Standard Draft\" ...\n $ siteID                    : chr [1:1834] \"ONAQ\" \"PUUM\" \"TECR\" \"KONZ\" ...\n $ collectDate               : chr [1:1834] \"20190619\" \"20210104\" \"20230821\" \"20170710\" ...\n $ Ecosystem                 : chr [1:1834] \"Environmental\" \"Environmental\" \"Environmental\" \"Environmental\" ...\n $ Ecosystem Category        : chr [1:1834] \"Terrestrial\" \"Terrestrial\" \"Aquatic\" \"Terrestrial\" ...\n $ Ecosystem Subtype         : chr [1:1834] \"Unclassified\" \"Forest\" \"Creek\" \"Unclassified\" ...\n $ Ecosystem Type            : chr [1:1834] \"Soil\" \"Soil\" \"Freshwater\" \"Soil\" ...\n $ Specific Ecosystem        : chr [1:1834] \"Unclassified\" \"Unclassified\" \"Unclassified\" \"Unclassified\" ...\n $ GenomeSize                : num [1:1834] 3.57e+06 8.86e+04 8.33e+08 2.23e+07 7.62e+08 ...\n $ GeneCount                 : num [1:1834] 11955 313 1296700 63840 1113040 ...\n $ ScaffoldCount             : num [1:1834] 10633 277 671686 56485 522571 ...\n $ metaBATbinCount           : num [1:1834] 0 0 11 0 23 5 0 7 0 0 ...\n $ eukCCbinCount             : num [1:1834] 0 0 2 0 2 0 0 0 0 0 ...\n $ estNumberGenomes          : num [1:1834] 0 0 147 0 151 215 0 132 0 0 ...\n $ avgGenomeSize             : num [1:1834] 0 0 5663975 0 5046004 ...\n $ numberFilteredReads       : num [1:1834] 0.00 0.00 1.87e+08 0.00 3.15e+08 ...\n $ numberMappedReads         : num [1:1834] 0.00 0.00 1.03e+08 0.00 2.78e+08 ...\n $ pctAssembledReads         : num [1:1834] 0 0 55.4 0 88.2 ...\n\n\nConvert the collectDate from character to date format\n\n\nR code\nneon.metaDB.my <- neon.metaDB\nneon.metaDB.my$collectDate <- as.numeric(neon.metaDB.my$collectDate)\nneon.metaDB.my$collectDate <- ymd(neon.metaDB.my$collectDate)\nstr(neon.metaDB.my$collectDate)\n\n\n Date[1:1834], format: \"2019-06-19\" \"2021-01-04\" \"2023-08-21\" \"2017-07-10\" \"2023-07-12\" ...\n\n\n\n\nTable of mean genome size per year\n\n\nR code\nneon.metaDB.my |> \n  filter(`GOLD Analysis Project Type` != \"Combined Assembly\") |> \n  group_by(year = lubridate::year(collectDate)) |> \n  summarize(mean_GenomeSize = mean(GenomeSize))\n\n\n# A tibble: 9 × 2\n   year mean_GenomeSize\n  <dbl>           <dbl>\n1  2013        8635723.\n2  2014        7670580.\n3  2016       16242281.\n4  2017       17172060.\n5  2018       14100181.\n6  2019       16735397.\n7  2020       37402350.\n8  2021     1334660078.\n9  2023     1310246892.\n\n\n\n\nTable HARV mean genome size per year\n\n\nR code\nneon.metaDB.my |> \n  filter(siteID == \"HARV\") |> \n  group_by(year = lubridate::year(collectDate)) |> \n  summarize(mean_GenomeSize = mean(GenomeSize))\n\n\n# A tibble: 6 × 2\n   year mean_GenomeSize\n  <dbl>           <dbl>\n1  2013        4721159.\n2  2016       17096867.\n3  2017       29942423.\n4  2019       13990976.\n5  2020       30567005.\n6  2023     2236533461.\n\n\n\n\nPlot of genome size per year\n\n\nR code\nneon.metaDB.my |> \n  ggplot(aes(x=collectDate, y = GenomeSize)) +\n  geom_col(colour = \"maroon\", fill = \"maroon\") +\n  coord_flip()\n\n\n\n\n\nTo reformat dnasampleID column for terrestrial samples (This does not work for the aquatic samples)\n\n\nR code\nneon.metaDB.my.soil <- neon.metaDB.my |> \n  filter(`Ecosystem Category` == \"Terrestrial\") |> \n  filter(`GOLD Analysis Project Type` != \"Combined Assembly\") |> \n  \n  separate(`dnaSampleID`, c(\"dnaSampleID.site\",\"dnaSampleID.sub\"), \"_\", remove=FALSE) |> \n  \n  mutate_at(\"dnaSampleID.sub\", str_replace, \"-COMP\", \"_COMP\") |>\n  mutate_at(\"dnaSampleID.sub\", str_replace, \"-GEN\", \"_GEN\") |>\n  separate(`dnaSampleID.sub`, c(\"dnaSampleID.sub\",\"dnaSampleID.type\"), \"_\") |> \n  \n  mutate_at(\"dnaSampleID.sub\", str_replace, \"-M\", \"_M\") |>\n  mutate_at(\"dnaSampleID.sub\", str_replace, \"-O\", \"_O\") |>\n  separate(`dnaSampleID.sub`, c(\"dnaSampleID.plot\",\"dnaSampleID.sub\"), \"_\") |> \n  \n  mutate_at(\"dnaSampleID.sub\", str_replace, \"M-\", \"M_\") |>\n  mutate_at(\"dnaSampleID.sub\", str_replace, \"O-\", \"O_\") |>\n  separate(`dnaSampleID.sub`, c(\"dnaSampleID.layer\",\"dnaSampleID.sub\"), \"_\") |> \n\n  mutate_at(\"dnaSampleID.sub\", str_replace, \"-201\", \"201\") |>\n  mutate_at(\"dnaSampleID.sub\", str_replace, \"-202\", \"202\") |>\n  mutate_at(\"dnaSampleID.sub\", str_replace, \"201\", \"_201\") |>\n  mutate_at(\"dnaSampleID.sub\", str_replace, \"202\", \"_202\") |>\n  separate(`dnaSampleID.sub`, c(\"dnaSampleID.subplot\",\"dnaSampleID.date\"), \"_\") |> \n\n  unite(plotID, c(dnaSampleID.site, dnaSampleID.plot), sep='_', remove=FALSE)\n\nneon.metaDB.my.soil$dnaSampleID.data <- as.numeric(neon.metaDB.my.soil$dnaSampleID.date)\nneon.metaDB.my.soil$dnaSampleID.date <- ymd(neon.metaDB.my.soil$dnaSampleID.date)\n\n\nTo reformat dnasampleID column for aquatic samples\n\n\nR code\nneon.metaDB.my.aquatic <- neon.metaDB.my |> \n  filter(`Ecosystem Category` == \"Aquatic\") |> \n  filter(`GOLD Analysis Project Type` != \"Combined Assembly\") |> \n  \n  mutate(dnaSampleID.sub = dnaSampleID) |> \n  mutate_at(\"dnaSampleID.sub\", str_replace, \".202\", \"_202\") |>\n  separate(`dnaSampleID.sub`, c(\"dnaSampleID.site\",\"dnaSampleID.sub\"), \"_\") |> \n  separate(`dnaSampleID.site`, c(\"dnaSampleID.site\",\"dnaSampleID.code\"), \"\\\\.\") |> \n  \n  mutate_at(\"dnaSampleID.sub\", str_replace, \".DNA\", \"_DNA\") |>\n  separate(`dnaSampleID.sub`, c(\"dnaSampleID.sub\",\"dnaSampleID.type\"), \"_\") |> \n  \n  separate(`dnaSampleID.sub`, c(\"dnaSampleID.data\",\"dnaSampleID.niche\", \"dnaSampleID.num\"), \"\\\\.\") |> \n\n  unite(dnaSampleID.niche, c(dnaSampleID.code, dnaSampleID.niche)) |> \n  mutate_at(\"dnaSampleID.niche\", str_replace, \"NA_\", \"\") |>\n  mutate_at(\"dnaSampleID.niche\", str_replace, \"_NA\", \"\")\n\n\n\n\nHARV metagenomes by year and plot\n\n\nR code\ndatatable(\nneon.metaDB.my.soil |> \n  filter(siteID == \"HARV\") |> \n  group_by(Year = lubridate::year(collectDate), dnaSampleID.plot) |> \n  count() |> \n  pivot_wider(names_from = dnaSampleID.plot, values_from = n) |> \n  mutate_all(funs(replace_na(.,0)))\n)\n\n\n\n\n\n\n\n\n\nWREF metagenomes by year and plot\n\n\nR code\ndatatable(\nneon.metaDB.my.soil |> \n  filter(siteID == \"WREF\") |> \n  group_by(Year = lubridate::year(collectDate), dnaSampleID.plot) |> \n  count() |> \n  pivot_wider(names_from = dnaSampleID.plot, values_from = n) |> \n  mutate_all(funs(replace_na(.,0)))\n)\n\n\n\n\n\n\n\n\n\nPlot of HARV samples per plot per year\n\n\nR code\nneon.metaDB.my.soil |> \n  filter(siteID == \"HARV\") |> \n  group_by(Year = lubridate::year(collectDate), dnaSampleID.plot) |> \n  count() |> \n  pivot_wider(names_from = dnaSampleID.plot, values_from = n) |> \n  mutate_all(funs(replace_na(.,0))) |> \n  pivot_longer(!Year, names_to = \"plot\", values_to = \"metagenomes\") |> \n  ggplot(aes(x=Year, y = plot)) +\n  geom_tile(aes(fill = metagenomes)) +\n  scale_fill_viridis(discrete=FALSE, direction = -1) +\n  scale_x_continuous(breaks = seq(2013, 2023, by = 1)) \n\n\n\n\n\n\n\nMissing years at HARV\nAll sites are missing data from 2021 and 2022. That should be in IMG soon. What about 2018?\n\nCollectDate\n\n\nR code\nneon.metaDB.my.soil |> \n  group_by(Year = lubridate::year(collectDate)) |> \n  count() \n\n\n# A tibble: 9 × 2\n# Groups:   Year [9]\n   Year     n\n  <dbl> <int>\n1  2013    63\n2  2014   106\n3  2016   229\n4  2017   326\n5  2018    45\n6  2019   231\n7  2020   185\n8  2021   117\n9  2023   303\n\n\n\n\ndnaSampleID.date\n\n\nR code\nneon.metaDB.my.soil |> \n  group_by(Year = lubridate::year(dnaSampleID.date)) |> \n  count() \n\n\n# A tibble: 9 × 2\n# Groups:   Year [9]\n   Year     n\n  <dbl> <int>\n1  2013    63\n2  2014   106\n3  2016   229\n4  2017   326\n5  2018    45\n6  2019   231\n7  2020   185\n8  2021   117\n9  2023   303\n\n\n\n\n\nPlot of samples per plot per year at all sites\n\n\nR code\nneon.metaDB.my.soil |> \n  group_by(siteID, Year = lubridate::year(collectDate), dnaSampleID.plot) |> \n  count() |> \n  pivot_wider(names_from = Year, values_from = n) |> \n  mutate_all(funs(replace_na(.,0))) |> \n  pivot_longer(!c(siteID, dnaSampleID.plot), names_to = \"Year\", values_to = \"metagenomes\") |> \n  ggplot(aes(x=Year, y = dnaSampleID.plot)) +\n  geom_tile(aes(fill = metagenomes)) +\n  scale_fill_viridis(discrete=FALSE, direction = -1) +\n # scale_x_continuous(breaks = seq(2013, 2023, by = 1)) +\n  facet_wrap(~siteID, scales =\"free_y\", ncol = 3) +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))"
  },
  {
    "objectID": "methods/Access_NEON_Data_for_Metagenomics.html",
    "href": "methods/Access_NEON_Data_for_Metagenomics.html",
    "title": "Access NEON Data for Metagenomics",
    "section": "",
    "text": "From Access NEON Data for Metagenomics See * Update on the changing NEON microbial data * Soil microbe metagenome sequences\nInstall packages\n\n\nR code\ninstall.packages(\"neonUtilities\")\ninstall.packages(\"neonOS\")\n\n\n\n\nR code\nlibrary(neonUtilities)\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(DT)\nlibrary(viridis)\n\n\n\n\nR code\nsoilTrialSites = c(\"BONA\",\"DEJU\",\"HEAL\",\"TOOL\",\"BARR\")\nsoilTrialSites = c(\"HARV\")\n\n\nsoilChem <- loadByProduct(\n  dpID='DP1.10086.001',\n  startdate = \"2017-01\",\n  enddate = \"2019-12\",\n  check.size = FALSE,\n  site = soilTrialSites,\n  package='expanded')\n\n\n\n\nR code\nView(soilChem$sls_metagenomicsPooling)\n\n\n\n\nR code\nmetaGdata <- loadByProduct(dpID = 'DP1.10107.001',\n\n                          check.size = FALSE,\n\n                          package = 'expanded') \n\n\n\n\nR code\nmetaGdata_mms_metagenomeSequencing <- metaGdata$mms_metagenomeSequencing\nwrite_csv(metaGdata_mms_metagenomeSequencing, \"../data/NEON_metadata/metaGdata_mms_metagenomeSequencing.csv\")\n\n\nThis has HARV data collected up until 2022. The 2021 and 2022 data are not in the phyloNEON data.\n\n\nR code\nmetaGdata_mms_metagenomeSequencing_HARV <- metaGdata$mms_metagenomeSequencing |> \nwrite_csv(metaGdata_mms_metagenomeSequencing_HARV, \"../data/NEON_metadata/metaGdata_mms_metagenomeSequencing_HARV.csv\")\n\n\n\nRead in saved file (all above in eval = FALSE)\n\n\nR code\nmetaGdata_mms_metagenomeSequencing <- read_csv(\"../data/NEON_metadata/metaGdata_mms_metagenomeSequencing.csv\")\n\n\n\n\nCreate data frame from dnaSampleID\n\n\nR code\nmetaGdata_dnaSampleID <- metaGdata_mms_metagenomeSequencing |> \n  select(dnaSampleID)\n\n# Read in 2023 and 2024 data that is not in the metagenome data product yet\n\nneon_ay23_jgi_samples <- read_csv(\"../data/NEON_metadata/neon_ay23_jgi_samples_soil.csv\")\nneon_ay24_jgi_samples <- read_csv(\"../data/NEON_metadata/neon_ay24_jgi_samples_soil.csv\")\n\nneon_dnaSampleID <- rbind(metaGdata_dnaSampleID, neon_ay23_jgi_samples, neon_ay24_jgi_samples)\n\n\n\nFull table\n\n\nR code\nneon_dnaSampleID_split <- neon_dnaSampleID |> \n\n  separate(`dnaSampleID`, c(\"dnaSampleID.site\",\"dnaSampleID.sub\"), \"_\", remove=FALSE) |> \n  \n  mutate_at(\"dnaSampleID.sub\", str_replace, \"-comp\", \"_COMP\") |>\n  mutate_at(\"dnaSampleID.sub\", str_replace, \"-COMP\", \"_COMP\") |>\n  mutate_at(\"dnaSampleID.sub\", str_replace, \"-GEN\", \"_GEN\") |>\n  separate(`dnaSampleID.sub`, c(\"dnaSampleID.sub\",\"dnaSampleID.type\"), \"_\") |> \n  \n  mutate_at(\"dnaSampleID.sub\", str_replace, \"-M\", \"_M\") |>\n  mutate_at(\"dnaSampleID.sub\", str_replace, \"-O\", \"_O\") |>\n  separate(`dnaSampleID.sub`, c(\"dnaSampleID.plot\",\"dnaSampleID.sub\"), \"_\") |> \n  \n  mutate_at(\"dnaSampleID.sub\", str_replace, \"M-\", \"M_\") |>\n  mutate_at(\"dnaSampleID.sub\", str_replace, \"O-\", \"O_\") |>\n  separate(`dnaSampleID.sub`, c(\"dnaSampleID.layer\",\"dnaSampleID.sub\"), \"_\") |> \n\n  mutate_at(\"dnaSampleID.sub\", str_replace, \"-201\", \"201\") |>\n  mutate_at(\"dnaSampleID.sub\", str_replace, \"-202\", \"202\") |>\n  mutate_at(\"dnaSampleID.sub\", str_replace, \"2013\", \"_2013\") |>\n  mutate_at(\"dnaSampleID.sub\", str_replace, \"2014\", \"_2014\") |>\n  mutate_at(\"dnaSampleID.sub\", str_replace, \"2015\", \"_2015\") |>\n  mutate_at(\"dnaSampleID.sub\", str_replace, \"2016\", \"_2016\") |>\n  mutate_at(\"dnaSampleID.sub\", str_replace, \"2017\", \"_2017\") |>\n  mutate_at(\"dnaSampleID.sub\", str_replace, \"2018\", \"_2018\") |>\n  mutate_at(\"dnaSampleID.sub\", str_replace, \"2019\", \"_2019\") |>\n  mutate_at(\"dnaSampleID.sub\", str_replace, \"2020\", \"_2020\") |>\n  mutate_at(\"dnaSampleID.sub\", str_replace, \"2021\", \"_2021\") |>\n  mutate_at(\"dnaSampleID.sub\", str_replace, \"2022\", \"_2022\") |>\n  mutate_at(\"dnaSampleID.sub\", str_replace, \"2023\", \"_2023\") |>\n  mutate_at(\"dnaSampleID.sub\", str_replace, \"2024\", \"_2024\") |>\n  separate(`dnaSampleID.sub`, c(\"dnaSampleID.subplot\",\"dnaSampleID.date\"), \"_\") |> \n\n  unite(plotID, c(dnaSampleID.site, dnaSampleID.plot), sep='_', remove=FALSE)\n\nneon_dnaSampleID_split$dnaSampleID.date <- as.numeric(neon_dnaSampleID_split$dnaSampleID.date)\nneon_dnaSampleID_split$dnaSampleID.date <- ymd(neon_dnaSampleID_split$dnaSampleID.date)\n\n\n\n\nFull table\n\n\nR code\nmetaGdata_mms_metagenomeSequencing <- metaGdata_mms_metagenomeSequencing |> \n\n  separate(`dnaSampleID`, c(\"dnaSampleID.site\",\"dnaSampleID.sub\"), \"_\", remove=FALSE) |> \n  \n  mutate_at(\"dnaSampleID.sub\", str_replace, \"-comp\", \"_COMP\") |>\n  mutate_at(\"dnaSampleID.sub\", str_replace, \"-COMP\", \"_COMP\") |>\n  mutate_at(\"dnaSampleID.sub\", str_replace, \"-GEN\", \"_GEN\") |>\n  separate(`dnaSampleID.sub`, c(\"dnaSampleID.sub\",\"dnaSampleID.type\"), \"_\") |> \n  \n  mutate_at(\"dnaSampleID.sub\", str_replace, \"-M\", \"_M\") |>\n  mutate_at(\"dnaSampleID.sub\", str_replace, \"-O\", \"_O\") |>\n  separate(`dnaSampleID.sub`, c(\"dnaSampleID.plot\",\"dnaSampleID.sub\"), \"_\") |> \n  \n  mutate_at(\"dnaSampleID.sub\", str_replace, \"M-\", \"M_\") |>\n  mutate_at(\"dnaSampleID.sub\", str_replace, \"O-\", \"O_\") |>\n  separate(`dnaSampleID.sub`, c(\"dnaSampleID.layer\",\"dnaSampleID.sub\"), \"_\") |> \n\n  mutate_at(\"dnaSampleID.sub\", str_replace, \"-201\", \"201\") |>\n  mutate_at(\"dnaSampleID.sub\", str_replace, \"-202\", \"202\") |>\n  mutate_at(\"dnaSampleID.sub\", str_replace, \"201\", \"_201\") |>\n  mutate_at(\"dnaSampleID.sub\", str_replace, \"202\", \"_202\") |>\n  separate(`dnaSampleID.sub`, c(\"dnaSampleID.subplot\",\"dnaSampleID.date\"), \"_\") |> \n\n  unite(plotID, c(dnaSampleID.site, dnaSampleID.plot), sep='_', remove=FALSE)\n\nmetaGdata_mms_metagenomeSequencing$dnaSampleID.data <- as.numeric(metaGdata_mms_metagenomeSequencing$dnaSampleID.date)\nmetaGdata_mms_metagenomeSequencing$dnaSampleID.date <- ymd(metaGdata_mms_metagenomeSequencing$dnaSampleID.date)\n\n\n\n\n\nPlot of HARV samples per plot per year\n\n\nR code\nneon_dnaSampleID_split |> \n  filter(dnaSampleID.site == \"HARV\") |> \n  group_by(Year = lubridate::year(dnaSampleID.date), dnaSampleID.plot) |> \n  count() |> \n  pivot_wider(names_from = dnaSampleID.plot, values_from = n) |> \n  mutate_all(funs(replace_na(.,0))) |> \n  pivot_longer(!Year, names_to = \"plot\", values_to = \"metagenomes\") |> \n  ggplot(aes(x=Year, y = plot)) +\n  geom_tile(aes(fill = metagenomes)) +\n  scale_fill_viridis(discrete=FALSE, direction = -1) +\n  scale_x_continuous(breaks = seq(2013, 2024, by = 1)) \n\n\n\n\n\n\n\nPlot of samples per plot per year at all sites\n\n\nR code\nneon_dnaSampleID_split |> \n  group_by(dnaSampleID.site, Year = lubridate::year(dnaSampleID.date), dnaSampleID.plot) |> \n  count() |> \n  pivot_wider(names_from = Year, values_from = n) |> \n  mutate_all(funs(replace_na(.,0))) |> \n  pivot_longer(!c(dnaSampleID.site, dnaSampleID.plot), names_to = \"Year\", values_to = \"metagenomes\") |> \n  ggplot(aes(x=Year, y = dnaSampleID.plot)) +\n  geom_tile(aes(fill = metagenomes)) +\n  scale_fill_viridis(discrete=FALSE, direction = -1) +\n  facet_wrap(~dnaSampleID.site, scales =\"free_y\", ncol = 3) +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) \n\n\n\n\n\n\n\nTable of mean sampleFilteredReadNumber\nAbout 3-5x increase in reads in 2021 and 2022 About 10-20x increase in 2023 over 2021 and 2022\n\n\nR code\nmetaGdata_mms_metagenomeSequencing |> \n  filter(dnaSampleID.site == \"HARV\") |> \n  group_by(Year = lubridate::year(collectDate)) |> \n  summarize(mean_sampleFilteredReadNumber = mean(sampleFilteredReadNumber))\n\n\n# A tibble: 8 × 2\n   Year mean_sampleFilteredReadNumber\n  <dbl>                         <dbl>\n1  2013                           NA \n2  2016                      6643162.\n3  2017                      5038437 \n4  2018                      2633512.\n5  2019                      4560748.\n6  2020                      3468523.\n7  2021                     16005210.\n8  2022                     19339618.\n\n\n\n\nTable of mean sampleTotalReadNumber\nAbout 3-5x increase in reads in 2021 and 2022 About 10-20x increase in 2023 over 2021 and 2022\n\n\nR code\nmetaGdata_mms_metagenomeSequencing |> \n  filter(dnaSampleID.site == \"HARV\") |> \n  group_by(Year = lubridate::year(collectDate)) |> \n  summarize(mean_sampleTotalReadNumber = mean(sampleTotalReadNumber))\n\n\n# A tibble: 8 × 2\n   Year mean_sampleTotalReadNumber\n  <dbl>                      <dbl>\n1  2013                   9270681.\n2  2016                  10802077.\n3  2017                  11456008.\n4  2018                   6664285.\n5  2019                   5442366.\n6  2020                   4674903 \n7  2021                  27270286.\n8  2022                  31374636."
  },
  {
    "objectID": "labs/lab1_overview.html",
    "href": "labs/lab1_overview.html",
    "title": "Lab 1 - Overview & Getting Started",
    "section": "",
    "text": "What is bioinformatics?\nWhat is reproducible research?\nWhy learn bioinformatics and data science skills?\nHigh Performance Computing (Unity)\nOverview of the R statistical programming language\n\n\n\n\nIn recent years, the field of genomic analysis and bioinformatics has sifted towards requiring some knowledge of R, Python/Perl/C and the use of high performance computers (often requiring some fundamental Unix skills) available at national computing centers for working with large data sets. While there are many great software packages available for particular computational problems in evolutionary biology, many software programs do not have a user interface (e.g. drop down menus and such) and are run in command line mode. The lab sessions in this course have been designed to give students an introduction to working with R and packages used for genome and metagenome analyses. We are using recently release National Ecological Observatory Network data to design a course-based Undergraduate Research Experience (CURE). The first 4 weeks we will discuss to project space, discuss research ideas and formulate testable hypothesis or discovery driven approaches, design the experimental approaches. For a preview today I will give an overview of the project space.\n\n\n\nBioinformatics is the field of science in which biology, computer science, statistics and information technology merge into a single discipline. There are three important sub-disciplines within bioinformatics:\n\nThe development of new algorithms and statistics with which to assess relationships among members of large data sets.\nThe development and implementation of tools that enable efficient access and management of different types of information.\nThe analysis and interpretation of various types of data including nucleotide and amino acid sequences, protein domains, and protein structures.\n\n\n\n\nis a term coined in response to the high demand of techniques and resources for handling the explosion of molecular data.\nis a buzzword to describe a growing field.\nbenefits from the physicists, chemists and mathematicians crossing over into biology.\nis a collection of tools.\nis way of thinking about a problem!\n\n\n\n\nIn order to make new algorithms and data sources available to biologists someone needs to write applications that include these algorithms and create new databases. Often this is first done by academic research groups. Later redone by private companies when market is large and profitable enough. There is a large gap between what is done by research groups and companies. Sometimes this is filled by large government funded projects, but not usually in time for most researchers. This is why bioinformatics and programming skills have become very valuable.\n\n\n\n\nThe field of data science has grown tremendously over the last decade and the two programming languages, R and Python, used in analyzing genomic data are the most popular languages for data science. This made it easy to transfer bioinformatics skills to diverse fields.\nHere a few links that I will go over in lab:\n\nWhat is Data Science? \n\nWhat is Data Science? 8 Skills That Will Get You Hired\n\nOpen Science is Kinder Science\n\nData Carpentry\n\nBuilding a local community of practice in scientific programming for life scientists\n\n\n\n\nR is the largest and most comprehensive public domain statistical computing environment. The core R package is enhanced by several hundred user-supplied add-on packages, including many for gene expression analysis, in the  Comprehensive R Archive Network (CRAN). Omegahat Project for Statistical Computing.  BioConductor is an open source and open development software project for the analysis and comprehension of genomic data and is based primarily on the R programming language. R and Bioconductor are free, Open Source and available for Windows, MacOS and a wide variety of UNIX platforms.\n\n\nReproducibility is the hallmark of science, which is based on empirical observations coupled with explanatory models. While reproducibility encompasses the full science lifecycle, and includes issues such as methodological consistency and treatment of bias, in this course we will focus on computational reproducibility: the ability to document data, analyses, and models sufficiently for other researchers to be able to understand and ideally re-execute the computations that lead to scientific results and conclusions. With current publishing practices, this can be difficult because data are typically unavailable, the method sections of papers do not detail the computational approaches used, and analyses and models are often conducted in graphical programs, or, when scripted analyses are employed, the code is not available. In this course we will learn how to write code that is integrated into reproducible reports.\n\n\n\nMany introductory and advance tutorials have been developed for R. Here are a few\n\nThe offical R manuals\nCRAN’s Introduction to R\nR for Data Science by Garrett Grolemund and Hadley Wickham\nR Graphics Cookbook by Winston Chang\nData Carpentries Genomic Workshop Sessions\nData Analysis and Visualization in R for Ecologists\n\nThere are also many workshops and online R courses that you could take to follow up what you learn in this class.\n\n\n\n\nGitHub has become a popular way to manage, share and view code for open source projects. The tutorials created for this course will be written in Quarto and posted on GitHub. Thus, you will be able to continue to see course materials after the end of the semester. You will use and make a GitHub web site for your research project.\n\n\n\nYou all are part of the first generation of generative AI users. The saying goes “AI won’t take your job, but someone using who knows how to use AI might.” Think of AI as a force multiplier. You have to learn to code and clearly state your problems before AI can to help you. This class will fully use generative AI in hopes that it will challenge us to think more creatively about problems and not stress out about syntax. Think first…ask questions…code…solve problem! We will use the UMass version of Microsoft Copilot Chat and Copilot integrated into RStudio. We will embrace “Vibe coding” (see What is Vibe Coding, Exactly?) and ride the waves.\n\n\n\nIn this course we will learn to write basic unix commands, run bioinformatics software from the command line and allocate computer resources for submitting large jobs. UMass has modern High Performance Computing system, Unity, and excellent staff members to help get you going and trouble shoot issues. Working on HPCs has become much easier with the advent of web interfaces that look and work much like software running on your computer.\n\n\n\nYou can do all of the R-based labs on your own computer. Follow these directions by the makers of RStudio, Posit. You will need to download the lab files from Unity or the course GitHub site."
  },
  {
    "objectID": "labs/lab_AI_R.html",
    "href": "labs/lab_AI_R.html",
    "title": "Learning R with the help of AI tools",
    "section": "",
    "text": "AI won’t take your job, but someone using who knows how to use AI might. Think of AI as a force multiplier. You have to learn to code first before you can use AI to help you. Google recently reported that about 25% of its new code is AI-generated.\nMicrosoft designed Copilot to work off of the latest version of OpenAI’s GPT model, GPT-4,\n\ngithub co-pilot - https://github.com/copilot\ngithub education - https://github.com/education\nRStudio github copilot - https://docs.posit.co/ide/user/ide/guide/tools/copilot.html\nMicrosoft Introduction to GitHub Copilot - https://learn.microsoft.com/en-us/training/modules/introduction-to-github-copilot/\nIntroduction to GitHub CoPilot videos - https://learn.microsoft.com/en-us/shows/introduction-to-github-copilot/\nSet up co-pilot for learning - https://docs.github.com/en/get-started/learning-to-code/setting-up-copilot-for-learning-to-code\nHow to write better prompts for GitHub Copilot - https://github.blog/developer-skills/github/how-to-write-better-prompts-for-github-copilot/\nAI Assisted Coding in RStudio - https://research-it.manchester.ac.uk/news/2024/11/29/ai-assisted-coding-in-rstudio/\nRTutor AI - https://rtutor.ai/\nSyntha AI - https://syntha.ai/code-generators/r\nR Code Generator - https://codingfleet.com/code-generator/r/\nLearning the tidyverse with the help of AI tools - https://www.tidyverse.org/blog/2025/04/learn-tidyverse-ai/\nIntroducing vitals, a toolkit for evaluating LLM products in R - https://www.tidyverse.org/blog/2025/06/vitals-0-1-0/\nUsing AI with R - https://rfortherestofus.com/courses/ai\nBoost Your R Skills with AI - https://artscience.ai/boost-your-r-skills-with-ai/\nBeginner’s Tutorial for the OpenAI API in R - https://tilburg.ai/2024/03/tutorial-openai-api-in-r/\nCodex - https://chatgpt.com/codex\n\nAI Assisted Coding in RStudio - https://research-it.manchester.ac.uk/news/2024/11/29/ai-assisted-coding-in-rstudio/ Integrating OpenAI’s ChatGPT into RStudio is now possible with “Chattr”, “GPT Studio” and “GitHub Copilot”. These new tools will help you find the right functions and commands and to quickly generate code snippets to save you time.\n8 ChatGPT packages for R - https://www.infoworld.com/article/2338386/8-chatgpt-tools-for-r-programming.html\n\nVibe coding https://www.geeksforgeeks.org/techtips/what-is-vibe-coding/\nWhat is vibe coding, exactly? - https://www.technologyreview.com/2025/04/16/1115135/what-is-vibe-coding-exactly/\nWhat Is Vibe Coding? Definition, Tools, Pros, and Cons - https://www.datacamp.com/blog/vibe-coding\nYou can use GitHub and Git to collaborate on work. https://docs.github.com/en/get-started/start-your-journey/about-github-and-git\nUsing co-pilot as your tutor - https://docs.github.com/en/get-started/learning-to-code/setting-up-copilot-for-learning-to-code\nchattr - https://mlverse.github.io/chattr/\n\nBioinformatics and AI * A data-intelligence-intensive bioinformatics copilot system for large-scale omics research and scientific insights - https://academic.oup.com/bib/article/26/4/bbaf312/8196318?login=true * Bioinformatics AI: Driving Future Biological Breakthroughs - https://biologyinsights.com/bioinformatics-ai-driving-future-biological-breakthroughs/"
  },
  {
    "objectID": "labs/lab1_rstudio.html",
    "href": "labs/lab1_rstudio.html",
    "title": "Lab 1 : Introduction to R and Reproducible Research",
    "section": "",
    "text": "The RStudio Integrated Development Environment\nThe Quarto scientific publishing system\nWorking in R coding chunks in Quarto\nReading error messages\n\n\n\nThe most popular way to write R programs and to interactively run code and create graphs is using the RStudio Integrated Devopement Environment (IDE). It is open source software that is available for free. There are other ways to write and run R code, such as using text editors, VS Code editors, Neovim or Jupyter Notebooks, but we will focus on RStudio in this class.\n\n\nI run R and RStudio on my computer. You can too. Most of the basics R labs for the class you should be able to do from your laptop.\n\nInstall the latest release (2025-06-13, Great Square Root) R-4.5.1 of R from CRAN and follow the installation instructions. If you have an older verion of R on your computer please update to this release as we can’t guarantee the labs will work on older versions.\nInstall R Studio, a nice graphical interface for working with R.\nOpen RStudio and install tidyverse under Tools &gt; Install Packages. You will need to install other packages as well for this and future labs."
  },
  {
    "objectID": "labs/lab1_rstudio.html#learning-objectives",
    "href": "labs/lab1_rstudio.html#learning-objectives",
    "title": "Lab 1 : Introduction to R and Reproducible Research",
    "section": "",
    "text": "The RStudio Integrated Development Environment\nThe Quarto scientific publishing system\nWorking in R coding chunks in Quarto\nReading error messages\n\n\n\nThe most popular way to write R programs and to interactively run code and create graphs is using the RStudio Integrated Devopement Environment (IDE). It is open source software that is available for free. There are other ways to write and run R code, such as using text editors, VS Code editors, Neovim or Jupyter Notebooks, but we will focus on RStudio in this class.\n\n\nI run R and RStudio on my computer. You can too. Most of the basics R labs for the class you should be able to do from your laptop.\n\nInstall the latest release (2025-06-13, Great Square Root) R-4.5.1 of R from CRAN and follow the installation instructions. If you have an older verion of R on your computer please update to this release as we can’t guarantee the labs will work on older versions.\nInstall R Studio, a nice graphical interface for working with R.\nOpen RStudio and install tidyverse under Tools &gt; Install Packages. You will need to install other packages as well for this and future labs."
  },
  {
    "objectID": "labs/lab1_rstudio.html#overview",
    "href": "labs/lab1_rstudio.html#overview",
    "title": "Lab 1 : Introduction to R and Reproducible Research",
    "section": "Overview",
    "text": "Overview\nIn recent years, the field of genomic analysis has sifted towards requiring some knowledge of R, Python/Perl/C and the use of high performance computers (often requiring some fundamental Unix skills) available at national computing centers for working with large data sets. While there are many great software packages available for particular computational problems in evolutionary biology, many software programs do not have a user interface (e.g. drop down menus and such) and are run in command line mode. The lab sessions in this course have been designed to give students an introduction to working with R and packages used for Human Genome Analysis.\nThe lab course is divided into 3 parts\n\nIntroduction to R and the tidyverse\nGene Expression Analysis\nAnalysis of SNPs and your genetic data"
  },
  {
    "objectID": "labs/lab1_rstudio.html#reproducible-research",
    "href": "labs/lab1_rstudio.html#reproducible-research",
    "title": "Lab 1 : Introduction to R and Reproducible Research",
    "section": "Reproducible Research",
    "text": "Reproducible Research\nReproducibility is the hallmark of science, which is based on empirical observations coupled with explanatory models. While reproducibility encompasses the full science lifecycle, and includes issues such as methodological consistency and treatment of bias, in this course we will focus on computational reproducibility: the ability to document data, analyses, and models sufficiently for other researchers to be able to understand and ideally re-execute the computations that lead to scientific results and conclusions. With current publishing practices, this can be difficult because data are typically unavailable, the method sections of papers do not detail the computational approaches used, and analyses and models are often conducted in graphical programs, or, when scripted analyses are employed, the code is not available. In this course we will learn how to write code that is integrated into reproducible reports."
  },
  {
    "objectID": "labs/lab1_rstudio.html#data-science",
    "href": "labs/lab1_rstudio.html#data-science",
    "title": "Lab 1 : Introduction to R and Reproducible Research",
    "section": "Data Science",
    "text": "Data Science\nHere a few links that I will go over in lab:\n\nWhat is Data Science? \n\nWhat is Data Science? 8 Skills That Will Get You Hired\n\nOpen Science is Kinder Science\n\nData Carpentry\n\nBuilding a local community of practice in scientific programming for life scientists"
  },
  {
    "objectID": "labs/lab1_rstudio.html#r",
    "href": "labs/lab1_rstudio.html#r",
    "title": "Lab 1 : Introduction to R and Reproducible Research",
    "section": "R",
    "text": "R\nR is the largest and most comprehensive public domain statistical computing environment. The core R package is enhanced by several hundred user-supplied add-on packages, including many for gene expression analysis, in the  Comprehensive R Archive Network (CRAN). Omegahat Project for Statistical Computing.  BioConductor is an open source and open development software project for the analysis and comprehension of genomic data and is based primarily on the R programming language. R and Bioconductor are free, Open Source and available for Windows, MacOS and a wide variety of UNIX platforms.\n\nThe RStudio Integrated Devopement Environment (IDE)\nThe most popular way to write R programs and to interactively run code and create graphs is using the RStudio Integrated Devopement Environment (IDE). It is open source software that is available for free. There are other ways to write and run R code, such as using text editors, VS Code editors, Neovim or Jupyter Notebooks, but we will focus on RStudio in this class.\n\n\nR manuals, help and tutorials\nMany introductory and advance tutorials have been developed for R. Here are a few\n\nThe offical R manuals\nCRAN’s Introduction to R\nR for Data Science by Garrett Grolemund and Hadley Wickham\nR Graphics Cookbook by Winston Chang\nData Carpentries Genomic Workshop Sessions\nData Analysis and Visualization in R for Ecologists\n\nThere are also many workshops and online R courses that you could take to follow up what you learn in this class."
  },
  {
    "objectID": "labs/lab1_rstudio.html#on-the-computer",
    "href": "labs/lab1_rstudio.html#on-the-computer",
    "title": "Lab 1 : Introduction to R and Reproducible Research",
    "section": "On the Computer",
    "text": "On the Computer\n\nGetting started on Unity\nUnity https://unity.rc.umass.edu/ is the UMass High Performance Computing cluster. We will be running bioinformatics software and using R and RStudio from the Unity HPC.\n\n\nWorking in RStudio\nThe default R studio appearance includes 4 windows.\n\nThe R script(s) and data view (upper left window).\nConsole (bottom left window).\nWorkspace and history (upper right window).\nFiles, plots, packages and help (botton right window).\n\n\n\n\nRStudio Screenshot\n\n\n\nThe R script(s) and data view window (upper left window)\nIn this window you can type directly into a file, run code and save the file for reuse. In this class we will work with Quarto files (discussed below).\n\n\nConsole Window (bottom left window)\nThe console is where you can type R commands and see output.\nType\n3 + 3\nTo better document and save your code write it in the Quarto documents rather than the console. On occasion we will use the console to access documentation and for other purposes.\n\n\nEnvironment and History tabs (upper right window)\nThe Environment tab shows all the active objects. If you have a data frame loaded, then click on the object will enable you to view the table. The History tab shows a list of commands used so far.\n\n\nFiles, Plots, Packages and Help (bottom right window)\nThere are data sets that come with the R package and used in tutorials. If you run the following command you will see a graph of related to the cars data set in the Plots window\n\n\n\nQuarto\nThe Quarto is a scientific publishing system. In this class we will use one of it’s simplest features, producing a report with the code and resulting output (graphs, tables, statistical analysis). Quarto can also be used to produce slides, web sites, scientific manuscripts and books. For example, and all the labs for this course and my research laboratory website were made using Quarto. Quarto wraps together many previous packages used for publishing with R.\nTo use Quarto with R, the rmarkdown R package is installed. There are some differences between a Quarto and R Markdown document, but overall they are very similar.\n\nProducing Lab Reports with Quarto\nIn RStudio select File &gt; New File &gt; Quarto Document. Add a title (e.g. Lab 1) and your name then create the document. Notice the your file says untitled with an asterisk. Save your file (e.g. lab1). This will automatically add the .qmd extension to your file (lab1.qmd). ALWAYS SAVE YOUR FILE BEFORE YOU START WORKING AND OFTEN WHILE WORKING.\nThe top section of the document delineated by the --- is called the YAML block. In this template it contains your the title, your name, the output type (html) and the editor preference (visual).You can also work with your file directly with the source code by clicking the source icon.\nThe following lines of code in your YAML block with generate a table of contents (toc) as shown at the top of this lab. The line with embed-resources creates a stand alone html file.\n---\ntitle: \"Lab 1\"\nauthor: \"Jeff Blanchard\"\nformat:\n  html:\n    toc: true\n    toc_float: true\n    embed-resources: true\neditor: visual\n---\nThe text with the white background is in rmarkdown. The icons in the same section as the visual icon you can easily made the text in bold or in italics, change the text from normal to a header, create bulleted or numbered lists, insert html links, add images, insert tables and more.\nThe text with the gray background is in R code chunks. Click on the green play icon in the top right corner of the code chunk to run the code.\nClick on the Render icon. This will run the code, show the output and create a html file that is automatically saved to your directory (look for the lab1.html file) and will automatically open this file in your browser.\nCreate new code chunk by clicking on the green +C icon to the right of the Render icon. In the code chunk type plot(cars). Then click the run the code to see a graph of the cars data set that comes preloaded into R.\n\n\nR code\nplot(cars)"
  },
  {
    "objectID": "labs/lab1_rstudio.html#writing-r-code",
    "href": "labs/lab1_rstudio.html#writing-r-code",
    "title": "Lab 1 : Introduction to R and Reproducible Research",
    "section": "Writing R code",
    "text": "Writing R code\n\nAssignment statements\nAll R statements where you create objects are called assignment statements and the form “object_name &lt;- value”\n\n\nR code\nx &lt;- 3\n\n\nSimply typing x will give the value of x\n\n\nR code\nx\n\n\n[1] 3\n\n\nYou will make lots of assignments and &lt;- is a pain to type. Instead, use RStudio’s keyboard shortcut: Alt + - (the minus sign). Notice that RStudio automagically surrounds &lt;- with spaces, which is a good code formatting practice. An equals sign = will work in place of &lt;-, but it will cause confusion later so keep to the convention of using &lt;- to make assignments\n\n\nObject Names\nObject names must start with a letter, and can only contain letters, numbers, underscores and periods. You want your object names to be descriptive, so you’ll need a convention for multiple words. I recommend snake_case where you separate lowercase words with an underscore. Note that R is case sensitive, e.g., object names gene, GENE, Gene are all different.\n\n\nR code\ngenome_size &lt;- 3100000000\n\n\nImportant note: since there are many built-in functions in R, make sure that the new object names you assign are not already used by the system. A simple way of checking this is to type in the name you want to use. If the system returns an error message telling you that such object is not found, it is safe to use the name.\n\n\nCharacters\nA character object is used to represent string values in R. It is defined by double quotes ““.\n\n\nR code\nDNA &lt;- \"ATGAAA\"\nDNA\n\n\n[1] \"ATGAAA\"\n\n\n\n\nVectors\nA vector is a sequence of data elements of the same basic type. data elements in a vector are officially called components. Assignment operator (&lt;-) stores the value (object) on the right side of (&lt;-) expression in the left side. Once assigned, the object can be used just as an ordinary component of the computation. The c function concanenates the components into a vector.\n\n\nR code\nrandom_numbers &lt;- c(1,10,100)    \nrandom_numbers\n\n\n[1]   1  10 100\n\n\nNow you can do scalar computations on a vector\n\n\nR code\nrandom_numbers * 2\n\n\n[1]   2  20 200\n\n\nor use sum, sort, min, max, length and many other operations. For example\n\n\nR code\nsort(random_numbers)\n\n\n[1]   1  10 100\n\n\nYou can also do vector arithmatic\n\n\nR code\nrandom_numbers &lt;- c(1,10,100) \ny&lt;- c(1,2,3) \nrandom_numbers * y\n\n\n[1]   1  20 300\n\n\nVectors can also be made of characters\n\n\nR code\ncodons&lt;- c(\"AUG\", \"UAU\", \"UGA\") \ncodons\n\n\n[1] \"AUG\" \"UAU\" \"UGA\""
  },
  {
    "objectID": "labs/lab1_rstudio.html#exercises",
    "href": "labs/lab1_rstudio.html#exercises",
    "title": "Lab 1 : Introduction to R and Reproducible Research",
    "section": "Exercises",
    "text": "Exercises\nYour lab report must have each exercise labeled with a header (e.g. ## Exercise 1) so that each one appears in the table of contents.\nYou will need to first export (download) the Lab1_yourname.html file to your computer, then upload the file to Canvas. In the bottom right corner click on the wheel icon then select Export.\n\nThe main goal for today’s lab is to create the lab report so we need a few exercises to fill it out\n\nExercise 1\nFor x = 2 and y = 15, compute the sum and difference of x and y\n\n\nExercise 2\nCreate a vector of the values 22, 62, 148, 43 and 129. Multiple the vector by 5.\n\n\nExercise 3\nCreate a vector of the nucleotides A, T, C and G. Remember to put a “” around each letter. Arrange the nucleotides alphabetically using the sort function sort(vector_name)"
  },
  {
    "objectID": "labs/lab1_overview.html#learning-objectives",
    "href": "labs/lab1_overview.html#learning-objectives",
    "title": "Lab 1 - Overview & Getting Started",
    "section": "",
    "text": "What is bioinformatics?\nWhat is reproducible research?\nWhy learn bioinformatics and data science skills?\nHigh Performance Computing (Unity)\nOverview of the R statistical programming language"
  },
  {
    "objectID": "labs/lab1_overview.html#overview",
    "href": "labs/lab1_overview.html#overview",
    "title": "Lab 1 - Overview",
    "section": "Overview",
    "text": "Overview\nIn recent years, the field of genomic analysis and bioinformatics has sifted towards requiring some knowledge of R, Python/Perl/C and the use of high performance computers (often requiring some fundamental Unix skills) available at national computing centers for working with large data sets. While there are many great software packages available for particular computational problems in evolutionary biology, many software programs do not have a user interface (e.g. drop down menus and such) and are run in command line mode. The lab sessions in this course have been designed to give students an introduction to working with R and packages used for genome and metagenome analyses.\nThe lab course is divided into 3 parts\n\nIntroduction to R and the tidyverse\nGene Expression Analysis\nAnalysis of SNPs and your genetic data"
  },
  {
    "objectID": "labs/lab1_overview.html#reproducible-research",
    "href": "labs/lab1_overview.html#reproducible-research",
    "title": "Lab 1 - Overview",
    "section": "Reproducible Research",
    "text": "Reproducible Research\nReproducibility is the hallmark of science, which is based on empirical observations coupled with explanatory models. While reproducibility encompasses the full science lifecycle, and includes issues such as methodological consistency and treatment of bias, in this course we will focus on computational reproducibility: the ability to document data, analyses, and models sufficiently for other researchers to be able to understand and ideally re-execute the computations that lead to scientific results and conclusions. With current publishing practices, this can be difficult because data are typically unavailable, the method sections of papers do not detail the computational approaches used, and analyses and models are often conducted in graphical programs, or, when scripted analyses are employed, the code is not available. In this course we will learn how to write code that is integrated into reproducible reports."
  },
  {
    "objectID": "labs/lab1_overview.html#data-science",
    "href": "labs/lab1_overview.html#data-science",
    "title": "Lab 1 - Overview & Getting Started",
    "section": "",
    "text": "The field of data science has grown tremendously over the last decade and the two programming languages, R and Python, used in analyzing genomic data are the most popular languages for data science. This made it easy to transfer bioinformatics skills to diverse fields.\nHere a few links that I will go over in lab:\n\nWhat is Data Science? \n\nWhat is Data Science? 8 Skills That Will Get You Hired\n\nOpen Science is Kinder Science\n\nData Carpentry\n\nBuilding a local community of practice in scientific programming for life scientists"
  },
  {
    "objectID": "labs/lab1_overview.html#high-performance-computing-unity-and-unix",
    "href": "labs/lab1_overview.html#high-performance-computing-unity-and-unix",
    "title": "Lab 1 - Overview & Getting Started",
    "section": "",
    "text": "In this course we will learn to write basic unix commands, run bioinformatics software from the command line and allocate computer resources for submitting large jobs. UMass has modern High Performance Computing system, Unity, and excellent staff members to help get you going and trouble shoot issues. Working on HPCs has become much easier with the advent of web interfaces that look and work much like software running on your computer."
  },
  {
    "objectID": "labs/lab1_overview.html#r",
    "href": "labs/lab1_overview.html#r",
    "title": "Lab 1 - Overview & Getting Started",
    "section": "",
    "text": "R is the largest and most comprehensive public domain statistical computing environment. The core R package is enhanced by several hundred user-supplied add-on packages, including many for gene expression analysis, in the  Comprehensive R Archive Network (CRAN). Omegahat Project for Statistical Computing.  BioConductor is an open source and open development software project for the analysis and comprehension of genomic data and is based primarily on the R programming language. R and Bioconductor are free, Open Source and available for Windows, MacOS and a wide variety of UNIX platforms.\n\n\nReproducibility is the hallmark of science, which is based on empirical observations coupled with explanatory models. While reproducibility encompasses the full science lifecycle, and includes issues such as methodological consistency and treatment of bias, in this course we will focus on computational reproducibility: the ability to document data, analyses, and models sufficiently for other researchers to be able to understand and ideally re-execute the computations that lead to scientific results and conclusions. With current publishing practices, this can be difficult because data are typically unavailable, the method sections of papers do not detail the computational approaches used, and analyses and models are often conducted in graphical programs, or, when scripted analyses are employed, the code is not available. In this course we will learn how to write code that is integrated into reproducible reports.\n\n\n\nMany introductory and advance tutorials have been developed for R. Here are a few\n\nThe offical R manuals\nCRAN’s Introduction to R\nR for Data Science by Garrett Grolemund and Hadley Wickham\nR Graphics Cookbook by Winston Chang\nData Carpentries Genomic Workshop Sessions\nData Analysis and Visualization in R for Ecologists\n\nThere are also many workshops and online R courses that you could take to follow up what you learn in this class."
  },
  {
    "objectID": "labs/lab1_overview.html#what-is-bioinformatics-and-data-science",
    "href": "labs/lab1_overview.html#what-is-bioinformatics-and-data-science",
    "title": "Lab 1 - Overview & Getting Started",
    "section": "",
    "text": "Bioinformatics is the field of science in which biology, computer science, statistics and information technology merge into a single discipline. There are three important sub-disciplines within bioinformatics:\n\nThe development of new algorithms and statistics with which to assess relationships among members of large data sets.\nThe development and implementation of tools that enable efficient access and management of different types of information.\nThe analysis and interpretation of various types of data including nucleotide and amino acid sequences, protein domains, and protein structures.\n\n\n\n\nis a term coined in response to the high demand of techniques and resources for handling the explosion of molecular data.\nis a buzzword to describe a growing field.\nbenefits from the physicists, chemists and mathematicians crossing over into biology.\nis a collection of tools.\nis way of thinking about a problem!\n\n\n\n\nIn order to make new algorithms and data sources available to biologists someone needs to write applications that include these algorithms and create new databases. Often this is first done by academic research groups. Later redone by private companies when market is large and profitable enough. There is a large gap between what is done by research groups and companies. Sometimes this is filled by large government funded projects, but not usually in time for most researchers. This is why bioinformatics and programming skills have become very valuable."
  },
  {
    "objectID": "methods/NEON_plot_samples.html",
    "href": "methods/NEON_plot_samples.html",
    "title": "Visualizing NEON samples within a plot",
    "section": "",
    "text": "R code\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(viridis)\n\n\nLoad file\n\n\nR code\nneon.plot.samples <- read_csv(\"../data/NEON_metadata/harvard_seasonal_study_coordinates.csv\")\n\n\nPlot of samples per plot per year at all HARV metagenome plots\n\n\nR code\nneon.plot.samples |> \n  ggplot(aes(x=coreCoordinateX, y = coreCoordinateY, color = sampleTiming)) +\n  # add lines and annotate subplots\n  geom_hline(yintercept=20, color = \"gray\") +\n  geom_vline(xintercept=20, color = \"gray\") + \n  annotate(\"text\", x = 5, y = 5, label = \"21\", color = \"black\", size = 2) +\n  annotate(\"text\", x = 5, y = 35, label = \"39\", color = \"black\", size = 2) +\n  annotate(\"text\", x = 35, y = 5, label = \"23\", color = \"black\", size = 2) +\n  annotate(\"text\", x = 35, y = 35, label = \"41\", color = \"black\", size = 2) +\n  geom_rect(aes(xmin = 0, xmax = 40, ymin = 0, ymax = 40), fill = NA, color = \"black\", linewidth = .1) +\n  # add rectangle with no soil sampling area\n  geom_rect(aes(xmin = 10, xmax = 30, ymin = 10, ymax = 30), fill = \"white\", color = \"grey\", linewidth = .1) +\n  annotate(\"text\", x = 20, y = 23, label = \"No soil\", color = \"black\", size = 2) +\n  annotate(\"text\", x = 20, y = 17, label = \"sampling area\", color = \"black\", size = 2) +\n  # sampling points\n  geom_point(aes(shape = candidate)) +\n  labs(title = \"Plot position of organic soil samples from HARV in 2024\") +\n  facet_wrap(~plotID) +\n  theme_minimal() +\n  coord_fixed()\n\n\n\n\n\n## Use pairwise distances and compute a total or average distance between the points in each set.\n### 33\n\n\nR code\n# Define two sets of 3 points\nset1 <- matrix(c(2.5, 15, 12, 31.5, 0.5, 35.5), ncol = 2, byrow = TRUE)  # Points: (21,2.5), (2,2), (3,3)\nset2 <- matrix(c(36, 19.5, 31.5, 16.5, 24.5, 0), ncol = 2, byrow = TRUE)  # Points: (1,1), (1.5,1.5), (2,2)\n\n# Function to compute total pairwise distance\ntotal_distance <- function(points) {\n  dist_matrix <- dist(points)  # Computes all pairwise distances\n  sum(dist_matrix)\n}\n\n# Compare sets\ndist1 <- total_distance(set1)\ndist2 <- total_distance(set2)\n\ncat(\"Set 1 total distance:\", dist1, \"\\n\")\n\n\nSet 1 total distance: 51.81256 \n\n\nR code\ncat(\"Set 2 total distance:\", dist2, \"\\n\")\n\n\nSet 2 total distance: 45.97024 \n\n\nR code\nif (dist1 < dist2) {\n  cat(\"Set 1 is closer together.\\n\")\n} else {\n  cat(\"Set 2 is closer together.\\n\")\n}\n\n\nSet 2 is closer together.\n\n\n## Use pairwise distances and compute a total or average distance between the points in each set.\n### 34\n\n\nR code\n# Define two sets of 3 points\nset1 <- matrix(c(16.5, 31.5, 11, 34, 30, 28), ncol = 2, byrow = TRUE)  # Points: (21,2.5), (2,2), (3,3)\nset2 <- matrix(c(3, 2, 19, 8, 13.5, 9), ncol = 2, byrow = TRUE)  # Points: (1,1), (1.5,1.5), (2,2)\n\n# Function to compute total pairwise distance\ntotal_distance <- function(points) {\n  dist_matrix <- dist(points)  # Computes all pairwise distances\n  sum(dist_matrix)\n}\n\n# Compare sets\ndist1 <- total_distance(set1)\ndist2 <- total_distance(set2)\n\ncat(\"Set 1 total distance:\", dist1, \"\\n\")\n\n\nSet 1 total distance: 39.91271 \n\n\nR code\ncat(\"Set 2 total distance:\", dist2, \"\\n\")\n\n\nSet 2 total distance: 35.29761 \n\n\nR code\nif (dist1 < dist2) {\n  cat(\"Set 1 is closer together.\\n\")\n} else {\n  cat(\"Set 2 is closer together.\\n\")\n}\n\n\nSet 2 is closer together."
  },
  {
    "objectID": "labs/lab1_overview.html#generative-ai",
    "href": "labs/lab1_overview.html#generative-ai",
    "title": "Lab 1 - Overview & Getting Started",
    "section": "",
    "text": "You all are part of the first generation of generative AI users. The saying goes “AI won’t take your job, but someone using who knows how to use AI might.” Think of AI as a force multiplier. You have to learn to code and clearly state your problems before AI can to help you. This class will fully use generative AI in hopes that it will challenge us to think more creatively about problems and not stress out about syntax. Think first…ask questions…code…solve problem! We will use the UMass version of Microsoft Copilot Chat and Copilot integrated into RStudio. We will embrace “Vibe coding” (see What is Vibe Coding, Exactly?) and ride the waves."
  },
  {
    "objectID": "labs/lab1_overview.html#overview-1",
    "href": "labs/lab1_overview.html#overview-1",
    "title": "Lab 1 - Overview & Getting Started",
    "section": "",
    "text": "In recent years, the field of genomic analysis and bioinformatics has sifted towards requiring some knowledge of R, Python/Perl/C and the use of high performance computers (often requiring some fundamental Unix skills) available at national computing centers for working with large data sets. While there are many great software packages available for particular computational problems in evolutionary biology, many software programs do not have a user interface (e.g. drop down menus and such) and are run in command line mode. The lab sessions in this course have been designed to give students an introduction to working with R and packages used for genome and metagenome analyses. We are using recently release National Ecological Observatory Network data to design a course-based Undergraduate Research Experience (CURE). The first 4 weeks we will discuss to project space, discuss research ideas and formulate testable hypothesis or discovery driven approaches, design the experimental approaches. For a preview today I will give an overview of the project space."
  },
  {
    "objectID": "labs/lab1_overview.html#github",
    "href": "labs/lab1_overview.html#github",
    "title": "Lab 1 - Overview & Getting Started",
    "section": "",
    "text": "GitHub has become a popular way to manage, share and view code for open source projects. The tutorials created for this course will be written in Quarto and posted on GitHub. Thus, you will be able to continue to see course materials after the end of the semester. You will use and make a GitHub web site for your research project."
  },
  {
    "objectID": "labs/lab1_overview.html#course-based-undergraduate-research-experience-cure",
    "href": "labs/lab1_overview.html#course-based-undergraduate-research-experience-cure",
    "title": "Lab 1 - Overview & Getting Started",
    "section": "",
    "text": "We are using recently release National Ecological Observatory Network data to design a course-based Undergraduate Research Experience (CURE). The first 4 weeks we will discuss to project space, discuss research ideas and formulate testable hypothesis or discovery driven approaches, design the experimental approaches. For a preview today I will give an overview of the project space"
  },
  {
    "objectID": "labs/lab1_overview.html#dyiers",
    "href": "labs/lab1_overview.html#dyiers",
    "title": "Lab 1 - Overview & Getting Started",
    "section": "",
    "text": "You can do all of the R-based labs on your own computer. Follow these directions by the makers of RStudio, Posit. You will need to download the lab files from Unity or the course GitHub site."
  },
  {
    "objectID": "labs/lab1_overview.html#accessing-the-course-unity-resources",
    "href": "labs/lab1_overview.html#accessing-the-course-unity-resources",
    "title": "Lab 1 - Overview & Getting Started",
    "section": "Accessing the course Unity resources",
    "text": "Accessing the course Unity resources\nIf you haven’t already done so, request a Unity HPC account and access to our course directory\nTo request a Unity account and access our course directory.\n\nGo to Unity\nRequest an account\nGo to MyPIs, click on the + button and enter pi_bio678_umass_edu"
  },
  {
    "objectID": "labs/lab1_overview.html#r-and-rstudio",
    "href": "labs/lab1_overview.html#r-and-rstudio",
    "title": "Lab 1 - Overview & Getting Started",
    "section": "R and RStudio",
    "text": "R and RStudio\n\nRStudio using Open OnDemand\nOpen OnDemand makes supercomputing accessible through a web portal.\n\nGo to Unity\nOn the left menu select OpenOnDemand\nIn the top menu select Interactive Apps then RStudio\nSet the job duration for 4 hrs to cover the length of the lab. Otherwise set the time to what you anticipate needing.\nUnless otherwise suggested set CPU Core Count to 2 and the memory to 8 gb.\n\nClick Launch. It takes about a minute the job to start and then you can launch the RStudio Interface.\n\n\n\nRStudio Interface\nThe default R studio appearance includes 4 windows.\n\nThe R script(s) and data view (upper left window).\nConsole (bottom left window).\nWork space and history (upper right window).\nFiles, plots, packages and help (bottom right window).\n\n\n\n\nRStudio Screenshot\n\n\n\nThe R script(s) and data view window (upper left window)\nIn this window you can type directly into a file, run code and save the file for reuse. In this class we will work with Quarto files (discussed below).\n\n\nConsole Window (bottom left window)\nThe console is where you can type R commands and see output.\nType\n3 + 3\nTo better document and save your code write it in the Quarto documents rather than the console. On occasion we will use the console to access documentation and for other purposes.\n\n\nEnvironment and History tabs (upper right window)\nThe Environment tab shows all the active objects. If you have a data frame loaded, then click on the object will enable you to view the table. The History tab shows a list of commands used so far.\n\n\nFiles, Plots, Packages and Help (bottom right window)\nThere are data sets that come with the R package and used in tutorials. If you run the following command you will see a graph of related to the cars data set in the Plots window\n\n\n\nQuarto\nThe Quarto is a scientific publishing system. In this class we will use one of it’s simplest features, producing a report with the code and resulting output (graphs, tables, statistical analysis). Quarto can also be used to produce slides, web sites, scientific manuscripts and books. For example, and all the labs for this course and my research laboratory website were made using Quarto. Quarto wraps together many previous packages used for publishing with R.\nTo use Quarto with R, the rmarkdown R package is installed. There are some differences between a Quarto and R Markdown document, but overall they are very similar.\n\nProducing Lab Reports with Quarto\nIn RStudio select File &gt; New File &gt; Quarto Document. Add a title (e.g. Lab 1) and your name then create the document. Notice the your file says untitled with an asterisk. Save your file (e.g. lab1). This will automatically add the .qmd extension to your file (lab1.qmd). ALWAYS SAVE YOUR FILE BEFORE YOU START WORKING AND OFTEN WHILE WORKING.\nThe top section of the document delineated by the --- is called the YAML block. In this template it contains your the title, your name, the output type (html) and the editor preference (visual).You can also work with your file directly with the source code by clicking the source icon.\nThe following lines of code in your YAML block with generate a table of contents (toc) as shown at the top of this lab. The line with embed-resources creates a stand alone html file. This is also availabe as lab_template.qmd in our course directory /work/pi_bio678_umass_edu\n---\ntitle: \"Lab 1\"\nauthor: \"Your name\"\nformat:\n  html:\n    toc: true\n    toc_float: true\n    embed-resources: true\neditor: visual\nexecute: \n  warning: false\n  message: false\n---\nThe text with the white background is in rmarkdown. The icons in the same section as the visual icon you can easily made the text in bold or in italics, change the text from normal to a header, create bulleted or numbered lists, insert html links, add images, insert tables and more.\nThe text with the gray background is in R code chunks. Click on the green play icon in the top right corner of the code chunk to run the code.\nClick on the Render icon. This will run the code, show the output and create a html file that is automatically saved to your directory (look for the lab1.html file) and will automatically open this file in your browser.\nCreate new code chunk by clicking on the green +C icon to the right of the Render icon. In the code chunk type plot(cars). Then click the run the code to see a graph of the cars data set that comes preloaded into R.\n\n\nR code\nplot(cars)"
  },
  {
    "objectID": "labs/lab1_overview.html#writing-r-code",
    "href": "labs/lab1_overview.html#writing-r-code",
    "title": "Lab 1 - Overview & Getting Started",
    "section": "Writing R code",
    "text": "Writing R code\n\nAssignment statements\nAll R statements where you create objects are called assignment statements and the form “object_name &lt;- value”\n\n\nR code\nx &lt;- 3\n\n\nSimply typing x will give the value of x\n\n\nR code\nx\n\n\n[1] 3\n\n\nYou will make lots of assignments and &lt;- is a pain to type. Instead, use RStudio’s keyboard shortcut: Alt + - (the minus sign). Notice that RStudio automagically surrounds &lt;- with spaces, which is a good code formatting practice. An equals sign = will work in place of &lt;-, but it will cause confusion later so keep to the convention of using &lt;- to make assignments\n\n\nObject Names\nObject names must start with a letter, and can only contain letters, numbers, underscores and periods. You want your object names to be descriptive, so you’ll need a convention for multiple words. I recommend snake_case where you separate lowercase words with an underscore. Note that R is case sensitive, e.g., object names gene, GENE, Gene are all different.\n\n\nR code\ngenome_size &lt;- 3100000000\n\n\nImportant note: since there are many built-in functions in R, make sure that the new object names you assign are not already used by the system. A simple way of checking this is to type in the name you want to use. If the system returns an error message telling you that such object is not found, it is safe to use the name.\n\n\nCharacters\nA character object is used to represent string values in R. It is defined by double quotes ““.\n\n\nR code\nDNA &lt;- \"ATGAAA\"\nDNA\n\n\n[1] \"ATGAAA\"\n\n\n\n\nVectors\nA vector is a sequence of data elements of the same basic type. data elements in a vector are officially called components. Assignment operator (&lt;-) stores the value (object) on the right side of (&lt;-) expression in the left side. Once assigned, the object can be used just as an ordinary component of the computation. The c function concanenates the components into a vector.\n\n\nR code\nrandom_numbers &lt;- c(1,10,100)    \nrandom_numbers\n\n\n[1]   1  10 100\n\n\nNow you can do scalar computations on a vector\n\n\nR code\nrandom_numbers * 2\n\n\n[1]   2  20 200\n\n\nor use sum, sort, min, max, length and many other operations. For example\n\n\nR code\nsort(random_numbers)\n\n\n[1]   1  10 100\n\n\nYou can also do vector arithmatic\n\n\nR code\nrandom_numbers &lt;- c(1,10,100) \ny&lt;- c(1,2,3) \nrandom_numbers * y\n\n\n[1]   1  20 300\n\n\nVectors can also be made of characters\n\n\nR code\ncodons&lt;- c(\"AUG\", \"UAU\", \"UGA\") \ncodons\n\n\n[1] \"AUG\" \"UAU\" \"UGA\""
  },
  {
    "objectID": "labs/lab1_overview.html#exercises",
    "href": "labs/lab1_overview.html#exercises",
    "title": "Lab 1 - Overview & Getting Started",
    "section": "Exercises",
    "text": "Exercises\nYour lab report must have each exercise labeled with a header (e.g. ## Exercise 1) so that each one appears in the table of contents.\nYou will need to first export (download) the Lab1_yourname.html file to your computer, then upload the file to Canvas. In the bottom right corner click on the wheel icon then select Export.\n\nThe main goal for today’s lab is to create the lab report so we need a few exercises to fill it out\n\nExercise 1\nFor x = 2 and y = 15, compute the sum and difference of x and y\n\n\nExercise 2\nCreate a vector of the values 22, 62, 148, 43 and 129. Multiple the vector by 5.\n\n\nExercise 3\nCreate a vector of the nucleotides A, T, C and G. Remember to put a “” around each letter. Arrange the nucleotides alphabetically using the sort function sort(vector_name)"
  },
  {
    "objectID": "labs/lab1s_quarto.html",
    "href": "labs/lab1s_quarto.html",
    "title": "Lab S1 - Quarto",
    "section": "",
    "text": "Quarto\nDifferences between R Markdown and Quarto\nYAML blocks\nCode blocks\n\n\n\n\n\nQuarto is the name of an open-source publishing system used for technical and scientific writing.\nIt lets you combine text, code, and outputs in one document—perfect for data science, research, and reproducible reports.\nYou can write in Python, R, Julia, or Observable JavaScript, and publish to formats like HTML, PDF, Word, and even full websites\nIt’s considered the next generation of R Markdown, and works with tools like Jupyter Notebooks, VS Code, and RStudio.\nBecause it is based on R Markdown, there is a wealth of related resources and books published on and using R Markdown. See some of on the examples books using R we will periodically using in the course.\n\n\n\n\nR Markdown and Quarto are both tools for creating dynamic documents that combine code, text, and outputs (like plots or tables), but they differ in terms of design philosophy, features, and flexibility. Here’s a breakdown of their key differences:\n\n\n\nR Markdown:\n\nDeveloped by RStudio.\nPrimarily designed for R users.\nBuilt on top of knitr and Pandoc.\nDeeply integrated into the RStudio IDE.\n\nQuarto:\n\nAlso developed by RStudio, but as a next-generation tool.\nLanguage-agnostic: supports R, Python, Julia, and Observable JavaScript.\nUses Pandoc directly (not knitr).\nDesigned to unify and modernize the workflow across languages.\n\n\n\n\n\n\nR Markdown: Best suited for R. Python support is possible but less seamless.\nQuarto: First-class support for multiple languages in a single document. You can mix R, Python, Julia, and JavaScript.\n\n\n\n\n\nR Markdown:\n\nUses YAML front matter for metadata.\nCode chunks are written using triple backticks with language identifiers.\n\nQuarto:\n\nSimilar structure but more consistent and extensible YAML.\nSupports Markdown extensions like callouts, citations, cross-referencing, and more.\n\n\n\n\n\n\nR Markdown:\n\nSupports HTML, PDF, Word, slides (via xaringan or ioslides), etc.\nCustomization can be complex for advanced layouts.\n\nQuarto:\n\nSupports all R Markdown formats plus:\n\nReveal.js slides.\nBooks and websites with built-in navigation and styling.\nJupyter-style notebooks.\n\nEasier to configure and customize outputs.\n\n\n\n\n\n\nR Markdown:\n\nExecutes code using knitr (for R) or reticulate (for Python).\nLess control over execution environment.\n\nQuarto:\n\nUses Jupyter kernels or R directly.\nBetter support for notebook-style interactivity and execution control.\n\n\n\n\n\n\nR Markdown:\n\nNo native concept of a “project” beyond RStudio projects.\n\nQuarto:\n\nSupports Quarto Projects: collections of documents with shared configuration.\nIdeal for books, blogs, websites, and multi-document workflows.\n\n\n\n\n\n\nQuarto:\n\nMore modern and extensible.\nSupports Lua filters, Markdown extensions, cross-referencing, citations, and interactive widgets.\nBetter support for version control and CI/CD workflows.\n\n\n\n\n\n\n\n\nFeature\nR Markdown\nQuarto\n\n\n\n\nLanguage Support\nPrimarily R\nR, Python, Julia, JS\n\n\nExecution Engine\nknitr\nJupyter / native\n\n\nOutput Formats\nMany\nMore + easier config\n\n\nInteractivity\nLimited\nRich (widgets, JS)\n\n\nProject Support\nBasic\nFull project system\n\n\nExtensibility\nModerate\nHigh\n\n\nIdeal For\nR-centric reports\nMulti-language docs\n\n\n\n\n\n\n\n\nLet’s go the the Quarto documentation for Markdown basics and more details on Figures\nIt is important to specific where the figure is located relative to your .qmd file. The path can be relative (giant_virus.jpg) or (images/giant_virus.jpg) or absolute (/home/pi_jlb_umass_edu/images/giant_virus.jpg).\n\n\n\ngiant virus\n\n\n\n\n\nIn Quarto, a YAML block is a section at the top of a document that contains metadata and configuration settings. YAML stands for “YAML Ain’t Markup Language”, and it’s used to define things like the document title, author, output format, and more.\n\n\nA YAML block is enclosed by triple dashes (---) at the beginning and end:\n---\ntitle: \"My Analysis Report\"\nauthor: \"Jeffrey Blanchard\"\ndate: \"2025-09-08\"\nformat: html\neditor: visual\n---\nThis block tells Quarto: - The title of the document. - The author name. - The date to display. - The output format (e.g., HTML, PDF, Word). - The editor preference (e.g., visual or source).\n\n\n\nHere are some frequently used fields:\n\n\n\n\n\n\n\nField\nDescription\n\n\n\n\ntitle\nTitle of the document\n\n\nauthor\nAuthor name(s)\n\n\ndate\nDate of publication\n\n\nformat\nOutput format (e.g., html, pdf, docx, revealjs)\n\n\ntoc\nTable of contents (true or false)\n\n\nnumber-sections\nNumber section headings\n\n\ntheme\nVisual theme for HTML or slides\n\n\ncode-fold\nWhether code chunks can be collapsed\n\n\nexecute\nControls code execution (e.g., echo, eval, freeze)\n\n\nbibliography\nPath to .bib file for citations\n\n\nfilters\nLua filters for advanced customization\n\n\n\n\n\n\n---\ntitle: \"Data Exploration\"\nauthor: \"Jeffrey Blanchard\"\nformat:\n  html:\n    toc: true\n    code-fold: true\n    theme: cosmo\n    embed-resources: true\nexecute:\n  echo: true\n  freeze: auto\n---\nThis configures: - An HTML output with a table of contents. - Collapsible code chunks. - A Bootstrap theme (cosmo). - Code execution settings.\nImportant for our class is the embed-resources: true line. This creates a single html file with the figures embeded in the file. If this line is not in the YAML block a new directory will be created which contains the images and is linked to the html file. This means that if you turn in this html file (without using embed-resources: true) the images will not be shown.\n\n\n\nQuarto YAML is: - More consistent and extensible. - Supports nested configuration (e.g., format.html.toc). - Easier to manage across multi-format outputs (e.g., HTML and PDF from one source).\nIn Quarto, R code chunks are sections of code embedded in your document that get executed when the document is rendered. These chunks are enclosed in triple backticks and start with {r}. You can customize their behavior using chunk options, which control things like whether the code is shown, whether it’s executed, how results are displayed, and more.\n\n\n\n\n\n\n\n\nR code\nsummary(cars)\n\n\n     speed           dist       \n Min.   : 4.0   Min.   :  2.00  \n 1st Qu.:12.0   1st Qu.: 26.00  \n Median :15.0   Median : 36.00  \n Mean   :15.4   Mean   : 42.98  \n 3rd Qu.:19.0   3rd Qu.: 56.00  \n Max.   :25.0   Max.   :120.00  \n\n\n\n\n\nHere’s a categorized list of the most useful options:\n\n\n\n\n\nOption\nDescription\n\n\n\n\neval\nWhether to evaluate the code (TRUE or FALSE)\n\n\necho\nShow the code in the output (TRUE or FALSE)\n\n\ninclude\nInclude both code and output (TRUE or FALSE)\n\n\nerror\nShow errors in output (TRUE or FALSE)\n\n\nwarning\nShow warnings (TRUE or FALSE)\n\n\nmessage\nShow messages (TRUE or FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\nOption\nDescription\n\n\n\n\nresults\nHow to display results (\"markup\", \"asis\", \"hide\")\n\n\nfig.width\nWidth of plots (in inches)\n\n\nfig.height\nHeight of plots (in inches)\n\n\nfig.cap\nCaption for figures\n\n\nfig.align\nAlignment of figures (\"left\", \"center\", \"right\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nOption\nDescription\n\n\n\n\ncache\nCache results to avoid re-running code\n\n\nfreeze\nFreeze output to avoid re-execution unless explicitly updated\n\n\n\n\n\n\n\n\n\nOption\nDescription\n\n\n\n\ntidy\nAutomatically tidy code before execution\n\n\ncollapse\nCollapse code and output together\n\n\ncomment\nPrefix for output lines\n\n\n\n\n\n\n\n{r pressure-plot, fig.width=6, fig.height=4, fig.cap=\"Pressure vs Temperature\"}\n\n\nR code\nplot(pressure)\n\n\n\n\n\nPressure vs Temperature\n\n\n\n\nThis chunk: - Hides the code (echo=FALSE) - Sets figure size - Adds a caption - Names the chunk (pressure-plot) for reference\n\n\n\n\nTry a different Quarto theme\n\n\n\nCreate a lab report that has\n\nA link out to an external web site.\nAn image embedded.\nA table of contents using the YAML block\nThe code folded using the YAML block\nA code chunk with plot(cars) in which the plot is sized to a figure width of 3 and height of 2\nA code chunk in which the output, but not the code is in the rendered file.\nTry a different Quarto theme.\n\n\n\n\nThis lab was created with assistance from UMass Copilot"
  },
  {
    "objectID": "labs/lab1s_quarto.html#learning-objectives",
    "href": "labs/lab1s_quarto.html#learning-objectives",
    "title": "Lab S1 - Quarto",
    "section": "",
    "text": "Quarto\nDifferences between R Markdown and Quarto\nYAML blocks\nCode blocks"
  },
  {
    "objectID": "labs/lab1s_quarto.html#quarto",
    "href": "labs/lab1s_quarto.html#quarto",
    "title": "Lab S1 - Quarto",
    "section": "",
    "text": "Quarto is the name of an open-source publishing system used for technical and scientific writing.\nIt lets you combine text, code, and outputs in one document—perfect for data science, research, and reproducible reports.\nYou can write in Python, R, Julia, or Observable JavaScript, and publish to formats like HTML, PDF, Word, and even full websites\nIt’s considered the next generation of R Markdown, and works with tools like Jupyter Notebooks, VS Code, and RStudio.\nBecause it is based on R Markdown, there is a wealth of related resources and books published on and using R Markdown. See some of on the examples books using R we will periodically using in the course."
  },
  {
    "objectID": "labs/lab1s_quarto.html#differences-between-r-markdown-and-quarto",
    "href": "labs/lab1s_quarto.html#differences-between-r-markdown-and-quarto",
    "title": "Lab S1 - Quarto",
    "section": "",
    "text": "R Markdown and Quarto are both tools for creating dynamic documents that combine code, text, and outputs (like plots or tables), but they differ in terms of design philosophy, features, and flexibility. Here’s a breakdown of their key differences:\n\n\n\nR Markdown:\n\nDeveloped by RStudio.\nPrimarily designed for R users.\nBuilt on top of knitr and Pandoc.\nDeeply integrated into the RStudio IDE.\n\nQuarto:\n\nAlso developed by RStudio, but as a next-generation tool.\nLanguage-agnostic: supports R, Python, Julia, and Observable JavaScript.\nUses Pandoc directly (not knitr).\nDesigned to unify and modernize the workflow across languages.\n\n\n\n\n\n\nR Markdown: Best suited for R. Python support is possible but less seamless.\nQuarto: First-class support for multiple languages in a single document. You can mix R, Python, Julia, and JavaScript.\n\n\n\n\n\nR Markdown:\n\nUses YAML front matter for metadata.\nCode chunks are written using triple backticks with language identifiers.\n\nQuarto:\n\nSimilar structure but more consistent and extensible YAML.\nSupports Markdown extensions like callouts, citations, cross-referencing, and more.\n\n\n\n\n\n\nR Markdown:\n\nSupports HTML, PDF, Word, slides (via xaringan or ioslides), etc.\nCustomization can be complex for advanced layouts.\n\nQuarto:\n\nSupports all R Markdown formats plus:\n\nReveal.js slides.\nBooks and websites with built-in navigation and styling.\nJupyter-style notebooks.\n\nEasier to configure and customize outputs.\n\n\n\n\n\n\nR Markdown:\n\nExecutes code using knitr (for R) or reticulate (for Python).\nLess control over execution environment.\n\nQuarto:\n\nUses Jupyter kernels or R directly.\nBetter support for notebook-style interactivity and execution control.\n\n\n\n\n\n\nR Markdown:\n\nNo native concept of a “project” beyond RStudio projects.\n\nQuarto:\n\nSupports Quarto Projects: collections of documents with shared configuration.\nIdeal for books, blogs, websites, and multi-document workflows.\n\n\n\n\n\n\nQuarto:\n\nMore modern and extensible.\nSupports Lua filters, Markdown extensions, cross-referencing, citations, and interactive widgets.\nBetter support for version control and CI/CD workflows.\n\n\n\n\n\n\n\n\nFeature\nR Markdown\nQuarto\n\n\n\n\nLanguage Support\nPrimarily R\nR, Python, Julia, JS\n\n\nExecution Engine\nknitr\nJupyter / native\n\n\nOutput Formats\nMany\nMore + easier config\n\n\nInteractivity\nLimited\nRich (widgets, JS)\n\n\nProject Support\nBasic\nFull project system\n\n\nExtensibility\nModerate\nHigh\n\n\nIdeal For\nR-centric reports\nMulti-language docs"
  },
  {
    "objectID": "labs/lab1s_quarto.html#yaml-blocks-in-quarto",
    "href": "labs/lab1s_quarto.html#yaml-blocks-in-quarto",
    "title": "Lab S1 - Quarto",
    "section": "",
    "text": "In Quarto, a YAML block is a section at the top of a document that contains metadata and configuration settings. YAML stands for “YAML Ain’t Markup Language”, and it’s used to define things like the document title, author, output format, and more.\n\n\nA YAML block is enclosed by triple dashes (---) at the beginning and end:\n---\ntitle: \"My Analysis Report\"\nauthor: \"Jeffrey Blanchard\"\ndate: \"2025-09-08\"\nformat: html\neditor: visual\n---\nThis block tells Quarto: - The title of the document. - The author name. - The date to display. - The output format (e.g., HTML, PDF, Word). - The editor preference (e.g., visual or source).\n\n\n\nHere are some frequently used fields:\n\n\n\n\n\n\n\nField\nDescription\n\n\n\n\ntitle\nTitle of the document\n\n\nauthor\nAuthor name(s)\n\n\ndate\nDate of publication\n\n\nformat\nOutput format (e.g., html, pdf, docx, revealjs)\n\n\ntoc\nTable of contents (true or false)\n\n\nnumber-sections\nNumber section headings\n\n\ntheme\nVisual theme for HTML or slides\n\n\ncode-fold\nWhether code chunks can be collapsed\n\n\nexecute\nControls code execution (e.g., echo, eval, freeze)\n\n\nbibliography\nPath to .bib file for citations\n\n\nfilters\nLua filters for advanced customization\n\n\n\n\n\n\n---\ntitle: \"Data Exploration\"\nauthor: \"Jeffrey Blanchard\"\nformat:\n  html:\n    toc: true\n    code-fold: true\n    theme: cosmo\n    embed-resources: true\nexecute:\n  echo: true\n  freeze: auto\n---\nThis configures: - An HTML output with a table of contents. - Collapsible code chunks. - A Bootstrap theme (cosmo). - Code execution settings.\nImportant for our class is the embed-resources: true line. This creates a single html file with the figures embeded in the file. If this line is not in the YAML block a new directory will be created which contains the images and is linked to the html file. This means that if you turn in this html file (without using embed-resources: true) the images will not be shown.\n\n\n\nQuarto YAML is: - More consistent and extensible. - Supports nested configuration (e.g., format.html.toc). - Easier to manage across multi-format outputs (e.g., HTML and PDF from one source).\nIn Quarto, R code chunks are sections of code embedded in your document that get executed when the document is rendered. These chunks are enclosed in triple backticks and start with {r}. You can customize their behavior using chunk options, which control things like whether the code is shown, whether it’s executed, how results are displayed, and more."
  },
  {
    "objectID": "labs/lab1s_quarto.html#r-code-chunks-in-quarto",
    "href": "labs/lab1s_quarto.html#r-code-chunks-in-quarto",
    "title": "Lab S1 - Quarto",
    "section": "",
    "text": "R code\nsummary(cars)\n\n\n     speed           dist       \n Min.   : 4.0   Min.   :  2.00  \n 1st Qu.:12.0   1st Qu.: 26.00  \n Median :15.0   Median : 36.00  \n Mean   :15.4   Mean   : 42.98  \n 3rd Qu.:19.0   3rd Qu.: 56.00  \n Max.   :25.0   Max.   :120.00  \n\n\n\n\n\nHere’s a categorized list of the most useful options:\n\n\n\n\n\nOption\nDescription\n\n\n\n\neval\nWhether to evaluate the code (TRUE or FALSE)\n\n\necho\nShow the code in the output (TRUE or FALSE)\n\n\ninclude\nInclude both code and output (TRUE or FALSE)\n\n\nerror\nShow errors in output (TRUE or FALSE)\n\n\nwarning\nShow warnings (TRUE or FALSE)\n\n\nmessage\nShow messages (TRUE or FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\nOption\nDescription\n\n\n\n\nresults\nHow to display results (\"markup\", \"asis\", \"hide\")\n\n\nfig.width\nWidth of plots (in inches)\n\n\nfig.height\nHeight of plots (in inches)\n\n\nfig.cap\nCaption for figures\n\n\nfig.align\nAlignment of figures (\"left\", \"center\", \"right\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nOption\nDescription\n\n\n\n\ncache\nCache results to avoid re-running code\n\n\nfreeze\nFreeze output to avoid re-execution unless explicitly updated\n\n\n\n\n\n\n\n\n\nOption\nDescription\n\n\n\n\ntidy\nAutomatically tidy code before execution\n\n\ncollapse\nCollapse code and output together\n\n\ncomment\nPrefix for output lines\n\n\n\n\n\n\n\n{r pressure-plot, fig.width=6, fig.height=4, fig.cap=\"Pressure vs Temperature\"}\n\n\nR code\nplot(pressure)\n\n\n\n\n\nPressure vs Temperature\n\n\n\n\nThis chunk: - Hides the code (echo=FALSE) - Sets figure size - Adds a caption - Names the chunk (pressure-plot) for reference"
  },
  {
    "objectID": "labs/lab1s_quarto.html#acknowledgements",
    "href": "labs/lab1s_quarto.html#acknowledgements",
    "title": "Lab S1 - Quarto",
    "section": "",
    "text": "This lab was created with assistance from UMass Copilot"
  },
  {
    "objectID": "labs/lab2_AI_ggplot.html",
    "href": "labs/lab2_AI_ggplot.html",
    "title": "Learning R with the help of AI tools starting graphing using ggplot2",
    "section": "",
    "text": "Generative AI\nInstalling R packages\nBuilt-in R data sets and data set packages\nggplot2"
  },
  {
    "objectID": "labs/lab1s_quarto.html#adding-links-and-figures-in-a-quarto-document",
    "href": "labs/lab1s_quarto.html#adding-links-and-figures-in-a-quarto-document",
    "title": "Lab S1 - Quarto",
    "section": "",
    "text": "Let’s go the the Quarto documentation for Markdown basics and more details on Figures\nIt is important to specific where the figure is located relative to your .qmd file. The path can be relative (giant_virus.jpg) or (images/giant_virus.jpg) or absolute (/home/pi_jlb_umass_edu/images/giant_virus.jpg).\n\n\n\ngiant virus"
  },
  {
    "objectID": "labs/lab1s_quarto.html#exercises",
    "href": "labs/lab1s_quarto.html#exercises",
    "title": "Lab S1 - Quarto",
    "section": "",
    "text": "Create a lab report that has\n\nA link out to an external web site.\nAn image embedded.\nA table of contents using the YAML block\nThe code folded using the YAML block\nA code chunk with plot(cars) in which the plot is sized to a figure width of 3 and height of 2\nA code chunk in which the output, but not the code is in the rendered file.\nTry a different Quarto theme."
  },
  {
    "objectID": "labs/lab1s_quarto.html#quarto-themes",
    "href": "labs/lab1s_quarto.html#quarto-themes",
    "title": "Lab S1 - Quarto",
    "section": "",
    "text": "Try a different Quarto theme"
  },
  {
    "objectID": "labs/lab2_AI_ggplot.html#learning-objectives",
    "href": "labs/lab2_AI_ggplot.html#learning-objectives",
    "title": "Learning R with the help of AI tools starting graphing using ggplot2",
    "section": "",
    "text": "Generative AI\nInstalling R packages\nBuilt-in R data sets and data set packages\nggplot2"
  },
  {
    "objectID": "labs/lab2_AI_ggplot.html#generative-ai",
    "href": "labs/lab2_AI_ggplot.html#generative-ai",
    "title": "Learning R with the help of AI tools starting graphing using ggplot2",
    "section": "Generative AI",
    "text": "Generative AI\n\nClimate Change\n\nTrends in Atmospheric Carbon Dioxide (CO2)\nNASA GISS Surface Temperature Analysis (GISTEMP v4)\nGenerative AI’s environmental costs are soaring — and mostly secret\n\n\n\nAI and your future jobs\nAI won’t take your job, but someone using who knows how to use AI might. Think of AI as a force multiplier. You have to learn to code first before you can use AI to help you. Google recently reported that about 25% of its new code is AI-generated.\n\n\nUMass and Generative AI\n\nUMass Guidance on Generative Artificial Intelligence\nUMass Responsible Use of Generative AI\nGenAI Products\n\n\n\nCopilot\nMicrosoft designed Copilot to work off of the latest version of OpenAI’s GPT model, GPT-4. GPT-5 is coming soon.\n\ngithub co-pilot\ngithub education\nMicrosoft Introduction to GitHub Copilot\nIntroduction to GitHub CoPilot videos\nSet up co-pilot for learning\nHow to write better prompts for GitHub Copilot\n\n\n\nAI and R\n\nRStudio github copilot\nAI Assisted Coding in RStudio Integrating OpenAI’s ChatGPT into RStudio is now possible with “Chattr”, “GPT Studio” and “GitHub Copilot”. These new tools will help you find the right functions and commands and to quickly generate code snippets to save you time.\n\n\n\nVibe coding\n\nVibe coding\nWhat is vibe coding, exactly?\nWhat Is Vibe Coding? Definition, Tools, Pros, and Cons\n\n\n\nGithub, Git and AI\n\nYou can use GitHub and Git to collaborate on work\nUsing co-pilot as your tutor\nchattr\n\n\n\nBioinformatics and AI\n\nA data-intelligence-intensive bioinformatics copilot system for large-scale omics research and scientific insights\nBioinformatics AI: Driving Future Biological Breakthroughs\n\n\n\nAI and Scholarly Publishing\n\nAmerican Society of Microbiology Guidelines for Authors Using AI Tools\nChatGPT: guidelines for responsible use (Nature)\nGuidelines from COPE\nICMJE guidance\nWebinar and article from STM integrity hub on use of generative AI in scholarly publishing\nCSR Review Matters Blog (nih.gov)"
  },
  {
    "objectID": "labs/lab2_AI_ggplot.html#introduction-to-r-graphics",
    "href": "labs/lab2_AI_ggplot.html#introduction-to-r-graphics",
    "title": "Learning R with the help of AI tools starting graphing using ggplot2",
    "section": "Introduction to R Graphics",
    "text": "Introduction to R Graphics\nR provides comprehensive graphics utilities for visualizing and exploring scientific data. To date we have been making a few plots using the R Base Graphics. In addition, several more recent graphics environments extend these utilities. These include the grid, lattice and ggplot2 packages. All have the roles, but ggplot2 environment that is part of the Tidyverse package has become popular and is now used for many R packages and in scientific publications.\n\nggplot2 and the Grammar of Graphics\nggplot2 is meant to be an implementation of the Grammar of Graphics, hence the gg in ggplot. The basic notion is that there is a grammar to the composition of graphical components in statistical graphics. By directly controlling that grammar, you can generate a large set of carefully constructed graphics from a relatively small set of operations. As Hadley Wickham (2010), the author of ggplot2 said,\n“A good grammar will allow us to gain insight into the composition of complicated graphics, and reveal unexpected connections between seemingly different graphics.”\n\n\nTutorials and resources\nYou can make amazing graphs with ggplot, but there is a long learning curve so we will have multiple lab sessions on ggplot and graphing. Here are a few different resources for ggplot.\n\nHadley Wickham and Garrett Grolemund released the second edition of R for Data Science.\nData Carpentry’s Data Analysis and Visualization in R for Ecologists\nFor those with a visual learning style there is Maria Nattestad’s Youtube videos\nThe ggplot cheatsheet"
  },
  {
    "objectID": "labs/lab2_AI_ggplot.html#on-the-computer",
    "href": "labs/lab2_AI_ggplot.html#on-the-computer",
    "title": "Learning R with the help of AI tools starting graphing using ggplot2",
    "section": "On the Computer",
    "text": "On the Computer\n\nCreate and save your Quarto Markdown (qmd) file\nJust like last week we will be writing our code in a Quarto Markdown (qmd) file. Remember to use the following formatting in your YAML block. You can add different themes or change the parameters below, but you need to put in the embed-resources: true line true into the YAML block.\n---\ntitle: \"Lab 2 Data Visualization\"\nauthor: \"You\"\nformat:\n  html:\n    toc: true\n    toc_float: true\n    embed-resources: true\nexecute: \n  warning: false\n  message: false\n---\n\n\nInstalling and loading R packages\nIn this course we will work with many different R packages that will need to be installed on your computer. I have already installed most of these packages for students on Posit Cloud. If you are working on your own computer or on Unity, you can install them using Tools &gt; Install Packages. You only need to install a package once!\nTo work with an R package load it with the library command. I always load my packages at the beginning of my files.\n\n\nR code\nlibrary(tidyverse)\n\n\n\n\nData for today’s lab\nIn most labs we will be loading in data from files (e.g. our 23andME SNP data). Today and next week for simplicity we will work with data sets that come with R and the are available as R packages.\n\nData sets (data frames) that come with R\nR contains pre-loaded data sets that will see in many examples posted on the internet. The mtcars and iris data sets are very popular. You can see the whole list by typing data(). This will pop up a window with a list of the data sets. Include #| eval: false within your R code chunk if you want to show but not run code. You can also use the older R Markdown style of including it in the header ```{r eval = FALSE}\n\n\nR code\ndata()\n\n\nIn class we will talk more about the structure of a data set, which can be summarized using the str command\n\n\nR code\nglimpse(iris)\n\n\nRows: 150\nColumns: 5\n$ Sepal.Length &lt;dbl&gt; 5.1, 4.9, 4.7, 4.6, 5.0, 5.4, 4.6, 5.0, 4.4, 4.9, 5.4, 4.…\n$ Sepal.Width  &lt;dbl&gt; 3.5, 3.0, 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, 3.1, 3.7, 3.…\n$ Petal.Length &lt;dbl&gt; 1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, 1.5, 1.5, 1.…\n$ Petal.Width  &lt;dbl&gt; 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1, 0.2, 0.…\n$ Species      &lt;fct&gt; setosa, setosa, setosa, setosa, setosa, setosa, setosa, s…\n\n\nYou can see the whole data set by typing the name iris or by typing view(iris) which will pop up a window with the data set. However we don’t want to show all 150 observations (rows) of the iris data set in this document. We can use the head command to show just the first 5 rows.\n\n\nR code\nhead(iris)\n\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\n\n\n\n\nData sets that are part of R packages\nR for Data Science uses the palmerpenguins package, “which includes the penguins dataset containing body measurements for penguins on three islands in the Palmer Archipelago, and the ggthemes package, which offers a colorblind safe color palette. We will load these for our work today.” You likely will need to install these packages before loading the libraries.\n\n\nR code\nlibrary(palmerpenguins)\nlibrary(ggthemes)\n\n\nData Analysis and Visualization in R for Ecologists uses the ratdat package, a long-term dataset from Portal, Arizona, in the Chihuahuan desert.\n\n\nR code\nlibrary(ratdat)\n\n\nThe help command can be used to learn more about the palmerpenguins and ratdat packages. After running the below commands, in the right bottom corner under the Help tab the package documentation can be viewed. I used #| eval: false in the below code chunk.\n\n\nR code\nhelp(package=\"palmerpenguins\")\nhelp(package=\"ratdat\")"
  },
  {
    "objectID": "labs/lab2_AI_ggplot.html#exercises",
    "href": "labs/lab2_AI_ggplot.html#exercises",
    "title": "Learning R with the help of AI tools starting graphing using ggplot2",
    "section": "Exercises",
    "text": "Exercises\n\nR for Data Science Chapter 1\nToday we will walk through Chapter 1 of R for Data Science. By putting the examples and exercises in our own Quarto Markdown file, we can create own personal path through the Chapter. Make are readable report by delineating the sections (e.g. 1.2.3 Creating a ggplot) with hashtags so they are visible in your report outline. Include all of the example code in the chapter in your report (In addition to the exercises).\nWorking through the exercises is a great time to explore changing the code with or without Copilot! Answers to all the questions are available online thanks to Martin Lukic and others. I recommend not using these, but learn how to use Copilot to help when your are not sure and to ask me questions during class, help sessions or email.\nIn your report include notes on the places you used Copilot and your prompts. One way to do this would be to have\n\nExercise 1\n\nEx 1 Copilot notes\nThere are probably better ways to do this. Think of one that works for you and clearly communicates to me your strategies.\n\n\nEx 1 code chunk\n\n\n\n\nWhat to upload to Canvas\nAfter you Render the qmd file to an html file, export the file to your computer and upload it to Canvas."
  },
  {
    "objectID": "labs/lab3_tibbles.html",
    "href": "labs/lab3_tibbles.html",
    "title": "Lab 3 : Data Transformation with dplyr",
    "section": "",
    "text": "Data Transformation using dplyr"
  },
  {
    "objectID": "labs/lab3_tibbles.html#learning-objectives",
    "href": "labs/lab3_tibbles.html#learning-objectives",
    "title": "Lab 3 : Data Transformation with dplyr",
    "section": "",
    "text": "Data Transformation using dplyr"
  },
  {
    "objectID": "labs/lab3_tibbles.html#load-libaries",
    "href": "labs/lab3_tibbles.html#load-libaries",
    "title": "Lab 3 : Data Transformation with dplyr",
    "section": "Load libaries",
    "text": "Load libaries\n\n\nR code\nlibrary(tidyverse)\nlibrary(nycflights13)"
  },
  {
    "objectID": "labs/lab3_tibbles.html#introduction-to-data-transformation",
    "href": "labs/lab3_tibbles.html#introduction-to-data-transformation",
    "title": "Lab 3 : Data Transformation with dplyr",
    "section": "Introduction to Data Transformation",
    "text": "Introduction to Data Transformation\n\nTables\nHow they are displayed in your qmd file is different from how they are rendered into a html, pdf and other files.\n\n\nPipes and shortcuts\nIn the last few years |&gt; pipe was introduced as a simpler alternative to the %&gt;% pipe that has been used in R and Tidyverse for the last 10 years. In many online examples you will see the %&gt;% used and at times in code from generative AI. For many uses in this class they are interchangeable.\nThe shortcut keys for generative the |&gt; is Ctrl/Cmd + Shift + M.\nThe shortcut keys for a new R code chuck are trl + Alt + I\n\n\nChecking each line of codes are you write it\nToday we will see in Chapter 4 the following code chunk\n\n\nR code\nflights |&gt;\n  filter(dest == \"IAH\") |&gt; \n  group_by(year, month) |&gt; \n  summarize(\n    arr_delay = mean(arr_delay, na.rm = TRUE)\n  )\n\n\n# A tibble: 12 × 3\n# Groups:   year [1]\n    year month arr_delay\n   &lt;int&gt; &lt;int&gt;     &lt;dbl&gt;\n 1  2013     1     4.16 \n 2  2013     2     5.40 \n 3  2013     3    -1.19 \n 4  2013     4    14.8  \n 5  2013     5     0.972\n 6  2013     6    11.1  \n 7  2013     7    11    \n 8  2013     8     0.705\n 9  2013     9   -10.6  \n10  2013    10     1.81 \n11  2013    11    -1.78 \n12  2013    12    14.5  \n\n\nIf I was writing the code I would check (run the code chunk) each line as a wrote it to make sure I was getting the right result and to simplify trouble shooting error messages\n\n\nR code\nflights |&gt;\n  filter(dest == \"IAH\") \n\n\n# A tibble: 7,198 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1      517            515         2      830            819\n 2  2013     1     1      533            529         4      850            830\n 3  2013     1     1      623            627        -4      933            932\n 4  2013     1     1      728            732        -4     1041           1038\n 5  2013     1     1      739            739         0     1104           1038\n 6  2013     1     1      908            908         0     1228           1219\n 7  2013     1     1     1028           1026         2     1350           1339\n 8  2013     1     1     1044           1045        -1     1352           1351\n 9  2013     1     1     1114            900       134     1447           1222\n10  2013     1     1     1205           1200         5     1503           1505\n# ℹ 7,188 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\n\n\nR code\nflights |&gt;\n  filter(dest == \"IAH\") |&gt; \n  group_by(year, month)\n\n\n# A tibble: 7,198 × 19\n# Groups:   year, month [12]\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1      517            515         2      830            819\n 2  2013     1     1      533            529         4      850            830\n 3  2013     1     1      623            627        -4      933            932\n 4  2013     1     1      728            732        -4     1041           1038\n 5  2013     1     1      739            739         0     1104           1038\n 6  2013     1     1      908            908         0     1228           1219\n 7  2013     1     1     1028           1026         2     1350           1339\n 8  2013     1     1     1044           1045        -1     1352           1351\n 9  2013     1     1     1114            900       134     1447           1222\n10  2013     1     1     1205           1200         5     1503           1505\n# ℹ 7,188 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\n\n\nR code\nflights |&gt;\n  filter(dest == \"IAH\") |&gt; \n  group_by(year, month) |&gt; \n  summarize(\n    arr_delay = mean(arr_delay, na.rm = TRUE)\n  )\n\n\n# A tibble: 12 × 3\n# Groups:   year [1]\n    year month arr_delay\n   &lt;int&gt; &lt;int&gt;     &lt;dbl&gt;\n 1  2013     1     4.16 \n 2  2013     2     5.40 \n 3  2013     3    -1.19 \n 4  2013     4    14.8  \n 5  2013     5     0.972\n 6  2013     6    11.1  \n 7  2013     7    11    \n 8  2013     8     0.705\n 9  2013     9   -10.6  \n10  2013    10     1.81 \n11  2013    11    -1.78 \n12  2013    12    14.5  \n\n\n\n\nAssignment\nIn the first lab with went over assignment of a number or a character sting to a variable\nx &lt;- 2\nThe above code does not create a new variable. After running the code flights is unchanged. This is good in many situations working with large data because we don’t want to be creating new variables that use up more computer memory and it is easier to keep track of fewer variables. If we wish to save the end results, we can assign this to a new variable (e.g. IAH_arr_delay_by_month)\n\n\nR code\nIAH_arr_delay_by_month &lt;- flights |&gt;\n  filter(dest == \"IAH\") |&gt; \n  group_by(year, month) |&gt; \n  summarize(\n    arr_delay = mean(arr_delay, na.rm = TRUE)\n  )\n\n\nNotice that nothing prints out. The new table is put in the data object IAH_arr_delay_by_month. Now you could use this object repeatedly in your code without running the larger code chunk above each time. You can view IAH_arr_delay_by_month by using view(IAH_arr_delay_by_month) or clicking on the object in the Environment window.\n\n\nWriting pseudo code\nWas there a flight on every month of 2013?\nBefore writing any code it is best to break this down into the tasks we need to accomplish\n\nfilter flight data set to the year 2013\nshow only 1 row for each month\ndisplay table to see if each month is present or count to see if rows equal 12\n\nThis is actually the hard part of solving a coding challenge. Writing the codes is relatively easy when you know the steps. This is the greatest challenge in using Generative AI to assist you in coding.\n\n\nR code\nflights |&gt; \n  filter(year == 2013) |&gt; \n  distinct(month)\n\n\n# A tibble: 12 × 1\n   month\n   &lt;int&gt;\n 1     1\n 2    10\n 3    11\n 4    12\n 5     2\n 6     3\n 7     4\n 8     5\n 9     6\n10     7\n11     8\n12     9"
  },
  {
    "objectID": "labs/lab3_tibbles.html#exercises",
    "href": "labs/lab3_tibbles.html#exercises",
    "title": "Lab 3 : Data Transformation with dplyr",
    "section": "Exercises",
    "text": "Exercises\nR for Data Science Chapter 3.\nToday we will walk through Chapter 3 Data Transformation in R for Data Science. As we did last week, by putting the examples and exercises in our own Quarto Markdown file, we can create own personal path through the Chapter.\n\nWhat to upload to Canvas\nAfter you Render the qmd file to an html file, export the file to your computer and upload it to Canvas."
  },
  {
    "objectID": "labs/lab3_data_transformation.html",
    "href": "labs/lab3_data_transformation.html",
    "title": "Lab 3 : Data Transformation with dplyr",
    "section": "",
    "text": "Data Transformation using dplyr"
  },
  {
    "objectID": "labs/lab3_data_transformation.html#learning-objectives",
    "href": "labs/lab3_data_transformation.html#learning-objectives",
    "title": "Lab 3 : Data Transformation with dplyr",
    "section": "",
    "text": "Data Transformation using dplyr"
  },
  {
    "objectID": "labs/lab3_data_transformation.html#load-libaries",
    "href": "labs/lab3_data_transformation.html#load-libaries",
    "title": "Lab 3 : Data Transformation with dplyr",
    "section": "Load libaries",
    "text": "Load libaries\n\n\nR code\nlibrary(tidyverse)\nlibrary(nycflights13)"
  },
  {
    "objectID": "labs/lab3_data_transformation.html#introduction-to-data-transformation",
    "href": "labs/lab3_data_transformation.html#introduction-to-data-transformation",
    "title": "Lab 3 : Data Transformation with dplyr",
    "section": "Introduction to Data Transformation",
    "text": "Introduction to Data Transformation\n\nTables\nHow they are displayed in your qmd file is different from how they are rendered into a html, pdf and other files.\n\n\nPipes and shortcuts\nIn the last few years |&gt; pipe was introduced as a simpler alternative to the %&gt;% pipe that has been used in R and Tidyverse for the last 10 years. In many online examples you will see the %&gt;% used and at times in code from generative AI. For many uses in this class they are interchangeable.\nThe shortcut keys for generative the |&gt; is Ctrl/Cmd + Shift + M.\nThe shortcut keys for a new R code chuck are trl + Alt + I\n\n\nChecking each line of codes are you write it\nToday we will see in Chapter 4 the following code chunk\n\n\nR code\nflights |&gt;\n  filter(dest == \"IAH\") |&gt; \n  group_by(year, month) |&gt; \n  summarize(\n    arr_delay = mean(arr_delay, na.rm = TRUE)\n  )\n\n\n# A tibble: 12 × 3\n# Groups:   year [1]\n    year month arr_delay\n   &lt;int&gt; &lt;int&gt;     &lt;dbl&gt;\n 1  2013     1     4.16 \n 2  2013     2     5.40 \n 3  2013     3    -1.19 \n 4  2013     4    14.8  \n 5  2013     5     0.972\n 6  2013     6    11.1  \n 7  2013     7    11    \n 8  2013     8     0.705\n 9  2013     9   -10.6  \n10  2013    10     1.81 \n11  2013    11    -1.78 \n12  2013    12    14.5  \n\n\nIf I was writing the code I would check (run the code chunk) each line as a wrote it to make sure I was getting the right result and to simplify trouble shooting error messages\n\n\nR code\nflights |&gt;\n  filter(dest == \"IAH\") \n\n\n# A tibble: 7,198 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1      517            515         2      830            819\n 2  2013     1     1      533            529         4      850            830\n 3  2013     1     1      623            627        -4      933            932\n 4  2013     1     1      728            732        -4     1041           1038\n 5  2013     1     1      739            739         0     1104           1038\n 6  2013     1     1      908            908         0     1228           1219\n 7  2013     1     1     1028           1026         2     1350           1339\n 8  2013     1     1     1044           1045        -1     1352           1351\n 9  2013     1     1     1114            900       134     1447           1222\n10  2013     1     1     1205           1200         5     1503           1505\n# ℹ 7,188 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\n\n\nR code\nflights |&gt;\n  filter(dest == \"IAH\") |&gt; \n  group_by(year, month)\n\n\n# A tibble: 7,198 × 19\n# Groups:   year, month [12]\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1      517            515         2      830            819\n 2  2013     1     1      533            529         4      850            830\n 3  2013     1     1      623            627        -4      933            932\n 4  2013     1     1      728            732        -4     1041           1038\n 5  2013     1     1      739            739         0     1104           1038\n 6  2013     1     1      908            908         0     1228           1219\n 7  2013     1     1     1028           1026         2     1350           1339\n 8  2013     1     1     1044           1045        -1     1352           1351\n 9  2013     1     1     1114            900       134     1447           1222\n10  2013     1     1     1205           1200         5     1503           1505\n# ℹ 7,188 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\n\n\nR code\nflights |&gt;\n  filter(dest == \"IAH\") |&gt; \n  group_by(year, month) |&gt; \n  summarize(\n    arr_delay = mean(arr_delay, na.rm = TRUE)\n  )\n\n\n# A tibble: 12 × 3\n# Groups:   year [1]\n    year month arr_delay\n   &lt;int&gt; &lt;int&gt;     &lt;dbl&gt;\n 1  2013     1     4.16 \n 2  2013     2     5.40 \n 3  2013     3    -1.19 \n 4  2013     4    14.8  \n 5  2013     5     0.972\n 6  2013     6    11.1  \n 7  2013     7    11    \n 8  2013     8     0.705\n 9  2013     9   -10.6  \n10  2013    10     1.81 \n11  2013    11    -1.78 \n12  2013    12    14.5  \n\n\n\n\nAssignment\nIn the first lab with went over assignment of a number or a character sting to a variable\nx &lt;- 2\nThe above code does not create a new variable. After running the code flights is unchanged. This is good in many situations working with large data because we don’t want to be creating new variables that use up more computer memory and it is easier to keep track of fewer variables. If we wish to save the end results, we can assign this to a new variable (e.g. IAH_arr_delay_by_month)\n\n\nR code\nIAH_arr_delay_by_month &lt;- flights |&gt;\n  filter(dest == \"IAH\") |&gt; \n  group_by(year, month) |&gt; \n  summarize(\n    arr_delay = mean(arr_delay, na.rm = TRUE)\n  )\n\n\nNotice that nothing prints out. The new table is put in the data object IAH_arr_delay_by_month. Now you could use this object repeatedly in your code without running the larger code chunk above each time. You can view IAH_arr_delay_by_month by using view(IAH_arr_delay_by_month) or clicking on the object in the Environment window.\n\n\nWriting pseudo code\nWas there a flight on every month of 2013?\nBefore writing any code it is best to break this down into the tasks we need to accomplish\n\nfilter flight data set to the year 2013\nshow only 1 row for each month\ndisplay table to see if each month is present or count to see if rows equal 12\n\nThis is actually the hard part of solving a coding challenge. Writing the codes is relatively easy when you know the steps. This is the greatest challenge in using Generative AI to assist you in coding.\n\n\nR code\nflights |&gt; \n  filter(year == 2013) |&gt; \n  distinct(month)\n\n\n# A tibble: 12 × 1\n   month\n   &lt;int&gt;\n 1     1\n 2    10\n 3    11\n 4    12\n 5     2\n 6     3\n 7     4\n 8     5\n 9     6\n10     7\n11     8\n12     9"
  },
  {
    "objectID": "labs/lab3_data_transformation.html#exercises",
    "href": "labs/lab3_data_transformation.html#exercises",
    "title": "Lab 3 : Data Transformation with dplyr",
    "section": "Exercises",
    "text": "Exercises\nR for Data Science Chapter 3.\nToday we will walk through Chapter 3 Data Transformation in R for Data Science. As we did last week, by putting the examples and exercises in our own Quarto Markdown file, we can create own personal path through the Chapter.\n\nWhat to upload to Canvas\nAfter you Render the qmd file to an html file, export the file to your computer and upload it to Canvas."
  },
  {
    "objectID": "labs/lab4_coding_import.html",
    "href": "labs/lab4_coding_import.html",
    "title": "Lab 4 : Coding Basics, Style and Data Read/Write",
    "section": "",
    "text": "Comments\nFunctions\nGood code style\nReading from and writing to files"
  },
  {
    "objectID": "labs/lab4_coding_import.html#learning-objectives",
    "href": "labs/lab4_coding_import.html#learning-objectives",
    "title": "Lab 4 : Coding Basics, Style and Data Read/Write",
    "section": "",
    "text": "Comments\nFunctions\nGood code style\nReading from and writing to files"
  },
  {
    "objectID": "labs/lab4_coding_import.html#exercises",
    "href": "labs/lab4_coding_import.html#exercises",
    "title": "Lab 4 : Coding Basics, Style and Data Read/Write",
    "section": "Exercises",
    "text": "Exercises\nR for Data Science.\nToday we will go through three short chapters in R for Data Science.\n\nChapter 2 Workflow: basics\nChapter 4 Workflow: code style\nChapter 7 Data import.\n\nAs we did last week, put the examples and exercises in a Quarto Markdown file with well organized headings and an outline.\n\nWhat to upload to Canvas\nAfter you Render the qmd file to an html file, export the file to your computer and upload it to Canvas."
  },
  {
    "objectID": "labs/lab4_NEON_tables.html#our-project-space",
    "href": "labs/lab4_NEON_tables.html#our-project-space",
    "title": "Learning R with the help of AI tools starting graphing using ggplot2",
    "section": "Our Project Space",
    "text": "Our Project Space\nNEON has produced metagenomic data as data product since 2014. The Joint Genome Institute has recently annotated version all reads prior to 20222 Gs0144570. However, these metagenomes have a low sequencing depth and therefore are difficult to use for assembling bacterial genomes.\nLast year JGI and NEON collaborated to produce metagenomes which are ~10-fold deeper which allow for better assemble of reads into gene length and greater fragments. We will work with the NEON 2023 data Gs0166454 study sets. By choosing Select Columns for Table we can download metadata associated with each metagenome."
  },
  {
    "objectID": "labs/lab4_NEON_tables.html#on-the-computer",
    "href": "labs/lab4_NEON_tables.html#on-the-computer",
    "title": "Learning R with the help of AI tools starting graphing using ggplot2",
    "section": "On the computer",
    "text": "On the computer"
  },
  {
    "objectID": "labs/EvoGeno_Lab8_tables.html",
    "href": "labs/EvoGeno_Lab8_tables.html",
    "title": "PathoGen",
    "section": "",
    "text": "Introduction to the National Ecological Observatory Network\nIntroduction to the JGI and the Integrated Microbial Genomes and Microbiomes (IMG/MER)\nCreating nicely displayed and interactive tables for reports\nWrangling the NEON data"
  },
  {
    "objectID": "labs/EvoGeno_Lab8_tables.html#learning-objectives",
    "href": "labs/EvoGeno_Lab8_tables.html#learning-objectives",
    "title": "PathoGen",
    "section": "",
    "text": "Introduction to the National Ecological Observatory Network\nIntroduction to the JGI and the Integrated Microbial Genomes and Microbiomes (IMG/MER)\nCreating nicely displayed and interactive tables for reports\nWrangling the NEON data"
  },
  {
    "objectID": "labs/EvoGeno_Lab8_tables.html#background",
    "href": "labs/EvoGeno_Lab8_tables.html#background",
    "title": "PathoGen",
    "section": "Background",
    "text": "Background\nWe will going over the following in class\n\nNEON\nJoint Genome Institute and the Integrated Microbial Genomes and Microbiomes(IMG/MER)\nDOE JGI Metagenome Workflow\nTerabase-scale metagenome coassembly with MetaHipMer\nJGI GOLD database summary of our project"
  },
  {
    "objectID": "labs/EvoGeno_Lab8_tables.html#on-the-computer",
    "href": "labs/EvoGeno_Lab8_tables.html#on-the-computer",
    "title": "PathoGen",
    "section": "On the Computer",
    "text": "On the Computer\n\n\nR code\nlibrary(tidyverse)\nlibrary(knitr)\nlibrary(DT)\n\n\n\nkable\nDon’t display tables with thousands of rows. If you do you may run out of memory and/or you will generate a very large html file.\nBy default, R Markdown displays data frames and matrixes as they would be in the R terminal (in a monospaced font). You have seen already what they look like. Here is an example for the iris data set that is preloaded when you start R. We will make a subset of the table.\n\n\nR code\niris_setosa &lt;- iris %&gt;% \nfilter(Species == \"setosa\") %&gt;% \nfilter(Sepal.Length &gt; 5)\n\n\nTo make a table more readable in a report the knitr::kable function works nice for simple customizable tables.\n\n\nR code\nlibrary(knitr)\nkable(iris_setosa)\n\n\n\n\n\nSepal.Length\nSepal.Width\nPetal.Length\nPetal.Width\nSpecies\n\n\n\n\n5.1\n3.5\n1.4\n0.2\nsetosa\n\n\n5.4\n3.9\n1.7\n0.4\nsetosa\n\n\n5.4\n3.7\n1.5\n0.2\nsetosa\n\n\n5.8\n4.0\n1.2\n0.2\nsetosa\n\n\n5.7\n4.4\n1.5\n0.4\nsetosa\n\n\n5.4\n3.9\n1.3\n0.4\nsetosa\n\n\n5.1\n3.5\n1.4\n0.3\nsetosa\n\n\n5.7\n3.8\n1.7\n0.3\nsetosa\n\n\n5.1\n3.8\n1.5\n0.3\nsetosa\n\n\n5.4\n3.4\n1.7\n0.2\nsetosa\n\n\n5.1\n3.7\n1.5\n0.4\nsetosa\n\n\n5.1\n3.3\n1.7\n0.5\nsetosa\n\n\n5.2\n3.5\n1.5\n0.2\nsetosa\n\n\n5.2\n3.4\n1.4\n0.2\nsetosa\n\n\n5.4\n3.4\n1.5\n0.4\nsetosa\n\n\n5.2\n4.1\n1.5\n0.1\nsetosa\n\n\n5.5\n4.2\n1.4\n0.2\nsetosa\n\n\n5.5\n3.5\n1.3\n0.2\nsetosa\n\n\n5.1\n3.4\n1.5\n0.2\nsetosa\n\n\n5.1\n3.8\n1.9\n0.4\nsetosa\n\n\n5.1\n3.8\n1.6\n0.2\nsetosa\n\n\n5.3\n3.7\n1.5\n0.2\nsetosa\n\n\n\n\n\nkable works for small tables, but even 22 rows is too much to display in a report. If you have larger tables and/or want to make them interactive, the DT works well.\n\n\nDT\n\n\nR code\nlibrary(DT)\ndatatable(iris_setosa)\n\n\n\n\n\n\nThere are two options for using datatable in your R code chunk. (1) Bound the code chunk you want to present by datatable\n\n\nR code\ndatatable(\n  iris %&gt;% \n    filter(Species == \"setosa\") %&gt;% \n    filter(Sepal.Length &gt; 5)\n)\n\n\n\n\n\n\nOr create a new object\n\n\nR code\niris_setosa &lt;- iris %&gt;% \n  filter(Species == \"setosa\") %&gt;% \n  filter(Sepal.Length &gt; 5)\n\ndatatable(iris_setosa)\n\n\n\n\n\n\n\n\nOther popular table making packages\nHere are a few other popular table making packages\n\nkableExtra\nGT\nreactable\n\n\n\nExamples using the NEON data table\nOur data that we will work with today can be found by searching metagenome bins associated with GOLD Study ID Gs0161344 IMG/MER\nA description of the column headers for the file we will work with\n\nBin ID - Metagenome Assemble Genome (MAG) ID\nGenome Name - The metagenome sample name\nIMG Genome ID - The metagenome sample ID\nBin Quality - An estimate of the quality of the bin or MAG\nBin Lineage - Taxonomic lineage using the JGI system\nGTDB-Tk Taxonomy Lineage - Taxonomic lineage using GTDB\nBin Methods - The methods for binning contigs and quality control\nCreated By - The process by which the bins were created\nDate Added - Date sample/metagenome was added\nBin Completeness - An estimate of the completeness of the MAG\nBin Contamination - An estimate of the contamination of the MAG\nTotal Number of Bases - MAG size in bases\n5s rRNA - Count of 5s rRNAs in the MAG\n16s rRNA - Count of 16S rRNAs in the MAG\n23s rRNA - Count of 23s rRNAs in the MAG\ntRNA Genes - Count of tRNA genes in the MAG\nGene Count - Count of number of genes in the MAG\nScaffold Count - Number of separate scaffold comprising the MAG. The ideal would be 1\nGOLD Study ID - The ID in the JGI GOLD database\n\nLet’s load the table into R\n\n\nR code\nNEON_MAGs &lt;- read_tsv(\"../data/NEON_metadata/exported_img_bins_Gs0166454_NEON.tsv\")\n\n\nAs always in the Environment window check to see if the table loaded as expect and what the object types are. Or you can do it in your R console\n\n\nR code\nhead(NEON_MAGs)\n\n\n# A tibble: 6 × 21\n  bin_oid     `Bin ID` `Genome Name` `IMG Genome ID` `Bin Quality` `Bin Lineage`\n  &lt;chr&gt;       &lt;chr&gt;    &lt;chr&gt;                   &lt;dbl&gt; &lt;chr&gt;         &lt;chr&gt;        \n1 3300075492… 3300075… Soil microbi…      3300075492 MQ            Bacteria     \n2 3300075492… 3300075… Soil microbi…      3300075492 MQ            Bacteria     \n3 3300075492… 3300075… Soil microbi…      3300075492 MQ            &lt;NA&gt;         \n4 3300075492… 3300075… Soil microbi…      3300075492 MQ            Bacteria; Ac…\n5 3300075492… 3300075… Soil microbi…      3300075492 MQ            Bacteria; Ac…\n6 3300075492… 3300075… Soil microbi…      3300075492 MQ            Bacteria; Ac…\n# ℹ 15 more variables: `GTDB Taxonomy Lineage` &lt;chr&gt;, `Bin Methods` &lt;chr&gt;,\n#   `Created By` &lt;chr&gt;, `Date Added` &lt;date&gt;, `Bin Completeness` &lt;dbl&gt;,\n#   `Bin Contamination` &lt;dbl&gt;, `Average Coverage` &lt;lgl&gt;,\n#   `Total Number of Bases` &lt;dbl&gt;, `5s rRNA` &lt;dbl&gt;, `16s rRNA` &lt;dbl&gt;,\n#   `23s rRNA` &lt;dbl&gt;, `tRNA Genes` &lt;dbl&gt;, `Gene Count` &lt;dbl&gt;,\n#   `Scaffold Count` &lt;dbl&gt;, `GOLD Study ID` &lt;chr&gt;\n\n\nR code\nstr(NEON_MAGs)\n\n\nspc_tbl_ [16,669 × 21] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ bin_oid              : chr [1:16669] \"3300075492_s0\" \"3300075492_s1\" \"3300075492_s100\" \"3300075492_s106\" ...\n $ Bin ID               : chr [1:16669] \"3300075492_s0\" \"3300075492_s1\" \"3300075492_s100\" \"3300075492_s106\" ...\n $ Genome Name          : chr [1:16669] \"Soil microbial communities from University of Notre Dame Environmental Research Center NEON Field Site, Michiga\"| __truncated__ \"Soil microbial communities from University of Notre Dame Environmental Research Center NEON Field Site, Michiga\"| __truncated__ \"Soil microbial communities from University of Notre Dame Environmental Research Center NEON Field Site, Michiga\"| __truncated__ \"Soil microbial communities from University of Notre Dame Environmental Research Center NEON Field Site, Michiga\"| __truncated__ ...\n $ IMG Genome ID        : num [1:16669] 3.3e+09 3.3e+09 3.3e+09 3.3e+09 3.3e+09 ...\n $ Bin Quality          : chr [1:16669] \"MQ\" \"MQ\" \"MQ\" \"MQ\" ...\n $ Bin Lineage          : chr [1:16669] \"Bacteria\" \"Bacteria\" NA \"Bacteria; Actinomycetota; Thermoleophilia; Solirubrobacterales\" ...\n $ GTDB Taxonomy Lineage: chr [1:16669] \"Bacteria; Acidobacteriota; Terriglobia; Acidoferrales; UBA7541; Acidoferrum\" \"Bacteria; Desulfobacterota_B; Binatia; Binatales; Binataceae; Binatus; Binatus soli\" \"Archaea; Thermoplasmatota; Thermoplasmata; UBA184; UBA184; UBA184\" \"Bacteria; Actinomycetota; Thermoleophilia; Solirubrobacterales; Solirubrobacteraceae; Palsa-744\" ...\n $ Bin Methods          : chr [1:16669] \"SemiBin2:v2.1.0, CheckM2:v1.0.2, GTDB-Tk:v2.4.0, GTDB-Tk-database:release220\" \"SemiBin2:v2.1.0, CheckM2:v1.0.2, GTDB-Tk:v2.4.0, GTDB-Tk-database:release220\" \"SemiBin2:v2.1.0, CheckM2:v1.0.2, GTDB-Tk:v2.4.0, GTDB-Tk-database:release220\" \"SemiBin2:v2.1.0, CheckM2:v1.0.2, GTDB-Tk:v2.4.0, GTDB-Tk-database:release220\" ...\n $ Created By           : chr [1:16669] \"IMG_PIPELINE\" \"IMG_PIPELINE\" \"IMG_PIPELINE\" \"IMG_PIPELINE\" ...\n $ Date Added           : Date[1:16669], format: \"2025-01-23\" \"2025-01-23\" ...\n $ Bin Completeness     : num [1:16669] 95.9 99.6 57.9 74 67.3 ...\n $ Bin Contamination    : num [1:16669] 6.31 0 2.39 8.19 3.95 6.54 5.24 0.63 0.61 4.56 ...\n $ Average Coverage     : logi [1:16669] NA NA NA NA NA NA ...\n $ Total Number of Bases: num [1:16669] 5600425 3706224 1233791 2084993 3809196 ...\n $ 5s rRNA              : num [1:16669] 1 1 1 1 0 0 0 1 1 0 ...\n $ 16s rRNA             : num [1:16669] 2 0 0 1 0 0 0 0 0 0 ...\n $ 23s rRNA             : num [1:16669] 2 1 1 1 0 0 0 1 0 0 ...\n $ tRNA Genes           : num [1:16669] 57 51 30 33 31 33 29 25 30 30 ...\n $ Gene Count           : num [1:16669] 4976 3617 1344 2284 3848 ...\n $ Scaffold Count       : num [1:16669] 26 45 210 322 398 85 527 435 243 409 ...\n $ GOLD Study ID        : chr [1:16669] \"Gs0166454\" \"Gs0166454\" \"Gs0166454\" \"Gs0166454\" ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   bin_oid = col_character(),\n  ..   `Bin ID` = col_character(),\n  ..   `Genome Name` = col_character(),\n  ..   `IMG Genome ID` = col_double(),\n  ..   `Bin Quality` = col_character(),\n  ..   `Bin Lineage` = col_character(),\n  ..   `GTDB Taxonomy Lineage` = col_character(),\n  ..   `Bin Methods` = col_character(),\n  ..   `Created By` = col_character(),\n  ..   `Date Added` = col_date(format = \"\"),\n  ..   `Bin Completeness` = col_double(),\n  ..   `Bin Contamination` = col_double(),\n  ..   `Average Coverage` = col_logical(),\n  ..   `Total Number of Bases` = col_double(),\n  ..   `5s rRNA` = col_double(),\n  ..   `16s rRNA` = col_double(),\n  ..   `23s rRNA` = col_double(),\n  ..   `tRNA Genes` = col_double(),\n  ..   `Gene Count` = col_double(),\n  ..   `Scaffold Count` = col_double(),\n  ..   `GOLD Study ID` = col_character()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\nToday we are just going to work from the assembly of the individual metagenomes, so let’s remove the MAGs from the combined assembly. When working with variable names that have spaces or special characters enclose them with grave accent that looks like a single quote ’ ’, but is not Note that single and double quotes delimit character strings in your variables. They can be used interchangeably but double quotes are preferred, so single quotes are normally only used to delimit character strings containing double quotes.\nCount the number of MQ and HQ genomes\n\n\nR code\nNEON_MAGs %&gt;% \n  count(`Bin Quality`, sort = TRUE) \n\n\n# A tibble: 2 × 2\n  `Bin Quality`     n\n  &lt;chr&gt;         &lt;int&gt;\n1 MQ            15369\n2 HQ             1300\n\n\nMake a knitr::kable table of the bin quality counts\n\n\nR code\nkable(\n  NEON_MAGs %&gt;% \n   count(`Bin Quality`) \n)\n\n\n\n\n\nBin Quality\nn\n\n\n\n\nHQ\n1300\n\n\nMQ\n15369\n\n\n\n\n\nFilter so that Bin Quality = HQ and display in DT::datatable\n\n\nR code\ndatatable(\n  NEON_MAGs%&gt;% \n    filter(`Bin Quality` == \"HQ\")\n)\n\n\n\n\n\n\nSelect the GTDB taxonomy and the MAGs genome size then filter to all MAGs greater than 10,000,000 bases\n\n\nR code\nkable(\nNEON_MAGs %&gt;% \n  select(c(`GTDB Taxonomy Lineage`, `Total Number of Bases`)) %&gt;% \n  filter(`Total Number of Bases` &gt; 10000000)\n)\n\n\n\n\n\n\n\n\n\nGTDB Taxonomy Lineage\nTotal Number of Bases\n\n\n\n\nBacteria; Pseudomonadota; Gammaproteobacteria; Steroidobacterales; Steroidobacteraceae; 13-2-20CM-66-19\n10115899\n\n\nBacteria; Planctomycetota; Planctomycetia; Isosphaerales; Isosphaeraceae\n11932805\n\n\nBacteria; Actinomycetota; Actinomycetes; Streptomycetales; Catenulisporaceae; Catenulispora\n12420050\n\n\nBacteria; Planctomycetota; Planctomycetia; Isosphaerales; Isosphaeraceae; JAJPJC01\n13151516\n\n\nBacteria; Planctomycetota; Planctomycetia; Isosphaerales; Isosphaeraceae\n12046820\n\n\nBacteria; Planctomycetota; Planctomycetia; Isosphaerales; Isosphaeraceae; JAQGHR01\n12217509\n\n\nBacteria; Planctomycetota; Planctomycetia; Isosphaerales; Isosphaeraceae\n12942605\n\n\nBacteria; Actinomycetota; Actinomycetes; Mycobacteriales; Pseudonocardiaceae; Actinophytocola\n11293845\n\n\nBacteria; Planctomycetota; Planctomycetia; Isosphaerales; Isosphaeraceae\n14411455\n\n\nBacteria; Planctomycetota; Planctomycetia; Isosphaerales; Isosphaeraceae\n10890912\n\n\nBacteria; Planctomycetota; Planctomycetia; Pirellulales; JAICIG01; JAICLL01\n11379784\n\n\nBacteria; Acidobacteriota; Terriglobia; Bryobacterales; Bryobacteraceae; PALSA-243\n10475466\n\n\nNA\n10248256\n\n\nBacteria; Pseudomonadota; Alphaproteobacteria; Rhizobiales; Xanthobacteraceae\n10436042\n\n\nBacteria; Planctomycetota; Planctomycetia; Gemmatales; Gemmataceae\n13087515\n\n\nBacteria; Actinomycetota; Actinomycetes; Mycobacteriales; Pseudonocardiaceae; Actinophytocola\n10431101\n\n\nBacteria; Myxococcota; Polyangia; Polyangiales; JAFGIB01\n10030262\n\n\nBacteria; Myxococcota; Polyangia; Polyangiales; Polyangiaceae; JANYGI01\n12560711\n\n\nBacteria; Planctomycetota; Planctomycetia; Isosphaerales; Isosphaeraceae\n11026377\n\n\nBacteria; Planctomycetota; Planctomycetia; Gemmatales; Gemmataceae\n12479517\n\n\nBacteria; Acidobacteriota; Terriglobia; Bryobacterales; Bryobacteraceae; Solibacter\n10617884\n\n\nBacteria; Planctomycetota; Planctomycetia; Isosphaerales; Isosphaeraceae; JAQGHR01\n10431455\n\n\nBacteria; Planctomycetota; Planctomycetia; Isosphaerales; Isosphaeraceae\n12864765\n\n\nBacteria; Actinomycetota; Actinomycetes; Mycobacteriales; Mycobacteriaceae; Mycobacterium\n10583130\n\n\n\n\n\nWe can use the stringr package to filter based on a word or string of characters in a column\n\n\nR code\ndatatable(\nNEON_MAGs %&gt;% \n  filter(str_detect(`GTDB Taxonomy Lineage`, 'Bacteroidota'))\n)\n\n\n\n\n\n\nFilter to include only the samples from Yellowstone NP\n\n\nR code\ndatatable(\nNEON_MAGs %&gt;% \n  filter(str_detect(`Genome Name`, 'Yellowstone NP'))\n)\n\n\n\n\n\n\nSince the the taxonomic categories in GTDB-Tk Taxonomy Lineage are separated by the ; we can use the separate function to create new columns for each of the taxonomic categories. The remove = FALSE keeps the original GTDB-Tk Taxonomy Lineage column\n\n\nR code\nNEON_MAGs_tax &lt;- NEON_MAGs %&gt;% \n  separate(`GTDB Taxonomy Lineage`, c(\"Domain\", \"Phylum\", \"Class\", \"Order\", \"Family\", \"Genus\"), \"; \", remove = FALSE) \n\n\nCount the number of MAGs for each Phylum and display in DT::datatable\n\n\nR code\ndatatable(\n  NEON_MAGs_tax %&gt;% \n    count(Phylum, sort = TRUE)\n)\n\n\n\n\n\n\nNote that there is one category with no name. This were MAGs that were not annotated by GTDB using the JGI pipline (they are Archaea)\nThere is a lot of information in Genome Name. Let’s unpack it into separate columns. Note here where the double quotes and grave accents are used\n\n\nR code\nNEON_MAGs_tax_sample &lt;- NEON_MAGs_tax %&gt;% \n  # Get rid of the the common string \"Soil microbial communities from \"\n  mutate_at(\"Genome Name\", str_replace, \"Terrestrial soil microbial communities from \", \"\") %&gt;% \n  # Use the first `-` to split the column in two\n  separate(`Genome Name`, c(\"Site\",\"Sample Name\"), \" - \") %&gt;% \n  # Get rid of the the common string \"S-comp-1\"\n  mutate_at(\"Sample Name\", str_replace, \"-comp-1\", \"\") %&gt;%\n  # separate the Sample Name into Site ID and plot info\n  separate(`Sample Name`, c(\"Site ID\",\"subplot.layer.date\"), \"_\", remove = FALSE,) %&gt;% \n  # separate the plot info into 3 columns\n  separate(`subplot.layer.date`, c(\"Subplot\", \"Layer\", \"Date\"), \"-\") \n\n\nCheck this out in the Environment window to make sure with got it right.\nLet’s see which Site has the most MAGs\n\n\nR code\ndatatable(\n  NEON_MAGs_tax_sample %&gt;% \n    count(Site, sort = TRUE)\n)"
  },
  {
    "objectID": "labs/EvoGeno_Lab8_tables.html#exercises",
    "href": "labs/EvoGeno_Lab8_tables.html#exercises",
    "title": "PathoGen",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1\nUse view(iris) to see the whole data table. Subset the table based on a different species than was used in the example. Display the table using DT::datatable\n\n\nExercise 2\nDisplay using DT::datatable the NEON MAGs from the individual assemblies that have at least 1 16S rRNA\n\n\nExercise 3\nDisplay a table of the MAGs from Lower Teakettle with only the columns for the Genome Name, GTDB-Tk Taxonomy Lineage, and estimated MAG genome size.\n\n\nExercise 4\nDisplay a table with the Class counts at LBJ National Grasslands\n\n\nExercise 5\nDisplay a table with the counts for the Phylum Actinobacteriota at each Site"
  },
  {
    "objectID": "labs/lab5_NEON_tables.html#our-project-space",
    "href": "labs/lab5_NEON_tables.html#our-project-space",
    "title": "Lab 5 : Working with NEON Metagenome Assembled Genomes (MAGs / bins)",
    "section": "Our Project Space",
    "text": "Our Project Space\nNEON has produced metagenomic data as data product since 2014. The Joint Genome Institute has recently annotated version all reads prior to 20222 Gs0144570. However, these metagenomes have a low sequencing depth and therefore are difficult to use for assembling bacterial genomes.\nLast year JGI and NEON collaborated to produce metagenomes which are ~10-fold deeper which allow for better assemble of reads into gene length and greater fragments. We will work with the NEON 2023 and 2024 data Gs0166454 study sets."
  },
  {
    "objectID": "labs/lab5_NEON_tables.html#on-the-computer",
    "href": "labs/lab5_NEON_tables.html#on-the-computer",
    "title": "Lab 5 : Working with NEON Metagenome Assembled Genomes (MAGs / bins)",
    "section": "On the Computer",
    "text": "On the Computer\n\n\nR code\nlibrary(tidyverse)\nlibrary(knitr)\nlibrary(janitor)\nlibrary(DT)\n\n\n\nkable\nDon’t display tables with thousands of rows. If you do you may run out of memory and/or you will generate a very large html file.\nBy default, Quarto displays data frames and matrixes as they would be in the R terminal (in a monospaced font). You have seen already what they look like. Here is an example for the iris data set that is preloaded when you start R. We will make a subset of the table.\n\n\nR code\niris_setosa &lt;- iris |&gt; \nfilter(Species == \"setosa\") |&gt; \nfilter(Sepal.Length &gt; 5)\n\n\nTo make a table more readable in a report the knitr::kable function works nice for simple customizable tables.\n\n\nR code\nlibrary(knitr)\nkable(iris_setosa)\n\n\n\n\n\nSepal.Length\nSepal.Width\nPetal.Length\nPetal.Width\nSpecies\n\n\n\n\n5.1\n3.5\n1.4\n0.2\nsetosa\n\n\n5.4\n3.9\n1.7\n0.4\nsetosa\n\n\n5.4\n3.7\n1.5\n0.2\nsetosa\n\n\n5.8\n4.0\n1.2\n0.2\nsetosa\n\n\n5.7\n4.4\n1.5\n0.4\nsetosa\n\n\n5.4\n3.9\n1.3\n0.4\nsetosa\n\n\n5.1\n3.5\n1.4\n0.3\nsetosa\n\n\n5.7\n3.8\n1.7\n0.3\nsetosa\n\n\n5.1\n3.8\n1.5\n0.3\nsetosa\n\n\n5.4\n3.4\n1.7\n0.2\nsetosa\n\n\n5.1\n3.7\n1.5\n0.4\nsetosa\n\n\n5.1\n3.3\n1.7\n0.5\nsetosa\n\n\n5.2\n3.5\n1.5\n0.2\nsetosa\n\n\n5.2\n3.4\n1.4\n0.2\nsetosa\n\n\n5.4\n3.4\n1.5\n0.4\nsetosa\n\n\n5.2\n4.1\n1.5\n0.1\nsetosa\n\n\n5.5\n4.2\n1.4\n0.2\nsetosa\n\n\n5.5\n3.5\n1.3\n0.2\nsetosa\n\n\n5.1\n3.4\n1.5\n0.2\nsetosa\n\n\n5.1\n3.8\n1.9\n0.4\nsetosa\n\n\n5.1\n3.8\n1.6\n0.2\nsetosa\n\n\n5.3\n3.7\n1.5\n0.2\nsetosa\n\n\n\n\n\nkable works for small tables, but even 22 rows is too much to display in a report. If you have larger tables and/or want to make them interactive, the DT works well.\n\n\nDT\n\n\nR code\nlibrary(DT)\ndatatable(iris_setosa)\n\n\n\n\n\n\nThere are two options for using datatable in your R code chunk. (1) Bound the code chunk you want to present by datatable\n\n\nR code\ndatatable(\n  iris |&gt; \n    filter(Species == \"setosa\") |&gt; \n    filter(Sepal.Length &gt; 5)\n)\n\n\n\n\n\n\nOr create a new object\n\n\nR code\niris_setosa &lt;- iris |&gt; \n  filter(Species == \"setosa\") |&gt; \n  filter(Sepal.Length &gt; 5)\n\ndatatable(iris_setosa)\n\n\n\n\n\n\n\n\nOther popular table making packages\nHere are a few other popular table making packages\n\nkableExtra\nGT\nreactable\n\n\n\nExamples using the NEON data table\nOur data that we will work with today can be found by searching metagenome bins associated with GOLD Study ID Gs0161344 IMG/MER\nA description of the column headers for the file we will work with\n\nBin ID - Metagenome Assemble Genome (MAG) ID\nGenome Name - The metagenome sample name\nIMG Genome ID - The metagenome sample ID\nBin Quality - An estimate of the quality of the bin or MAG\nBin Lineage - Taxonomic lineage using the JGI system\nGTDB-Tk Taxonomy Lineage - Taxonomic lineage using GTDB\nBin Methods - The methods for binning contigs and quality control\nCreated By - The process by which the bins were created\nDate Added - Date sample/metagenome was added\nBin Completeness - An estimate of the completeness of the MAG\nBin Contamination - An estimate of the contamination of the MAG\nTotal Number of Bases - MAG size in bases\n5s rRNA - Count of 5s rRNAs in the MAG\n16s rRNA - Count of 16S rRNAs in the MAG\n23s rRNA - Count of 23s rRNAs in the MAG\ntRNA Genes - Count of tRNA genes in the MAG\nGene Count - Count of number of genes in the MAG\nScaffold Count - Number of separate scaffold comprising the MAG. The ideal would be 1\nGOLD Study ID - The ID in the JGI GOLD database\n\nLet’s load the table into R\n\n\nR code\n# This is the location used for Github\nNEON_MAGs &lt;- read_tsv(\"../data/NEON_metadata/exported_img_bins_Gs0166454_NEON.tsv\")\n# This is the location used for the class data directory on Unity\n# NEON_MAGs &lt;- read_tsv(\"/work/pi_bio678_umass_edu/data_NEON/exported_img_bins_Gs0166454_NEON.tsv\")\n\n\nAs always in the Environment window check to see if the table loaded as expect and what the object types are. Or you can do it in your R console\n\n\nR code\nhead(NEON_MAGs)\n\n\n# A tibble: 6 × 21\n  bin_oid     `Bin ID` `Genome Name` `IMG Genome ID` `Bin Quality` `Bin Lineage`\n  &lt;chr&gt;       &lt;chr&gt;    &lt;chr&gt;                   &lt;dbl&gt; &lt;chr&gt;         &lt;chr&gt;        \n1 3300075492… 3300075… Soil microbi…      3300075492 MQ            Bacteria     \n2 3300075492… 3300075… Soil microbi…      3300075492 MQ            Bacteria     \n3 3300075492… 3300075… Soil microbi…      3300075492 MQ            &lt;NA&gt;         \n4 3300075492… 3300075… Soil microbi…      3300075492 MQ            Bacteria; Ac…\n5 3300075492… 3300075… Soil microbi…      3300075492 MQ            Bacteria; Ac…\n6 3300075492… 3300075… Soil microbi…      3300075492 MQ            Bacteria; Ac…\n# ℹ 15 more variables: `GTDB Taxonomy Lineage` &lt;chr&gt;, `Bin Methods` &lt;chr&gt;,\n#   `Created By` &lt;chr&gt;, `Date Added` &lt;date&gt;, `Bin Completeness` &lt;dbl&gt;,\n#   `Bin Contamination` &lt;dbl&gt;, `Average Coverage` &lt;lgl&gt;,\n#   `Total Number of Bases` &lt;dbl&gt;, `5s rRNA` &lt;dbl&gt;, `16s rRNA` &lt;dbl&gt;,\n#   `23s rRNA` &lt;dbl&gt;, `tRNA Genes` &lt;dbl&gt;, `Gene Count` &lt;dbl&gt;,\n#   `Scaffold Count` &lt;dbl&gt;, `GOLD Study ID` &lt;chr&gt;\n\n\nR code\nstr(NEON_MAGs)\n\n\nspc_tbl_ [16,669 × 21] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ bin_oid              : chr [1:16669] \"3300075492_s0\" \"3300075492_s1\" \"3300075492_s100\" \"3300075492_s106\" ...\n $ Bin ID               : chr [1:16669] \"3300075492_s0\" \"3300075492_s1\" \"3300075492_s100\" \"3300075492_s106\" ...\n $ Genome Name          : chr [1:16669] \"Soil microbial communities from University of Notre Dame Environmental Research Center NEON Field Site, Michiga\"| __truncated__ \"Soil microbial communities from University of Notre Dame Environmental Research Center NEON Field Site, Michiga\"| __truncated__ \"Soil microbial communities from University of Notre Dame Environmental Research Center NEON Field Site, Michiga\"| __truncated__ \"Soil microbial communities from University of Notre Dame Environmental Research Center NEON Field Site, Michiga\"| __truncated__ ...\n $ IMG Genome ID        : num [1:16669] 3.3e+09 3.3e+09 3.3e+09 3.3e+09 3.3e+09 ...\n $ Bin Quality          : chr [1:16669] \"MQ\" \"MQ\" \"MQ\" \"MQ\" ...\n $ Bin Lineage          : chr [1:16669] \"Bacteria\" \"Bacteria\" NA \"Bacteria; Actinomycetota; Thermoleophilia; Solirubrobacterales\" ...\n $ GTDB Taxonomy Lineage: chr [1:16669] \"Bacteria; Acidobacteriota; Terriglobia; Acidoferrales; UBA7541; Acidoferrum\" \"Bacteria; Desulfobacterota_B; Binatia; Binatales; Binataceae; Binatus; Binatus soli\" \"Archaea; Thermoplasmatota; Thermoplasmata; UBA184; UBA184; UBA184\" \"Bacteria; Actinomycetota; Thermoleophilia; Solirubrobacterales; Solirubrobacteraceae; Palsa-744\" ...\n $ Bin Methods          : chr [1:16669] \"SemiBin2:v2.1.0, CheckM2:v1.0.2, GTDB-Tk:v2.4.0, GTDB-Tk-database:release220\" \"SemiBin2:v2.1.0, CheckM2:v1.0.2, GTDB-Tk:v2.4.0, GTDB-Tk-database:release220\" \"SemiBin2:v2.1.0, CheckM2:v1.0.2, GTDB-Tk:v2.4.0, GTDB-Tk-database:release220\" \"SemiBin2:v2.1.0, CheckM2:v1.0.2, GTDB-Tk:v2.4.0, GTDB-Tk-database:release220\" ...\n $ Created By           : chr [1:16669] \"IMG_PIPELINE\" \"IMG_PIPELINE\" \"IMG_PIPELINE\" \"IMG_PIPELINE\" ...\n $ Date Added           : Date[1:16669], format: \"2025-01-23\" \"2025-01-23\" ...\n $ Bin Completeness     : num [1:16669] 95.9 99.6 57.9 74 67.3 ...\n $ Bin Contamination    : num [1:16669] 6.31 0 2.39 8.19 3.95 6.54 5.24 0.63 0.61 4.56 ...\n $ Average Coverage     : logi [1:16669] NA NA NA NA NA NA ...\n $ Total Number of Bases: num [1:16669] 5600425 3706224 1233791 2084993 3809196 ...\n $ 5s rRNA              : num [1:16669] 1 1 1 1 0 0 0 1 1 0 ...\n $ 16s rRNA             : num [1:16669] 2 0 0 1 0 0 0 0 0 0 ...\n $ 23s rRNA             : num [1:16669] 2 1 1 1 0 0 0 1 0 0 ...\n $ tRNA Genes           : num [1:16669] 57 51 30 33 31 33 29 25 30 30 ...\n $ Gene Count           : num [1:16669] 4976 3617 1344 2284 3848 ...\n $ Scaffold Count       : num [1:16669] 26 45 210 322 398 85 527 435 243 409 ...\n $ GOLD Study ID        : chr [1:16669] \"Gs0166454\" \"Gs0166454\" \"Gs0166454\" \"Gs0166454\" ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   bin_oid = col_character(),\n  ..   `Bin ID` = col_character(),\n  ..   `Genome Name` = col_character(),\n  ..   `IMG Genome ID` = col_double(),\n  ..   `Bin Quality` = col_character(),\n  ..   `Bin Lineage` = col_character(),\n  ..   `GTDB Taxonomy Lineage` = col_character(),\n  ..   `Bin Methods` = col_character(),\n  ..   `Created By` = col_character(),\n  ..   `Date Added` = col_date(format = \"\"),\n  ..   `Bin Completeness` = col_double(),\n  ..   `Bin Contamination` = col_double(),\n  ..   `Average Coverage` = col_logical(),\n  ..   `Total Number of Bases` = col_double(),\n  ..   `5s rRNA` = col_double(),\n  ..   `16s rRNA` = col_double(),\n  ..   `23s rRNA` = col_double(),\n  ..   `tRNA Genes` = col_double(),\n  ..   `Gene Count` = col_double(),\n  ..   `Scaffold Count` = col_double(),\n  ..   `GOLD Study ID` = col_character()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\nYou might also notice that many columns are surrounded by backticks. That’s because they contain spaces, breaking R’s usual rules for variable names; they’re non-syntactic names. To refer to these variables, you need to surround them with backticks, `. Last week in Chapter 7 we used janitor::clean_names() to use some heuristics to turn them all into snake case at once.\n\n\nR code\nNEON_MAGs &lt;- NEON_MAGs |&gt; janitor::clean_names()\n\n\nCount the number of MQ and HQ genomes\n\n\nR code\nNEON_MAGs |&gt; \n  count(bin_quality, sort = TRUE) \n\n\n# A tibble: 2 × 2\n  bin_quality     n\n  &lt;chr&gt;       &lt;int&gt;\n1 MQ          15369\n2 HQ           1300\n\n\nMake a knitr::kable table of the bin quality counts\n\n\nR code\nkable(\n  NEON_MAGs |&gt; \n   count(bin_quality) \n)\n\n\n\n\n\nbin_quality\nn\n\n\n\n\nHQ\n1300\n\n\nMQ\n15369\n\n\n\n\n\nFilter so that Bin Quality = HQ and display in DT::datatable\n\n\nR code\ndatatable(\n  NEON_MAGs|&gt; \n    filter(bin_quality == \"HQ\")\n)\n\n\n\n\n\n\nSelect the GTDB taxonomy and the MAGs genome size then filter to all MAGs greater than 10,000,000 bases\n\n\nR code\nkable(\nNEON_MAGs |&gt; \n  select(c(gtdb_taxonomy_lineage, total_number_of_bases)) |&gt; \n  filter(total_number_of_bases &gt; 10000000)\n)\n\n\n\n\n\n\n\n\n\ngtdb_taxonomy_lineage\ntotal_number_of_bases\n\n\n\n\nBacteria; Pseudomonadota; Gammaproteobacteria; Steroidobacterales; Steroidobacteraceae; 13-2-20CM-66-19\n10115899\n\n\nBacteria; Planctomycetota; Planctomycetia; Isosphaerales; Isosphaeraceae\n11932805\n\n\nBacteria; Actinomycetota; Actinomycetes; Streptomycetales; Catenulisporaceae; Catenulispora\n12420050\n\n\nBacteria; Planctomycetota; Planctomycetia; Isosphaerales; Isosphaeraceae; JAJPJC01\n13151516\n\n\nBacteria; Planctomycetota; Planctomycetia; Isosphaerales; Isosphaeraceae\n12046820\n\n\nBacteria; Planctomycetota; Planctomycetia; Isosphaerales; Isosphaeraceae; JAQGHR01\n12217509\n\n\nBacteria; Planctomycetota; Planctomycetia; Isosphaerales; Isosphaeraceae\n12942605\n\n\nBacteria; Actinomycetota; Actinomycetes; Mycobacteriales; Pseudonocardiaceae; Actinophytocola\n11293845\n\n\nBacteria; Planctomycetota; Planctomycetia; Isosphaerales; Isosphaeraceae\n14411455\n\n\nBacteria; Planctomycetota; Planctomycetia; Isosphaerales; Isosphaeraceae\n10890912\n\n\nBacteria; Planctomycetota; Planctomycetia; Pirellulales; JAICIG01; JAICLL01\n11379784\n\n\nBacteria; Acidobacteriota; Terriglobia; Bryobacterales; Bryobacteraceae; PALSA-243\n10475466\n\n\nNA\n10248256\n\n\nBacteria; Pseudomonadota; Alphaproteobacteria; Rhizobiales; Xanthobacteraceae\n10436042\n\n\nBacteria; Planctomycetota; Planctomycetia; Gemmatales; Gemmataceae\n13087515\n\n\nBacteria; Actinomycetota; Actinomycetes; Mycobacteriales; Pseudonocardiaceae; Actinophytocola\n10431101\n\n\nBacteria; Myxococcota; Polyangia; Polyangiales; JAFGIB01\n10030262\n\n\nBacteria; Myxococcota; Polyangia; Polyangiales; Polyangiaceae; JANYGI01\n12560711\n\n\nBacteria; Planctomycetota; Planctomycetia; Isosphaerales; Isosphaeraceae\n11026377\n\n\nBacteria; Planctomycetota; Planctomycetia; Gemmatales; Gemmataceae\n12479517\n\n\nBacteria; Acidobacteriota; Terriglobia; Bryobacterales; Bryobacteraceae; Solibacter\n10617884\n\n\nBacteria; Planctomycetota; Planctomycetia; Isosphaerales; Isosphaeraceae; JAQGHR01\n10431455\n\n\nBacteria; Planctomycetota; Planctomycetia; Isosphaerales; Isosphaeraceae\n12864765\n\n\nBacteria; Actinomycetota; Actinomycetes; Mycobacteriales; Mycobacteriaceae; Mycobacterium\n10583130\n\n\n\n\n\nWe can use the stringr package to filter based on a word or string of characters in a column\n\n\nR code\ndatatable(\nNEON_MAGs |&gt; \n  filter(str_detect(gtdb_taxonomy_lineage, 'Bacteroidota'))\n)\n\n\n\n\n\n\nFilter to include only the samples from Yellowstone NP\n\n\nR code\ndatatable(\nNEON_MAGs |&gt; \n  filter(str_detect(genome_name, 'Yellowstone NP'))\n)\n\n\n\n\n\n\nSince the the taxonomic categories in GTDB-Tk Taxonomy Lineage are separated by the ; we can use the separate function to create new columns for each of the taxonomic categories. The remove = FALSE keeps the original GTDB-Tk Taxonomy Lineage column\n\n\nR code\nNEON_MAGs_tax &lt;- NEON_MAGs |&gt; \n  separate(gtdb_taxonomy_lineage, c(\"domain\", \"phylum\", \"class\", \"order\", \"family\", \"genus\"), \"; \", remove = FALSE) \n\n\nCount the number of MAGs for each Phylum and display in DT::datatable\n\n\nR code\ndatatable(\n  NEON_MAGs_tax |&gt; \n    count(phylum, sort = TRUE)\n)\n\n\n\n\n\n\nNote that there is one category with no name. This were MAGs that were not annotated by GTDB using the JGI pipline (they are Archaea)\nThere is a lot of information in genome_name. Let’s unpack it into separate columns. Note here where the double quotes and grave accents are used\n\n\nR code\nNEON_MAGs_tax_sample &lt;- NEON_MAGs_tax |&gt; \n  # Get rid of the the common string \"Soil microbial communities from \"\n  mutate_at(\"genome_name\", str_replace, \"Terrestrial soil microbial communities from \", \"\") |&gt; \n  # Use the first `-` to split the column in two\n  separate(genome_name, c(\"site\",\"sample_name\"), \" - \") |&gt; \n  # Get rid of the the common string \"S-comp-1\"\n  mutate_at(\"sample_name\", str_replace, \"-comp-1\", \"\") |&gt;\n  # separate the Sample Name into Site ID and plot info\n  separate(sample_name, c(\"site_ID\",\"subplot.layer.date\"), \"_\", remove = FALSE,) |&gt; \n  # separate the plot info into 3 columns\n  separate(`subplot.layer.date`, c(\"subplot\", \"layer\", \"date\"), \"-\") \n\n\nCheck this out in the Environment window to make sure with got it right.\nLet’s see which Site has the most MAGs\n\n\nR code\ndatatable(\n  NEON_MAGs_tax_sample |&gt; \n    count(site, sort = TRUE)\n)"
  },
  {
    "objectID": "labs/lab5_NEON_tables.html",
    "href": "labs/lab5_NEON_tables.html",
    "title": "Lab 5 : Working with NEON Metagenome Assembled Genomes (MAGs / bins)",
    "section": "",
    "text": "Introduction to the National Ecological Observatory Network\nIntroduction to the JGI and the Integrated Microbial Genomes and Microbiomes (IMG/MER)\nCreating nicely displayed and interactive tables for reports\nWrangling the NEON data"
  },
  {
    "objectID": "labs/lab5_NEON_tables.html#learning-objectives",
    "href": "labs/lab5_NEON_tables.html#learning-objectives",
    "title": "Lab 5 : Working with NEON Metagenome Assembled Genomes (MAGs / bins)",
    "section": "",
    "text": "Introduction to the National Ecological Observatory Network\nIntroduction to the JGI and the Integrated Microbial Genomes and Microbiomes (IMG/MER)\nCreating nicely displayed and interactive tables for reports\nWrangling the NEON data"
  },
  {
    "objectID": "labs/lab5_NEON_tables.html#background",
    "href": "labs/lab5_NEON_tables.html#background",
    "title": "Lab 5 : Working with NEON Metagenome Assembled Genomes (MAGs / bins)",
    "section": "Background",
    "text": "Background\nWe will going over the following in class\n\nNEON\nJoint Genome Institute and the Integrated Microbial Genomes and Microbiomes(IMG/MER)\nDOE JGI Metagenome Workflow\nJGI GOLD database summary of our project"
  },
  {
    "objectID": "labs/lab5_NEON_tables.html#exercises",
    "href": "labs/lab5_NEON_tables.html#exercises",
    "title": "Lab 5 : Working with NEON Metagenome Assembled Genomes (MAGs / bins)",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1\nUse view(iris) to see the whole data table. Subset the table based on a different species than was used in the example. Display the table using DT::datatable\n\n\nExercise 2\nDisplay using DT::datatable the NEON MAGs that have at least 1 16S rRNA\n\n\nExercise 3\nDisplay a table of the MAGs from Lower Tombigbee with only the columns for the genome_name, gtdb_taxonomy_lineage, and estimated MAG genome size (total_number_of_bases).\n\n\nExercise 4\nDisplay a table with the counts of each class names at Lyndon B. Johnson National Grasslands.\n\n\nExercise 5\nDisplay a table with the counts for the Phylum Actinomycetota at each Site."
  },
  {
    "objectID": "labs/tesy.html",
    "href": "labs/tesy.html",
    "title": "Lab 5 : Working with NEON Metagenome Assembled Genomes (MAGs / bins)",
    "section": "",
    "text": "R code\nlibrary(tidyverse)\n\n\n\n\nR code\nsimple_csv &lt;- \"\n  x\n  10\n  .\n  20\n  30\"\n\n\n\n\nR code\nread_csv(simple_csv)\n\n\n# A tibble: 4 × 1\n  x    \n  &lt;chr&gt;\n1 10   \n2 .    \n3 20   \n4 30"
  },
  {
    "objectID": "labs/lab6_biblio.html",
    "href": "labs/lab6_biblio.html",
    "title": "Lab 6s : Adding references exported from Zotero to your quarto documents",
    "section": "",
    "text": "Adding references exported from Zotero to your report"
  },
  {
    "objectID": "labs/lab6_biblio.html#learning-objectives",
    "href": "labs/lab6_biblio.html#learning-objectives",
    "title": "Lab 6s : Adding references exported from Zotero to your quarto documents",
    "section": "",
    "text": "Adding references exported from Zotero to your report"
  },
  {
    "objectID": "labs/lab6_biblio.html#background",
    "href": "labs/lab6_biblio.html#background",
    "title": "Lab 6s : Adding references exported from zotero to your quarto documents",
    "section": "Background",
    "text": "Background\n\nZotero"
  },
  {
    "objectID": "labs/lab6_biblio.html#adding-references-to-your-report",
    "href": "labs/lab6_biblio.html#adding-references-to-your-report",
    "title": "Lab 6s : Adding references exported from Zotero to your quarto documents",
    "section": "Adding references to your report",
    "text": "Adding references to your report\n\nStep 1: Set up Zotero on your computer\nDownload Zotero to your computer and add the Zotero plugin to your web browser.\n\n\nStep 2: Get references from Zotero\nGo to PubMed and search for metagenome. Add 3 articles to your Zotero database\n\n\nStep 3: Export the 3 references from Zotero\n\nSelect the 3 references and select File &gt; Export Library\nExport in BibTeX format. This will generate a file with a .bib extension. Do not include any spaces in your file name.\nUpload the .bib file to Unity.\n\n\n\nStep 4: Add the file name of your references library to your YAML block\n---\ntitle: \"Lab 6\"\nauthor: \"Your name\"\nformat:\n  html:\n    toc: true\n    toc_float: true\n    embed-resources: true\nexecute: \n  warning: false\n  message: false\nbibliography: MyReferences.bib\n---\n\n\nStep 5: Cite the references in the text of your document\nMy reference file looks like this.\n@Misc{Chang2015,\n  Title                    = {shiny: Web Application Framework for R. R package version 0.12.1},\n\n  Author                   = {Chang, W. and Cheng, J. and Allaire, JJ. and Xie, Y. and McPherson, J. },\n  Year                     = {2015},\n\n  Type                     = {Computer Program},\n  Url                      = {http://CRAN.R-project.org/package=shiny}\n}\n\n\n@Article{RCoreTeam,\n  Title                    = {R: A Language and Environment for Statistical Computing},\n  Author                   = {{R Core Team}},\n  Year                     = {2015},\n\n  Type                     = {Journal Article},\n  Url                      = {http://www.R-project.org}\n}\nTo cite this in my document I would use the following format.\nApplication written in R [@RCoreTeam] using the Shiny framework [@Chang2015].\n\n\nAdd a section header for the references at the end of your document\nWhen you Render the document the references will be added to the end of the document. To define this section and to make it visable in our outline put # References on the last line (or the appropriate header level for your report)."
  },
  {
    "objectID": "labs/lab6_biblio.html#exercises",
    "href": "labs/lab6_biblio.html#exercises",
    "title": "Lab 6s : Adding references exported from Zotero to your quarto documents",
    "section": "Exercises",
    "text": "Exercises\nMake a document that has 3 references."
  },
  {
    "objectID": "labs/lab6_biblio.html#acknowledgements",
    "href": "labs/lab6_biblio.html#acknowledgements",
    "title": "Lab 6s : Adding references exported from Zotero to your quarto documents",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nOur labs are written in R (R Core Team 2015) and past labs have used th Shiny framework (Chang et al. 2015)."
  },
  {
    "objectID": "labs/lab1m_quarto.html",
    "href": "labs/lab1m_quarto.html",
    "title": "Lab 1s - Quarto",
    "section": "",
    "text": "Quarto\nDifferences between R Markdown and Quarto\nYAML blocks\nCode blocks\n\n\n\n\n\nQuarto is the name of an open-source publishing system used for technical and scientific writing.\nIt lets you combine text, code, and outputs in one document—perfect for data science, research, and reproducible reports.\nYou can write in Python, R, Julia, or Observable JavaScript, and publish to formats like HTML, PDF, Word, and even full websites\nIt’s considered the next generation of R Markdown, and works with tools like Jupyter Notebooks, VS Code, and RStudio.\nBecause it is based on R Markdown, there is a wealth of related resources and books published on and using R Markdown. See some of on the examples books using R we will periodically using in the course.\n\n\n\n\nR Markdown and Quarto are both tools for creating dynamic documents that combine code, text, and outputs (like plots or tables), but they differ in terms of design philosophy, features, and flexibility. Here’s a breakdown of their key differences:\n\n\n\nR Markdown:\n\nDeveloped by RStudio.\nPrimarily designed for R users.\nBuilt on top of knitr and Pandoc.\nDeeply integrated into the RStudio IDE.\n\nQuarto:\n\nAlso developed by RStudio, but as a next-generation tool.\nLanguage-agnostic: supports R, Python, Julia, and Observable JavaScript.\nUses Pandoc directly (not knitr).\nDesigned to unify and modernize the workflow across languages.\n\n\n\n\n\n\nR Markdown: Best suited for R. Python support is possible but less seamless.\nQuarto: First-class support for multiple languages in a single document. You can mix R, Python, Julia, and JavaScript.\n\n\n\n\n\nR Markdown:\n\nUses YAML front matter for metadata.\nCode chunks are written using triple backticks with language identifiers.\n\nQuarto:\n\nSimilar structure but more consistent and extensible YAML.\nSupports Markdown extensions like callouts, citations, cross-referencing, and more.\n\n\n\n\n\n\nR Markdown:\n\nSupports HTML, PDF, Word, slides (via xaringan or ioslides), etc.\nCustomization can be complex for advanced layouts.\n\nQuarto:\n\nSupports all R Markdown formats plus:\n\nReveal.js slides.\nBooks and websites with built-in navigation and styling.\nJupyter-style notebooks.\n\nEasier to configure and customize outputs.\n\n\n\n\n\n\nR Markdown:\n\nExecutes code using knitr (for R) or reticulate (for Python).\nLess control over execution environment.\n\nQuarto:\n\nUses Jupyter kernels or R directly.\nBetter support for notebook-style interactivity and execution control.\n\n\n\n\n\n\nR Markdown:\n\nNo native concept of a “project” beyond RStudio projects.\n\nQuarto:\n\nSupports Quarto Projects: collections of documents with shared configuration.\nIdeal for books, blogs, websites, and multi-document workflows.\n\n\n\n\n\n\nQuarto:\n\nMore modern and extensible.\nSupports Lua filters, Markdown extensions, cross-referencing, citations, and interactive widgets.\nBetter support for version control and CI/CD workflows.\n\n\n\n\n\n\n\n\nFeature\nR Markdown\nQuarto\n\n\n\n\nLanguage Support\nPrimarily R\nR, Python, Julia, JS\n\n\nExecution Engine\nknitr\nJupyter / native\n\n\nOutput Formats\nMany\nMore + easier config\n\n\nInteractivity\nLimited\nRich (widgets, JS)\n\n\nProject Support\nBasic\nFull project system\n\n\nExtensibility\nModerate\nHigh\n\n\nIdeal For\nR-centric reports\nMulti-language docs\n\n\n\n\n\n\n\n\nLet’s go the the Quarto documentation for Markdown basics and more details on Figures\nIt is important to specific where the figure is located relative to your .qmd file. The path can be relative (giant_virus.jpg) or (images/giant_virus.jpg) or absolute (/home/pi_jlb_umass_edu/images/giant_virus.jpg).\n\n\n\ngiant virus\n\n\n\n\n\nIn Quarto, a YAML block is a section at the top of a document that contains metadata and configuration settings. YAML stands for “YAML Ain’t Markup Language”, and it’s used to define things like the document title, author, output format, and more.\n\n\nA YAML block is enclosed by triple dashes (---) at the beginning and end:\n---\ntitle: \"My Analysis Report\"\nauthor: \"Jeffrey Blanchard\"\ndate: \"2025-09-08\"\nformat: html\neditor: visual\n---\nThis block tells Quarto: - The title of the document. - The author name. - The date to display. - The output format (e.g., HTML, PDF, Word). - The editor preference (e.g., visual or source).\n\n\n\nHere are some frequently used fields:\n\n\n\n\n\n\n\nField\nDescription\n\n\n\n\ntitle\nTitle of the document\n\n\nauthor\nAuthor name(s)\n\n\ndate\nDate of publication\n\n\nformat\nOutput format (e.g., html, pdf, docx, revealjs)\n\n\ntoc\nTable of contents (true or false)\n\n\nnumber-sections\nNumber section headings\n\n\ntheme\nVisual theme for HTML or slides\n\n\ncode-fold\nWhether code chunks can be collapsed\n\n\nexecute\nControls code execution (e.g., echo, eval, freeze)\n\n\nbibliography\nPath to .bib file for citations\n\n\nfilters\nLua filters for advanced customization\n\n\n\n\n\n\n---\ntitle: \"Data Exploration\"\nauthor: \"Jeffrey Blanchard\"\nformat:\n  html:\n    toc: true\n    code-fold: true\n    theme: cosmo\n    embed-resources: true\nexecute:\n  echo: true\n  freeze: auto\n---\nThis configures: - An HTML output with a table of contents. - Collapsible code chunks. - A Bootstrap theme (cosmo). - Code execution settings.\nImportant for our class is the embed-resources: true line. This creates a single html file with the figures embeded in the file. If this line is not in the YAML block a new directory will be created which contains the images and is linked to the html file. This means that if you turn in this html file (without using embed-resources: true) the images will not be shown.\n\n\n\nQuarto YAML is: - More consistent and extensible. - Supports nested configuration (e.g., format.html.toc). - Easier to manage across multi-format outputs (e.g., HTML and PDF from one source).\nIn Quarto, R code chunks are sections of code embedded in your document that get executed when the document is rendered. These chunks are enclosed in triple backticks and start with {r}. You can customize their behavior using chunk options, which control things like whether the code is shown, whether it’s executed, how results are displayed, and more.\n\n\n\n\n\n\n\n\nR code\nsummary(cars)\n\n\n     speed           dist       \n Min.   : 4.0   Min.   :  2.00  \n 1st Qu.:12.0   1st Qu.: 26.00  \n Median :15.0   Median : 36.00  \n Mean   :15.4   Mean   : 42.98  \n 3rd Qu.:19.0   3rd Qu.: 56.00  \n Max.   :25.0   Max.   :120.00  \n\n\n\n\n\nHere’s a categorized list of the most useful options:\n\n\n\n\n\nOption\nDescription\n\n\n\n\neval\nWhether to evaluate the code (TRUE or FALSE)\n\n\necho\nShow the code in the output (TRUE or FALSE)\n\n\ninclude\nInclude both code and output (TRUE or FALSE)\n\n\nerror\nShow errors in output (TRUE or FALSE)\n\n\nwarning\nShow warnings (TRUE or FALSE)\n\n\nmessage\nShow messages (TRUE or FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\nOption\nDescription\n\n\n\n\nresults\nHow to display results (\"markup\", \"asis\", \"hide\")\n\n\nfig.width\nWidth of plots (in inches)\n\n\nfig.height\nHeight of plots (in inches)\n\n\nfig.cap\nCaption for figures\n\n\nfig.align\nAlignment of figures (\"left\", \"center\", \"right\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nOption\nDescription\n\n\n\n\ncache\nCache results to avoid re-running code\n\n\nfreeze\nFreeze output to avoid re-execution unless explicitly updated\n\n\n\n\n\n\n\n\n\nOption\nDescription\n\n\n\n\ntidy\nAutomatically tidy code before execution\n\n\ncollapse\nCollapse code and output together\n\n\ncomment\nPrefix for output lines\n\n\n\n\n\n\n\n{r pressure-plot, fig.width=6, fig.height=4, fig.cap=\"Pressure vs Temperature\"}\n\n\nR code\nplot(pressure)\n\n\n\n\n\nPressure vs Temperature\n\n\n\n\nThis chunk: - Hides the code (echo=FALSE) - Sets figure size - Adds a caption - Names the chunk (pressure-plot) for reference\n\n\n\n\nTry a different Quarto theme\n\n\n\nCreate a lab report that has\n\nA link out to an external web site.\nAn image embedded.\nA table of contents using the YAML block\nThe code folded using the YAML block\nA code chunk with plot(cars) in which the plot is sized to a figure width of 3 and height of 2\nA code chunk in which the output, but not the code is in the rendered file.\nTry a different Quarto theme.\n\n\n\n\nThis lab was created with assistance from UMass Copilot"
  },
  {
    "objectID": "labs/lab1m_quarto.html#learning-objectives",
    "href": "labs/lab1m_quarto.html#learning-objectives",
    "title": "Lab 1s - Quarto",
    "section": "",
    "text": "Quarto\nDifferences between R Markdown and Quarto\nYAML blocks\nCode blocks"
  },
  {
    "objectID": "labs/lab1m_quarto.html#quarto",
    "href": "labs/lab1m_quarto.html#quarto",
    "title": "Lab 1s - Quarto",
    "section": "",
    "text": "Quarto is the name of an open-source publishing system used for technical and scientific writing.\nIt lets you combine text, code, and outputs in one document—perfect for data science, research, and reproducible reports.\nYou can write in Python, R, Julia, or Observable JavaScript, and publish to formats like HTML, PDF, Word, and even full websites\nIt’s considered the next generation of R Markdown, and works with tools like Jupyter Notebooks, VS Code, and RStudio.\nBecause it is based on R Markdown, there is a wealth of related resources and books published on and using R Markdown. See some of on the examples books using R we will periodically using in the course."
  },
  {
    "objectID": "labs/lab1m_quarto.html#differences-between-r-markdown-and-quarto",
    "href": "labs/lab1m_quarto.html#differences-between-r-markdown-and-quarto",
    "title": "Lab 1s - Quarto",
    "section": "",
    "text": "R Markdown and Quarto are both tools for creating dynamic documents that combine code, text, and outputs (like plots or tables), but they differ in terms of design philosophy, features, and flexibility. Here’s a breakdown of their key differences:\n\n\n\nR Markdown:\n\nDeveloped by RStudio.\nPrimarily designed for R users.\nBuilt on top of knitr and Pandoc.\nDeeply integrated into the RStudio IDE.\n\nQuarto:\n\nAlso developed by RStudio, but as a next-generation tool.\nLanguage-agnostic: supports R, Python, Julia, and Observable JavaScript.\nUses Pandoc directly (not knitr).\nDesigned to unify and modernize the workflow across languages.\n\n\n\n\n\n\nR Markdown: Best suited for R. Python support is possible but less seamless.\nQuarto: First-class support for multiple languages in a single document. You can mix R, Python, Julia, and JavaScript.\n\n\n\n\n\nR Markdown:\n\nUses YAML front matter for metadata.\nCode chunks are written using triple backticks with language identifiers.\n\nQuarto:\n\nSimilar structure but more consistent and extensible YAML.\nSupports Markdown extensions like callouts, citations, cross-referencing, and more.\n\n\n\n\n\n\nR Markdown:\n\nSupports HTML, PDF, Word, slides (via xaringan or ioslides), etc.\nCustomization can be complex for advanced layouts.\n\nQuarto:\n\nSupports all R Markdown formats plus:\n\nReveal.js slides.\nBooks and websites with built-in navigation and styling.\nJupyter-style notebooks.\n\nEasier to configure and customize outputs.\n\n\n\n\n\n\nR Markdown:\n\nExecutes code using knitr (for R) or reticulate (for Python).\nLess control over execution environment.\n\nQuarto:\n\nUses Jupyter kernels or R directly.\nBetter support for notebook-style interactivity and execution control.\n\n\n\n\n\n\nR Markdown:\n\nNo native concept of a “project” beyond RStudio projects.\n\nQuarto:\n\nSupports Quarto Projects: collections of documents with shared configuration.\nIdeal for books, blogs, websites, and multi-document workflows.\n\n\n\n\n\n\nQuarto:\n\nMore modern and extensible.\nSupports Lua filters, Markdown extensions, cross-referencing, citations, and interactive widgets.\nBetter support for version control and CI/CD workflows.\n\n\n\n\n\n\n\n\nFeature\nR Markdown\nQuarto\n\n\n\n\nLanguage Support\nPrimarily R\nR, Python, Julia, JS\n\n\nExecution Engine\nknitr\nJupyter / native\n\n\nOutput Formats\nMany\nMore + easier config\n\n\nInteractivity\nLimited\nRich (widgets, JS)\n\n\nProject Support\nBasic\nFull project system\n\n\nExtensibility\nModerate\nHigh\n\n\nIdeal For\nR-centric reports\nMulti-language docs"
  },
  {
    "objectID": "labs/lab1m_quarto.html#adding-links-and-figures-in-a-quarto-document",
    "href": "labs/lab1m_quarto.html#adding-links-and-figures-in-a-quarto-document",
    "title": "Lab 1s - Quarto",
    "section": "",
    "text": "Let’s go the the Quarto documentation for Markdown basics and more details on Figures\nIt is important to specific where the figure is located relative to your .qmd file. The path can be relative (giant_virus.jpg) or (images/giant_virus.jpg) or absolute (/home/pi_jlb_umass_edu/images/giant_virus.jpg).\n\n\n\ngiant virus"
  },
  {
    "objectID": "labs/lab1m_quarto.html#yaml-blocks-in-quarto",
    "href": "labs/lab1m_quarto.html#yaml-blocks-in-quarto",
    "title": "Lab 1s - Quarto",
    "section": "",
    "text": "In Quarto, a YAML block is a section at the top of a document that contains metadata and configuration settings. YAML stands for “YAML Ain’t Markup Language”, and it’s used to define things like the document title, author, output format, and more.\n\n\nA YAML block is enclosed by triple dashes (---) at the beginning and end:\n---\ntitle: \"My Analysis Report\"\nauthor: \"Jeffrey Blanchard\"\ndate: \"2025-09-08\"\nformat: html\neditor: visual\n---\nThis block tells Quarto: - The title of the document. - The author name. - The date to display. - The output format (e.g., HTML, PDF, Word). - The editor preference (e.g., visual or source).\n\n\n\nHere are some frequently used fields:\n\n\n\n\n\n\n\nField\nDescription\n\n\n\n\ntitle\nTitle of the document\n\n\nauthor\nAuthor name(s)\n\n\ndate\nDate of publication\n\n\nformat\nOutput format (e.g., html, pdf, docx, revealjs)\n\n\ntoc\nTable of contents (true or false)\n\n\nnumber-sections\nNumber section headings\n\n\ntheme\nVisual theme for HTML or slides\n\n\ncode-fold\nWhether code chunks can be collapsed\n\n\nexecute\nControls code execution (e.g., echo, eval, freeze)\n\n\nbibliography\nPath to .bib file for citations\n\n\nfilters\nLua filters for advanced customization\n\n\n\n\n\n\n---\ntitle: \"Data Exploration\"\nauthor: \"Jeffrey Blanchard\"\nformat:\n  html:\n    toc: true\n    code-fold: true\n    theme: cosmo\n    embed-resources: true\nexecute:\n  echo: true\n  freeze: auto\n---\nThis configures: - An HTML output with a table of contents. - Collapsible code chunks. - A Bootstrap theme (cosmo). - Code execution settings.\nImportant for our class is the embed-resources: true line. This creates a single html file with the figures embeded in the file. If this line is not in the YAML block a new directory will be created which contains the images and is linked to the html file. This means that if you turn in this html file (without using embed-resources: true) the images will not be shown.\n\n\n\nQuarto YAML is: - More consistent and extensible. - Supports nested configuration (e.g., format.html.toc). - Easier to manage across multi-format outputs (e.g., HTML and PDF from one source).\nIn Quarto, R code chunks are sections of code embedded in your document that get executed when the document is rendered. These chunks are enclosed in triple backticks and start with {r}. You can customize their behavior using chunk options, which control things like whether the code is shown, whether it’s executed, how results are displayed, and more."
  },
  {
    "objectID": "labs/lab1m_quarto.html#r-code-chunks-in-quarto",
    "href": "labs/lab1m_quarto.html#r-code-chunks-in-quarto",
    "title": "Lab 1s - Quarto",
    "section": "",
    "text": "R code\nsummary(cars)\n\n\n     speed           dist       \n Min.   : 4.0   Min.   :  2.00  \n 1st Qu.:12.0   1st Qu.: 26.00  \n Median :15.0   Median : 36.00  \n Mean   :15.4   Mean   : 42.98  \n 3rd Qu.:19.0   3rd Qu.: 56.00  \n Max.   :25.0   Max.   :120.00  \n\n\n\n\n\nHere’s a categorized list of the most useful options:\n\n\n\n\n\nOption\nDescription\n\n\n\n\neval\nWhether to evaluate the code (TRUE or FALSE)\n\n\necho\nShow the code in the output (TRUE or FALSE)\n\n\ninclude\nInclude both code and output (TRUE or FALSE)\n\n\nerror\nShow errors in output (TRUE or FALSE)\n\n\nwarning\nShow warnings (TRUE or FALSE)\n\n\nmessage\nShow messages (TRUE or FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\nOption\nDescription\n\n\n\n\nresults\nHow to display results (\"markup\", \"asis\", \"hide\")\n\n\nfig.width\nWidth of plots (in inches)\n\n\nfig.height\nHeight of plots (in inches)\n\n\nfig.cap\nCaption for figures\n\n\nfig.align\nAlignment of figures (\"left\", \"center\", \"right\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nOption\nDescription\n\n\n\n\ncache\nCache results to avoid re-running code\n\n\nfreeze\nFreeze output to avoid re-execution unless explicitly updated\n\n\n\n\n\n\n\n\n\nOption\nDescription\n\n\n\n\ntidy\nAutomatically tidy code before execution\n\n\ncollapse\nCollapse code and output together\n\n\ncomment\nPrefix for output lines\n\n\n\n\n\n\n\n{r pressure-plot, fig.width=6, fig.height=4, fig.cap=\"Pressure vs Temperature\"}\n\n\nR code\nplot(pressure)\n\n\n\n\n\nPressure vs Temperature\n\n\n\n\nThis chunk: - Hides the code (echo=FALSE) - Sets figure size - Adds a caption - Names the chunk (pressure-plot) for reference"
  },
  {
    "objectID": "labs/lab1m_quarto.html#quarto-themes",
    "href": "labs/lab1m_quarto.html#quarto-themes",
    "title": "Lab 1s - Quarto",
    "section": "",
    "text": "Try a different Quarto theme"
  },
  {
    "objectID": "labs/lab1m_quarto.html#exercises",
    "href": "labs/lab1m_quarto.html#exercises",
    "title": "Lab 1s - Quarto",
    "section": "",
    "text": "Create a lab report that has\n\nA link out to an external web site.\nAn image embedded.\nA table of contents using the YAML block\nThe code folded using the YAML block\nA code chunk with plot(cars) in which the plot is sized to a figure width of 3 and height of 2\nA code chunk in which the output, but not the code is in the rendered file.\nTry a different Quarto theme."
  },
  {
    "objectID": "labs/lab1m_quarto.html#acknowledgements",
    "href": "labs/lab1m_quarto.html#acknowledgements",
    "title": "Lab 1s - Quarto",
    "section": "",
    "text": "This lab was created with assistance from UMass Copilot"
  },
  {
    "objectID": "labs/lab2s_biblio.html",
    "href": "labs/lab2s_biblio.html",
    "title": "Lab S2 : Adding References to Your Report with Zotero",
    "section": "",
    "text": "Adding references exported from Zotero to your report"
  },
  {
    "objectID": "labs/lab2s_biblio.html#learning-objectives",
    "href": "labs/lab2s_biblio.html#learning-objectives",
    "title": "Lab S2 : Adding References to Your Report with Zotero",
    "section": "",
    "text": "Adding references exported from Zotero to your report"
  },
  {
    "objectID": "labs/lab2s_biblio.html#adding-references-to-your-report",
    "href": "labs/lab2s_biblio.html#adding-references-to-your-report",
    "title": "Lab S2 : Adding References to Your Report with Zotero",
    "section": "Adding references to your report",
    "text": "Adding references to your report\n\nStep 1: Set up Zotero on your computer\nDownload Zotero to your computer and add the Zotero plugin to your web browser.\n\n\nStep 2: Get references from Zotero\nGo to PubMed and search for metagenome. Add 3 articles to your Zotero database\n\n\nStep 3: Export the 3 references from Zotero\n\nSelect the 3 references and select File &gt; Export Library\nExport in BibTeX format. This will generate a file with a .bib extension. Do not include any spaces in your file name.\nUpload the .bib file to Unity.\n\n\n\nStep 4: Add the file name of your references library to your YAML block\n---\ntitle: \"Lab 6\"\nauthor: \"Your name\"\nformat:\n  html:\n    toc: true\n    toc_float: true\n    embed-resources: true\nexecute: \n  warning: false\n  message: false\nbibliography: MyReferences.bib\n---\n\n\nStep 5: Cite the references in the text of your document\nMy reference file looks like this.\n@Misc{Chang2015,\n  Title                    = {shiny: Web Application Framework for R. R package version 0.12.1},\n\n  Author                   = {Chang, W. and Cheng, J. and Allaire, JJ. and Xie, Y. and McPherson, J. },\n  Year                     = {2015},\n\n  Type                     = {Computer Program},\n  Url                      = {http://CRAN.R-project.org/package=shiny}\n}\n\n\n@Article{RCoreTeam,\n  Title                    = {R: A Language and Environment for Statistical Computing},\n  Author                   = {{R Core Team}},\n  Year                     = {2015},\n\n  Type                     = {Journal Article},\n  Url                      = {http://www.R-project.org}\n}\nTo cite this in my document I would use the following format.\nApplication written in R [@RCoreTeam] using the Shiny framework [@Chang2015].\nOpen your .bib file to see the appropriate @ names for your references.\n\n\nStep 6: Add a section header for the references at the end of your document\nWhen you Render the document the references will be added to the end of the document. To define this section and to make it visible in our outline put # References on the last line (or the appropriate header level for your report)."
  },
  {
    "objectID": "labs/lab2s_biblio.html#exercises",
    "href": "labs/lab2s_biblio.html#exercises",
    "title": "Lab S2 : Adding References to Your Report with Zotero",
    "section": "Exercises",
    "text": "Exercises\nCreate and turn in a report that has 3 references."
  },
  {
    "objectID": "labs/lab2s_biblio.html#acknowledgements",
    "href": "labs/lab2s_biblio.html#acknowledgements",
    "title": "Lab S2 : Adding References to Your Report with Zotero",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nOur labs are written in R (R Core Team 2015) and past labs have used th Shiny framework (Chang et al. 2015)."
  },
  {
    "objectID": "labs/lab6_NEON_pub_graphics.html",
    "href": "labs/lab6_NEON_pub_graphics.html",
    "title": "Lab 6 : ggplotting with NEON MAG data",
    "section": "",
    "text": "Be able to add title, axis labels, legends, colors to ggplot graphs\nResize graphs within R code chunks\nPrint graphics to a file (e.g. jpeg, pdf)\nLoading images into Markdown\nMaking interactive graphs"
  },
  {
    "objectID": "labs/lab6_NEON_pub_graphics.html#learning-objectives",
    "href": "labs/lab6_NEON_pub_graphics.html#learning-objectives",
    "title": "Lab 6 : ggplotting with NEON MAG data",
    "section": "",
    "text": "Be able to add title, axis labels, legends, colors to ggplot graphs\nResize graphs within R code chunks\nPrint graphics to a file (e.g. jpeg, pdf)\nLoading images into Markdown\nMaking interactive graphs"
  },
  {
    "objectID": "labs/lab6_NEON_pub_graphics.html#fine-tuning-ggplots",
    "href": "labs/lab6_NEON_pub_graphics.html#fine-tuning-ggplots",
    "title": "Lab 6 : ggplotting with NEON MAG data",
    "section": "Fine tuning ggplots",
    "text": "Fine tuning ggplots\nToday we will build upon the graphing approaches in the with all the Data Carpentry ggplot tutorial\nThe Cookbook for R by Winston Chang is also great for tidying up our graphs.\nHere are a couple of cheat sheets that can be useful\n\nR Studio ggplot2 cheatsheet\nRMarkdown cheatsheet\n\n\nFirst load the libraries\n\n\nR code\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(plotly)\nlibrary(DT)\nlibrary(lubridate)\n\n\n\n\nBasic graph labels\n\n\nR code\n  ggplot(data = iris, aes(x = Sepal.Length, y = Sepal.Width)) +\n    geom_point(aes(color=Species, shape=Species)) +\n    labs(title = \"Iris Sepal Length vs Wide\", x = \"Sepal Length\", y = \"Sepal Width\", color = \"Plant Species\", shape = \"Plant Species\") \n\n\n\n\n\n\n\n\n\n\n\nThemes\nhttps://r-charts.com/ggplot2/themes/\n\n\nR code\n  ggplot(data = iris, aes(x = Sepal.Length, y = Sepal.Width)) +\n    geom_point(aes(color=Species, shape=Species)) +\n    labs(title = \"Iris Sepal Length vs Wide\", x = \"Sepal Length\", y = \"Sepal Width\", color = \"Plant Species\", shape = \"Plant Species\") +\n  theme_classic()\n\n\n\n\n\n\n\n\n\n\n\nColors\n\n\nR code\n  ggplot(data = iris, aes(x = Sepal.Length, y = Sepal.Width)) +\n    geom_point(color = \"red\", aes(shape = Species))+\n    labs(title = \"Iris Sepal Length vs Wide\", x = \"Sepal Length\", y = \"Sepal Width\") \n\n\n\n\n\n\n\n\n\n\n\nR code\n  ggplot(data = iris, aes(x = Sepal.Length, y = Sepal.Width)) +\n    geom_point(aes(color = Species, shape = Species)) +\n    scale_color_manual(values=c(\"blue\", \"purple\", \"red\")) +\n    labs(title = \"Iris Sepal Length vs Wide\", x = \"Sepal Length\", y = \"Sepal Width\") \n\n\n\n\n\n\n\n\n\n\n\nR code\n  ggplot(data = iris, aes(x = Sepal.Length, y = Sepal.Width)) +\n    geom_point(aes(color = Species, shape = Species)) +\n    scale_color_brewer(palette=\"Dark2\") +\n    labs(title = \"Iris Sepal Length vs Wide\", x = \"Sepal Length\", y = \"Sepal Width\") \n\n\n\n\n\n\n\n\n\n\n\nR code\nlibrary(viridisLite)\n  ggplot(data = iris, aes(x = Sepal.Length, y = Sepal.Width)) +\n    geom_point(aes(fill = Species), color = \"black\", pch=21) +\n    labs(title = \"Iris Sepal Length vs Wide\", x = \"Sepal Length\", y = \"Sepal Width\") \n\n\n\n\n\n\n\n\n\nviridisLite - Colorblind-Friendly Color Maps for R](https://sjmgarnier.github.io/viridisLite/)\n\n\nR code\nlibrary(viridisLite)\n  ggplot(data = iris, aes(x = Sepal.Length, y = Sepal.Width)) +\n    geom_point(aes(color = Species, shape = Species)) +\n    scale_colour_viridis_d() +\n    labs(title = \"Iris Sepal Length vs Wide\", x = \"Sepal Length\", y = \"Sepal Width\") \n\n\n\n\n\n\n\n\n\n\n\nUnderstanding directory paths\nHere’s an overview of Unix directory paths, which are fundamental to navigating and managing files in Unix-like operating systems (such as on Unity). There directory paths that are listed in examples will often be different than the ones you need to use on Unity.\n\nAbsolute vs. Relative Paths\nAbsolute Path: Starts from the root directory (/) and specifies the full path to a file or directory.\nExample: /home/jlb/images/star_virus.png\nRelative Path: Starts from the current working directory.\nExample: images/star_virus.png (if you’re already in /home/jlb)\nTo find your absolute path in RStudiio. Type in the console (bottow left window) getwd()\n&gt; getwd()\n[1] \"/home/jlb_umass_edu\"\nOften I will put the data sets we are working with in our course directory which has the path\n/work/pi_bio678_umass_edu/data_NEON/\ntherefore to load the data into RStudio\nNEON_MAGs &lt;- read_tsv(\"/work/pi_bio678_umass_edu/data_NEON/exported_img_bins_Gs0166454_NEON.tsv\")\nI suggest you make a new folder for today’s lab in names images in your home directory. When you create or plot a graph you can use the relative path\n\"images/iris_example_plot1.pdf\"\nor the absolute path\n\"home/jlb/images/iris_example_plot1.pdf\"\n\n\n\nControlling graph size in Markdown\nThe dimensions of an individual graph in the Markdown document be adjusted by specifying the graph dimensions in the header for the r code chunk.\n#| fig-height: 20\n#| fig-width: 8\nThis is similar to what we used in previous labs where we wanted to show but not run the code\n#| eval: false\nIf you want to run the code but not show the code\n#| echo: false\n\n\nGraphic Output\nYou may have realized that you can export plots in R Studio by clicking on Export in the Plots window that appears after you make a graph. You can save as a pdf, svg, tiff, png, bmp, jpeg and eps. You can also write the output directly to a file. This is particularly useful for controling the final dimensions in a reproducible way and for manuscripts.\n\nCookbook for R - Output to a file - PDF, PNG, TIFF, SVG \n\n\n\nR code\n# Plot graph to a pdf outputfile\npdf(\"../images/iris_example_plot1.pdf\", width=6, height=3)\nggplot(data = iris, aes(x = Sepal.Length, y = Sepal.Width, color = Species)) + \n  geom_point() +\n  labs(title = \"Iris Sepal Length vs Wide\", x = \"Sepal Length\", y = \"Sepal Width\") \ndev.off()\n\n\npng \n  2 \n\n\n\n\nR code\n# Plot graph to a png outputfile\nppi &lt;- 300\npng(\"../images/iris_example_plot2.png\", width=6*ppi, height=4*ppi, res=ppi)\nggplot(data = iris, aes(x = Sepal.Length, y = Sepal.Width, color = Species)) + \n  geom_point()\ndev.off()\n\n\npng \n  2 \n\n\nFor more details on sizing output Cookbook for R - Output to a file - PDF, PNG, TIFF, SVG \n\n\nMarkdown loading images\nSometimes it is useful in controlling the image layout for a report to file with the graph and then subsequently load it into the .qmd file. This works with png files, but not pdfs. You can also upload images made with other bioinformatic tools into your report.\n![Iris example plot](../images/iris_example_plot2.png) \n\n\n\nIris example plot\n\n\nAnother way to present a graph without the code is adding echo = FALSE within the r{} chunk - {r echo = FALSE}. This prevents code, but not the results from appearing in the knitr file.\n\n\nInteractive graphs\nWith plotly/ggplotly (https://plot.ly/ggplot2/) you can make interactive graphs in your lab report.\n\n\nR code\nlibrary(plotly)\n\n\n\n\nR code\n# Version 1\nggplotly(\n  ggplot(data = iris, aes(x = Sepal.Length, y = Sepal.Width, color = Species)) + \n    geom_point()\n )\n\n\n\n\n\n\n\n\nR code\n# Version 2\np &lt;- ggplot(data = iris, aes(x = Sepal.Length, y = Sepal.Width, color = Species)) + \n  geom_point()\nggplotly(p)"
  },
  {
    "objectID": "labs/lab6_NEON_pub_graphics.html#examples-with-the-neon-data",
    "href": "labs/lab6_NEON_pub_graphics.html#examples-with-the-neon-data",
    "title": "Lab 6 : ggplotting with NEON MAG data",
    "section": "Examples with the NEON data",
    "text": "Examples with the NEON data\nLet’s load the table into R. This week I have made a number of changes to the data table to get it into a format in which we can work with both the soil and freshwater MAGs\n\nThis first block of code is for both the freshwater and soil MAGs\n\n\nR code\n# This is the location used for Github\nNEON_MAGs_prelim &lt;- read_tsv(\"../data/NEON_metadata/exported_img_bins_Gs0166454_NEON.tsv\") |&gt; \n# This is the location used for the class data directory on Unity\n# NEON_MAGs_prelim &lt;- read_tsv(\"/work/pi_bio678_umass_edu/data_NEON/exported_img_bins_Gs0166454_NEON.tsv\") |&gt;\n  \n  clean_names() |&gt; \n  \n  # Add a new column community corresponding to different communities names in the genome_name\n  mutate(community = case_when(\n    str_detect(genome_name, \"Freshwater sediment microbial communities\") ~ \"Freshwater sediment microbial communitie\",\n    str_detect(genome_name, \"Freshwater biofilm microbial communities\") ~ \"Freshwater biofilm microbial communities\",\n    str_detect(genome_name, \"Freshwater microbial communities\") ~ \"Freshwater microbial communities\",\n    str_detect(genome_name, \"Soil microbial communities\") ~ \"Soil microbial communities\",\n    TRUE ~ NA_character_\n  )) |&gt; \n  \n  # Create a column type that is either Freshwater or Soil\n  mutate(type = case_when(\n    str_detect(genome_name, \"Freshwater sediment microbial communities\") ~ \"Freshwater\",\n    str_detect(genome_name, \"Freshwater biofilm microbial communities\") ~ \"Freshwater\",\n    str_detect(genome_name, \"Freshwater microbial communities\") ~ \"Freshwater\",\n    str_detect(genome_name, \"Soil microbial communities\") ~ \"Soil\",\n    TRUE ~ NA_character_\n  )) |&gt; \n  \n  # Get rid of the communities strings\n  mutate_at(\"genome_name\", str_replace, \"Freshwater sediment microbial communities from \", \"\") |&gt; \n  mutate_at(\"genome_name\", str_replace, \"Freshwater biofilm microbial communities from\", \"\") |&gt; \n  mutate_at(\"genome_name\", str_replace, \"Freshwater microbial communities from \", \"\") |&gt; \n  mutate_at(\"genome_name\", str_replace, \"Soil microbial communities from \", \"\") |&gt; \n\n  # separate site from sample name \n  separate(genome_name, c(\"site\",\"sample_name\"), \" - \") |&gt;   \n  \n  # Deal with these unknow fields in the sample name by creating a new column and removing them from the sample name\n  mutate(sample_unknown = case_when(\n    str_detect(sample_name, \".SS.\") ~ \"SS\",\n    str_detect(sample_name, \".C0.\") ~ \"C0\",\n    str_detect(sample_name, \".C1.\") ~ \"C1\",\n    str_detect(sample_name, \".C2.\") ~ \"C2\",\n    TRUE ~ NA_character_\n  )) |&gt; \n\n# These fields are all associated with \"Freshwater microbial communities from...   \n# SS - near stream sensor\n# C0 - non-stratified lake/river surface near buoy\n# C1 - stratified lake surface/epilimnion near buoy\n# C2 - stratified lake hypolimnion near buoy\n# EPIPSAMMON  - biofilm on sand/silt\n# EPILITHON - biofilm on rocks/cobbles\n# EPIPHYTON - biofilm that grows on the stems and leaves of aquatic plants\n  \n# These fields are all associated with \"Freshwater biofilm microbial communities from\n# EPILITHON - biofilm on rocks/cobbles\n  \n# These fields are all associated with \"Freshwater sediment microbial communities from \n# EPIPSAMMON - biofilm on sand/silt\n  \n  mutate_at(\"sample_name\", str_replace, \".SS\", \"\") |&gt; \n  mutate_at(\"sample_name\", str_replace, \".C0\", \"\") |&gt; \n  mutate_at(\"sample_name\", str_replace, \".C1\", \"\") |&gt; \n  mutate_at(\"sample_name\", str_replace, \".C2\", \"\") |&gt; \n  \n\n  # Get rid of the the common strings at the end of sample names\n  mutate_at(\"sample_name\", str_replace, \"-GEN-DNA1\", \"\") |&gt;  \n  mutate_at(\"sample_name\", str_replace, \"-COMP-DNA1\", \"\") |&gt;  \n  mutate_at(\"sample_name\", str_replace, \"-COMP-DNA2\", \"\") |&gt;  \n  mutate_at(\"sample_name\", str_replace, \".DNA-DNA1\", \"\") |&gt;\n  mutate_at(\"sample_name\", str_replace, \"_v2\", \"\") |&gt;\n  mutate_at(\"sample_name\", str_replace, \" \\\\(version 2\\\\)\", \"\") |&gt;\n  mutate_at(\"sample_name\", str_replace, \" \\\\(version 3\\\\)\", \"\") |&gt;\n  \n# Separate out the taxonomy groups\n  separate(gtdb_taxonomy_lineage, c(\"domain\", \"phylum\", \"class\", \"order\", \"family\", \"genus\"), \"; \", remove = FALSE)\n\n\n\n\nThis block is for separating out the freshwater sample names\n\n\nR code\nNEON_MAGs_freshwater &lt;- NEON_MAGs_prelim |&gt;\n  filter(type == \"Freshwater\") |&gt;\n  # separate the Sample Name into Site ID and plot info\n  separate(sample_name, c(\"site_ID\",\"date\", \"layer\", \"subplot\"), \"\\\\.\", remove = FALSE) |&gt;\n  mutate(quadrant = NA_character_)\n\n\n\n\nThis block is for separating out the soil sample names\n\n\nR code\nNEON_MAGs_soil &lt;- NEON_MAGs_prelim |&gt;\n  filter(type == \"Soil\") |&gt;\n  # separate the Sample Name into Site ID and plot info\n  separate(sample_name, c(\"site_ID\",\"subplot.layer.date\"), \"_\", remove = FALSE,) |&gt; \n  # some sample names have 3 fields while others have a fourth field for the quadrant. This code create a field for the quadrant when present and adds na for samples from combined cores.\n  extract(\n    subplot.layer.date,\n    into = c(\"subplot\", \"layer\", \"quadrant\", \"date\"),\n    regex = \"^([^-]+)-([^-]+)(?:-([^-]+))?-([^-]+)$\",\n    remove = FALSE\n  ) |&gt;\n  mutate(quadrant = na_if(quadrant, \"\")) |&gt;\n  select(-subplot.layer.date)\n\n\n\n\nThis combines the soil and freshwater data frames\n\n\nR code\nNEON_MAGs &lt;-bind_rows(NEON_MAGs_freshwater, NEON_MAGs_soil) |&gt;\n  # This changes the format of the data column\n  mutate(date = ymd(date))\n\n\n\n\nFinding rows with NA\nIn some cases you will have NA on your graphs. If you would like to see which rows in a column contain NA use\n\n\nR code\nfilter(is.na(column_name))\n\n\nThese represent potential novel taxonomic groups. If you would like to replace NA with unknown or novel\n\n\nR code\nmutate(column_name = replace_na(column_name, \"novel\"))"
  },
  {
    "objectID": "labs/lab6_NEON_pub_graphics.html#exercises",
    "href": "labs/lab6_NEON_pub_graphics.html#exercises",
    "title": "Lab 6 : ggplotting with NEON MAG data",
    "section": "Exercises",
    "text": "Exercises\nFor all exercises make complete graphs that are report ready. Relabel the x-axis, y-axis and legend for clarity, add a title, add color and size appropriately. The NAs in the taxonomy indicate a novel species starting with the highest level. For example a NA in a class that has an assigned phylum Proteobacteria would be a novel class in the phylum Proteobacteria. To filter Class and Order based on NA.\n\n\nR code\nNEON_MAGs |&gt; \n  filter(is.na(class) | is.na(order))\n\n\n\nExercise 1\nWhat are the overall class MAG counts?\n\n\nExercise 2\nWhat are the MAG counts for each subplot. Color by site ID.\n\n\nExercise 3\nHow many novel bacteria were discovered (Show that number of NAs for each site)?\n\n\nExercise 4\nHow many novel bacterial MAGs are high quality vs medium quality?\n\n\nExercise 5\nWhat phyla have novel bacterial genera?\n\n\nExercise 6\nMake a stacked bar plot of the total number of MAGs at each site using Phylum as the fill.\n\n\nExercise 7\nUsing facet_wrap make plots of the total number of MAGs at each site for each phylum (e.g. similar to the example above but using the site ID and separating each graph by phylum.)\n\n\nExercise 8\nWhat is the relationship between MAGs genome size and the number of genes? Color by Phylum.\n\n\nExercise 9\nWhat is the relationship between scaffold count and MAG completeness?\n\n\nExercise 10\nSeparate out bin_id (e.g 3300078752_s0) into 2 columns metagenome_id and bin_num.\n\n\nExercise 11\nThe site column has strings like\n\nRio Cupeyes NEON Field Site, San Germán, Puerto Rico\nSycamore Creek NEON Field Site, Rio Verde, Arizona, USA\nSan Joaquin Experimental Range NEON Field site, Yosemite Lakes, California, USA\nSan Joaquin Experimental Range NEON Field Site, California, USA\nOak Ridge NEON Field Station, Tennessee, USA\n\nSeparate out this string into 4 columns site name (e.g. Rio Cupeyes), ’NEON field site(e.g. NEON Field Site/Station),region(e.g. Yosemite Lakes) andstate`.\nThis is a tough one that may require back and forth with copilot.\n\n\nExercise 12\nMake a graph showing the number of MAGs in each state."
  },
  {
    "objectID": "labs/lab6_NEON_pub_graphics.html#neon-graphs",
    "href": "labs/lab6_NEON_pub_graphics.html#neon-graphs",
    "title": "Lab 6 : ggplotting with NEON MAG data",
    "section": "NEON graphs",
    "text": "NEON graphs\n\nBar plots\n\nCounts produced by ggplot\nNote that in this graph ggplot produces the count automatically\n\n\nR code\nNEON_MAGs |&gt; \nmutate(phylum = replace_na(phylum, \"***NOVEL***\")) |&gt;\nggplot(aes(x = phylum)) +\n  geom_bar() +\n  coord_flip()\n\n\n\n\n\n\n\n\n\nUse the forcats package in tidyverse to put the counts in descending order\n\n\nR code\nNEON_MAGs |&gt; \nggplot(aes(x = fct_infreq(phylum))) +\n  geom_bar() +\n  coord_flip()\n\n\n\n\n\n\n\n\n\n\n\nCounts passed to ggplot\nThis is different code that creates the same graph as above. Note in this case the counts were first calculated in dplyr then passed to ggplot. Both x and y values are needed. Within geom_bar stat is set to “identify”\n\n\nR code\nNEON_MAGs |&gt; \n  count(phylum) |&gt; \nggplot(aes(x = phylum, y = n)) +\n  geom_col(stat = \"identity\") +\n  coord_flip()\n\n\n\n\n\n\n\n\n\nTo put in descending order\noye\"Sepal Width #| fig-height: 10 #| fig-width: 8 NEON_MAGs |&gt;    count(phylum) |&gt;  ggplot(aes(x = reorder(phylum, n), y = n)) +   geom_col(stat = \"identity\") +   coord_flip()\n\n\nStacked vs multiple bar plots\n\n\nR code\nNEON_MAGs |&gt; \n  mutate(phylum = replace_na(phylum, \"***UNKNOWN***\")) |&gt; \nggplot(aes(x = fct_rev(fct_infreq(phylum)), fill = type)) +\n  geom_bar() +\n  coord_flip() +\n  labs(title = \"2023 and 2024 NEON MAG Taxonomic Distribution\", x = \"Count\", y = \"Phylum\") \n\n\n\n\n\n\n\n\n\n\n\nR code\nNEON_MAGs |&gt; \nmutate(phylum = replace_na(phylum, \"***NOVEL***\")) |&gt;\nggplot(aes(x = fct_rev(fct_infreq(phylum)), fill = type)) +\n  geom_bar(position = \"dodge\") +\n  coord_flip()\n\n\n\n\n\n\n\n\n\nNotice that the bars are of different width. This can be adjusted by setting the width\n\n\nR code\nNEON_MAGs |&gt; \nmutate(phylum = replace_na(phylum, \"***NOVEL***\")) |&gt; \nggplot(aes(x = fct_rev(fct_infreq(phylum)), fill = type)) +\n  geom_bar(position = position_dodge2(width = 0.9, preserve = \"single\")) +\n  coord_flip()\n\n\n\n\n\n\n\n\n\n\n\n\nMultiple panels (facet_wrap)\n\n\nR code\nNEON_MAGs |&gt; \nggplot(aes(x = phylum, fill = type)) +\n  geom_bar(position = position_dodge2(width = 0.9, preserve = \"single\")) +\n  coord_flip() +\n  facet_wrap(vars(site_ID), scales = \"free\", ncol = 2)\n\n\n\n\n\n\n\n\n\n\n\nHistogram\n\n\nR code\nNEON_MAGs |&gt; \nggplot(aes(x = total_number_of_bases)) +\n  geom_histogram(bins = 50) \n\n\n\n\n\n\n\n\n\n\n\nBox plot\n\n\nR code\nNEON_MAGs  |&gt;    \nggplot(aes(x = fct_infreq(phylum), y = total_number_of_bases)) +\n  geom_boxplot() +\n  theme(axis.text.x = element_text(angle=45, vjust=1, hjust=1))\n\n\n\n\n\n\n\n\n\n\n\nShowing each point in the above plot\n\n\nR code\nNEON_MAGs |&gt;   \nggplot(aes(x = fct_infreq(phylum), y = total_number_of_bases)) +\n  geom_point() +\n  coord_flip()"
  },
  {
    "objectID": "labs/lab6_freshwater.html",
    "href": "labs/lab6_freshwater.html",
    "title": "Lab 6 : ggplotting with NEON MAG data",
    "section": "",
    "text": "R code\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(lubridate)"
  },
  {
    "objectID": "labs/lab6_freshwater.html#examples-with-the-neon-data",
    "href": "labs/lab6_freshwater.html#examples-with-the-neon-data",
    "title": "Lab 6 : ggplotting with NEON MAG data",
    "section": "Examples with the NEON data",
    "text": "Examples with the NEON data\n\nThis first block of code is for both the freshwater and soil MAGs\n\n\nR code\n# This is the location used for Github\nNEON_MAGs_prelim &lt;- read_tsv(\"../data/NEON_metadata/exported_img_bins_Gs0166454_NEON.tsv\") |&gt; \n# This is the location used for the class data directory on Unity\n# NEON_MAGs &lt;- read_tsv(\"/work/pi_bio678_umass_edu/data_NEON/exported_img_bins_Gs0166454_NEON.tsv\")\n  \n  clean_names() |&gt; \n  \n  # Add a new column community corresponding to different communities names in the genome_name\n  mutate(community = case_when(\n    str_detect(genome_name, \"Freshwater sediment microbial communities\") ~ \"Freshwater sediment microbial communitie\",\n    str_detect(genome_name, \"Freshwater biofilm microbial communities\") ~ \"Freshwater biofilm microbial communities\",\n    str_detect(genome_name, \"Freshwater microbial communities\") ~ \"Freshwater microbial communities\",\n    str_detect(genome_name, \"Soil microbial communities\") ~ \"Soil microbial communities\",\n    TRUE ~ NA_character_\n  )) |&gt; \n  \n  # Create a column type that is either Freshwater or Soil\n  mutate(type = case_when(\n    str_detect(genome_name, \"Freshwater sediment microbial communities\") ~ \"Freshwater\",\n    str_detect(genome_name, \"Freshwater biofilm microbial communities\") ~ \"Freshwater\",\n    str_detect(genome_name, \"Freshwater microbial communities\") ~ \"Freshwater\",\n    str_detect(genome_name, \"Soil microbial communities\") ~ \"Soil\",\n    TRUE ~ NA_character_\n  )) |&gt; \n  \n  # Get rid of the communities strings\n  mutate_at(\"genome_name\", str_replace, \"Freshwater sediment microbial communities from \", \"\") |&gt; \n  mutate_at(\"genome_name\", str_replace, \"Freshwater biofilm microbial communities from\", \"\") |&gt; \n  mutate_at(\"genome_name\", str_replace, \"Freshwater microbial communities from \", \"\") |&gt; \n  mutate_at(\"genome_name\", str_replace, \"Soil microbial communities from \", \"\") |&gt; \n\n  # separate site from sample name \n  separate(genome_name, c(\"site\",\"sample_name\"), \" - \") |&gt;   \n  \n  # Deal with these unknow fields in the sample name by creating a new column and removing them from the sample name\n  mutate(sample_unknown = case_when(\n    str_detect(sample_name, \".SS.\") ~ \"SS\",\n    str_detect(sample_name, \".C0.\") ~ \"C0\",\n    str_detect(sample_name, \".C1.\") ~ \"C1\",\n    str_detect(sample_name, \".C2.\") ~ \"C2\",\n    TRUE ~ NA_character_\n  )) |&gt; \n  \n  mutate_at(\"sample_name\", str_replace, \".SS\", \"\") |&gt; \n  mutate_at(\"sample_name\", str_replace, \".C0\", \"\") |&gt; \n  mutate_at(\"sample_name\", str_replace, \".C1\", \"\") |&gt; \n  mutate_at(\"sample_name\", str_replace, \".C2\", \"\") |&gt; \n  \n\n  # Get rid of the the common strings at the end of sample names\n  mutate_at(\"sample_name\", str_replace, \"-GEN-DNA1\", \"\") |&gt;  \n  mutate_at(\"sample_name\", str_replace, \"-COMP-DNA1\", \"\") |&gt;  \n  mutate_at(\"sample_name\", str_replace, \"-COMP-DNA2\", \"\") |&gt;  \n  mutate_at(\"sample_name\", str_replace, \".DNA-DNA1\", \"\") |&gt;\n  mutate_at(\"sample_name\", str_replace, \"_v2\", \"\") |&gt;\n  mutate_at(\"sample_name\", str_replace, \" \\\\(version 2\\\\)\", \"\") |&gt;\n  mutate_at(\"sample_name\", str_replace, \" \\\\(version 3\\\\)\", \"\") |&gt;\n  \n# Separate out the taxonomy groups\n  separate(gtdb_taxonomy_lineage, c(\"domain\", \"phylum\", \"class\", \"order\", \"family\", \"genus\"), \"; \", remove = FALSE)\n\n\n\n\nThis block is for separating out the freshwater sample names\n\n\nR code\nNEON_MAGs_freshwater &lt;- NEON_MAGs_prelim |&gt;\n  filter(type == \"Freshwater\") |&gt;\n  # separate the Sample Name into Site ID and plot info\n  separate(sample_name, c(\"site_ID\",\"date\", \"layer\", \"subplot\"), \"\\\\.\", remove = FALSE) |&gt;\n  mutate(quadrant = NA_character_)\n\n\n\n\nThis block is for separating out the soil sample names\n\n\nR code\nNEON_MAGs_soil &lt;- NEON_MAGs_prelim |&gt;\n  filter(type == \"Soil\") |&gt;\n  # separate the Sample Name into Site ID and plot info\n  separate(sample_name, c(\"site_ID\",\"subplot.layer.date\"), \"_\", remove = FALSE,) |&gt; \n  # some sample names have 3 fields while others have a fourth field for the quadrant. This code create a field for the quadrant when present and adds na for samples from combined cores.\n  extract(\n    subplot.layer.date,\n    into = c(\"subplot\", \"layer\", \"quadrant\", \"date\"),\n    regex = \"^([^-]+)-([^-]+)(?:-([^-]+))?-([^-]+)$\",\n    remove = FALSE\n  ) |&gt;\n  mutate(quadrant = na_if(quadrant, \"\")) |&gt;\n  select(-subplot.layer.date)\n\n\n\n\nThis combines the soil and freshwater data frames\n\n\nR code\nNEON_MAGs &lt;-bind_rows(NEON_MAGs_freshwater, NEON_MAGs_soil) |&gt;\n  # This changes the format of the data column\n  mutate(date = ymd(date))"
  },
  {
    "objectID": "labs/lab7_covid.html",
    "href": "labs/lab7_covid.html",
    "title": "Lab 7 : Data Tidying, Transformation and Visualization with COVID-19 reporting data",
    "section": "",
    "text": "Understanding the sources of SARS-CoV-2 incidence reports\nAccessing data remotely\nWide and long table formats\nMore data visualization with ggplot2\nAnimation"
  },
  {
    "objectID": "labs/lab7_covid.html#learning-objectives",
    "href": "labs/lab7_covid.html#learning-objectives",
    "title": "Lab 7 : Data Tidying, Transformation and Visualization with COVID-19 reporting data",
    "section": "",
    "text": "Understanding the sources of SARS-CoV-2 incidence reports\nAccessing data remotely\nWide and long table formats\nMore data visualization with ggplot2\nAnimation"
  },
  {
    "objectID": "labs/lab7_covid.html#visualizing-covid-19-cases-deaths-and-recoveries",
    "href": "labs/lab7_covid.html#visualizing-covid-19-cases-deaths-and-recoveries",
    "title": "Lab 7 : Data Tidying, Transformation and Visualization with COVID-19 reporting data",
    "section": "Visualizing COVID-19 cases, deaths and recoveries",
    "text": "Visualizing COVID-19 cases, deaths and recoveries\nThe virus has been recently renamed based on phylogenetic analysis severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). The disease caused by the virus is coronavirus disease (COVID-19). In this lab we will work with reporting data on COVID-19 cases, deaths and recoveries.\n\nIntroduction to JHU case tracking data\nResearchers (Ensheng Dong, Hongru Du, Lauren Gardner) at John Hopkins University developed an interactive dashboard to visual data and track reported cases of coronavirus disease 2019 (SARS-CoV-2) in real time. The underlying data is collated from the following sources was updated several times a day until March 2023 (For more recent views of the data see the (CDC tracker and NY Times Tracker)\nIt is important to understand that this data is only as accurate as the reporting and many cases of the disease go unreported because of a lack of testing. This some countries may have have confirmed cases because of more comprehensive testing. Thus, the reporting data represent a minimum number of cases.\nJHU researchers make data that goes into the dashboard available on Github repo for Novel Coronavirus (COVID-19) Cases. In this lab we will work with this data.\nLet’s take a look at the files and the structure of data in the files.\n\ncsse_covid_19_data\n\ncsse_covid_19_daily_reports\n\n03-11-2020.csv\n\n\n\nOpen up the file to look at the structure\nThe file contains the columns\nProvince/State Country/Region Last Update Confirmed Deaths Recovered Latitude Longitude\nIt is important to note that for some countries there is only one row, while for others (e.g. China and US) there are multiple rows representing different provinces or states. Thus, we will need to sum these rows to get a total count for the US and China when we make graphs. From experience in making this tutorial I know the Column names with / will cause errors in ggplot ()."
  },
  {
    "objectID": "labs/lab7_covid.html#on-the-computer",
    "href": "labs/lab7_covid.html#on-the-computer",
    "title": "Lab 7 : Data Tidying, Transformation and Visualization with COVID-19 reporting data",
    "section": "On the Computer",
    "text": "On the Computer\nLet’s start by loading tidyverse and a package lubridate for working with dates.\n\n\nR code\nlibrary(tidyverse)\nlibrary(lubridate)\n\n\n\nLoading data from a github repository\nWe could load data directly into R each time we render, it would make sure we have the most current data, but it is a time consuming step. This code is for loading the data from the site just once to your data folder. After you do this add the line #| eval: false to you code chunk so that you do not download the file each time your render (this will take a long time).\n\n\nR code\n download.file(url=\"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv\", \n               destfile = \"data/time_series_covid19_confirmed_global.csv\")\n\n\nThen we can load the data.\n\n\nR code\ntime_series_confirmed &lt;- read_csv(\"data/time_series_covid19_confirmed_global.csv\")|&gt;\n  rename(Province_State = \"Province/State\", Country_Region = \"Country/Region\")\n\n\nCheck the table properties to make sure the data imported as we expected. Click on the file in the top right corner of R Studio under Environment.\n\n\nData Tidying - Pivoting\nToday we will go over Chapter 5 in R for Data Sciences - Data Tiyding and Pivot\nAs noted above this data is in wide format. To convert to long format we can usepivot_longer\n\n\nR code\ntime_series_confirmed_long &lt;- time_series_confirmed |&gt; \n               pivot_longer(-c(Province_State, Country_Region, Lat, Long),\n                            names_to = \"Date\", values_to = \"Confirmed\") \n\n\n\n\nDates and time\nLet’s also change the format of Date to something that is easier to work with in graphs. See Chapter 17 in R for Data Sciences - Data Tiyding and Pivot\n\n\nR code\ntime_series_confirmed_long$Date &lt;- mdy(time_series_confirmed_long$Date)\n\n\nLet’s look at the format of the data frame of time_series_confirmed_long by clicking on it in the top right corner of R Studio under Environment."
  },
  {
    "objectID": "labs/lab7_covid.html#making-graphs-from-the-time-series-data",
    "href": "labs/lab7_covid.html#making-graphs-from-the-time-series-data",
    "title": "Lab 7 : Data Tidying, Transformation and Visualization with COVID-19 reporting data",
    "section": "Making Graphs from the time series data",
    "text": "Making Graphs from the time series data\nTo make a times series graph of the confirmed cases we need to summarize the Country date to count up the individual state data for the US.\n\n\nR code\ntime_series_confirmed_long|&gt; \n  group_by(Country_Region, Date) |&gt; \n  summarise(Confirmed = sum(Confirmed)) |&gt; \n  filter (Country_Region == \"US\") |&gt; \n  ggplot(aes(x = Date,  y = Confirmed)) + \n    geom_point() +\n    geom_line() +\n    ggtitle(\"US COVID-19 Confirmed Cases\")\n\n\n\n\n\n\n\n\n\nNow several countries on the same graph\n\n\nR code\ntime_series_confirmed_long |&gt; \n    group_by(Country_Region, Date) |&gt; \n    summarise(Confirmed = sum(Confirmed)) |&gt; \n    filter (Country_Region %in% c(\"China\",\"France\",\"Italy\", \n                                \"Korea, South\", \"US\")) |&gt; \n    ggplot(aes(x = Date,  y = Confirmed, color = Country_Region)) + \n      geom_point() +\n      geom_line() +\n      ggtitle(\"COVID-19 Confirmed Cases\")\n\n\n\n\n\n\n\n\n\nThe above graphs using the cumulative counts. Let’s make a new table with the daily counts using the tidverse/dyplr lag function which subtracts a row from the previous row.\n\n\nR code\ntime_series_confirmed_long_daily &lt;-time_series_confirmed_long |&gt; \n    group_by(Country_Region, Date) |&gt; \n    summarise(Confirmed = sum(Confirmed)) |&gt; \n    mutate(Daily = Confirmed - lag(Confirmed, default = first(Confirmed )))\n\n\nNow for a graph with the US data\n\n\nR code\ntime_series_confirmed_long_daily |&gt; \n    filter (Country_Region == \"US\") |&gt; \n    ggplot(aes(x = Date,  y = Daily, color = Country_Region)) + \n      geom_point() +\n      ggtitle(\"COVID-19 Confirmed Cases\")\n\n\n\n\n\n\n\n\n\nA line graph version of the above\n\n\nR code\ntime_series_confirmed_long_daily |&gt; \n    filter (Country_Region == \"US\") |&gt; \n    ggplot(aes(x = Date,  y = Daily, color = Country_Region)) + \n      geom_line() +\n      ggtitle(\"COVID-19 Confirmed Cases\")\n\n\n\n\n\n\n\n\n\nNow with a curve fit\n\n\nR code\ntime_series_confirmed_long_daily |&gt; \n    filter (Country_Region == \"US\") |&gt; \n    ggplot(aes(x = Date,  y = Daily, color = Country_Region)) + \n      geom_smooth() +\n      ggtitle(\"COVID-19 Confirmed Cases\")\n\n\n\n\n\n\n\n\n\nBy default, geom_smooth() adds a LOESS/LOWESS (Locally Weighted Scatterplot Smoothing) smoother to the data. That’s not what we’re after, though. Here is a fit using a generalized additive model (GAM)\n\n\nR code\ntime_series_confirmed_long_daily |&gt; \n    filter (Country_Region == \"US\") |&gt; \n    ggplot(aes(x = Date,  y = Daily, color = Country_Region)) + \n      geom_smooth(method = \"gam\", se = FALSE) +\n      ggtitle(\"COVID-19 Confirmed Cases\")"
  },
  {
    "objectID": "labs/lab7_covid.html#animated-graphs-with-gganimate",
    "href": "labs/lab7_covid.html#animated-graphs-with-gganimate",
    "title": "Lab 7 : Data Tidying, Transformation and Visualization with COVID-19 reporting data",
    "section": "Animated Graphs with gganimate",
    "text": "Animated Graphs with gganimate\nAnimated graphs when down right have a great visual impact. You can do this in R and have your animations embedded on your web page. Essentially gganimate creates a series of files that are encompassed in a gif file. In addition to having this gif as part of your report file, you can save the gif and use in a slide or other presentations. It just takes a few lines of code to covert and existing ggplot graph into an animation. See Tutorial for Getting Started with gganimate and gganimate: How to Create Plots with Beautiful Animation in R.\nThis are some important gganimate functions:\n\ntransition_*() defines how the data should be spread out and how it relates to itself across time.\nview_*() defines how the positional scales should change along the animation.\nshadow_*() defines how data from other points in time should be presented in the given point in time.\nenter_()/exit_() defines how new data should appear and how old data should disappear during the course of the animation.\nease_aes() defines how different aesthetics should be eased during transitions.\n\n\nInstalling gganimate and gifski\ngifski is a package for creating a gif file from gganimate. Use Tools &gt; Install Packages to install gifski and gganimate on Unity.\n\n\nR code\nlibrary(gganimate)\nlibrary(gifski)\ntheme_set(theme_bw())\n\n\n\n\nAn animation of the confirmed cases in select countries\n\n\nR code\ndaily_counts &lt;- time_series_confirmed_long_daily |&gt; \n      filter (Country_Region == \"US\")\n\np &lt;- ggplot(daily_counts, aes(x = Date,  y = Daily, color = Country_Region)) + \n        geom_point() +\n        ggtitle(\"Confirmed COVID-19 Cases\") +\n# gganimate lines  \n        geom_point(aes(group = seq_along(Date))) +\n        transition_reveal(Date) \n\n# make the animation\n animate(p, renderer = gifski_renderer(), end_pause = 15)\n\n\n\n\n\n\n\n\n\nYou can change the output to a gif file that can be used in slide presentations or an instagram post. After you make the gif set eval=FALSE in your report so that it doesn’t recreate the gif (this takes a fair amount of time) each time you Knit.\n\n\nR code\nanim_save(\"daily_counts_US.gif\", p)\n\n\n\n\nAnimation of confirmed deaths\n\nDownload the data\n\n\nR code\n# This download may take about 5 minutes. You only need to do this once so set `#| eval: false` in your qmd file\ndownload.file(url=\"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv\", \n  destfile = \"data/time_series_covid19_deaths_global.csv\")\n\n\n\n\nData tidying, pivot and time\n\n\nR code\ntime_series_deaths_confirmed &lt;- read_csv(\"data/time_series_covid19_deaths_global.csv\")|&gt;\n  rename(Province_State = \"Province/State\", Country_Region = \"Country/Region\")\n\ntime_series_deaths_long &lt;- time_series_deaths_confirmed |&gt; \n    pivot_longer(-c(Province_State, Country_Region, Lat, Long),\n        names_to = \"Date\", values_to = \"Confirmed\") \n\ntime_series_deaths_long$Date &lt;- mdy(time_series_deaths_long$Date)\n\n\n\n\nMaking the animated graph\n\n\nR code\np &lt;- time_series_deaths_long |&gt;\n  filter (Country_Region %in% c(\"US\",\"Canada\", \"Mexico\",\"Brazil\",\"Egypt\",\"Ecuador\",\"India\", \"Netherlands\", \"Germany\", \"China\" )) |&gt;\n  ggplot(aes(x=Country_Region, y=Confirmed, color= Country_Region)) + \n    geom_point(aes(size=Confirmed)) + \n    transition_time(Date) + \n    labs(title = \"Cumulative Deaths: {frame_time}\") + \n    ylab(\"Deaths\") +\n    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))\n# make the animation\nanimate(p, renderer = gifski_renderer(), end_pause = 15)"
  },
  {
    "objectID": "labs/lab7_covid.html#exercises",
    "href": "labs/lab7_covid.html#exercises",
    "title": "Lab 7 : Data Tidying, Transformation and Visualization with COVID-19 reporting data",
    "section": "Exercises",
    "text": "Exercises\nPay attention to how your graphs look in today’s final rendered lab report. You will be docked points if the graphs do not look nice (e.g. overlapping column names, truncated legends, ets.)\n\nExercise 1\nGo through Chapter 5 in R for Data Sciences - Data Tiyding and Pivot](https://r4ds.hadley.nz/data-tidy.html) putting the examples and exerices into your report as in Lab 2 and 3\n\n\nExercise 2\nInstead of making a graph of 5 countries on the same graph as in the above example, use facet_wrap with scales=\"free_y\".\n\n\nExercise 3\nUsing the daily count of confirmed cases, make a single graph with 5 countries of your choosing.\n\n\nExercise 4\nPlot the cumulative deaths in the US, Canada and Mexico (you will need to download time_series_covid19_deaths_global.csv)\n\n\nExercise 5\nMake a graph with the countries of your choice using the daily deaths data\n\n\nExercise 6\nMake an animation of your choosing (do not use a graph with geom_smooth)"
  },
  {
    "objectID": "labs/lab3s_github.html",
    "href": "labs/lab3s_github.html",
    "title": "Lab S3 - “Connecting a Github repo site with a new RStudio project”",
    "section": "",
    "text": "Much of the material for this lesson was borrowed from or inspired by Matt Jones’ NCEAS Reproducible Research Techniques for Synthesis workshop"
  },
  {
    "objectID": "labs/lab3s_github.html#learning-objectives",
    "href": "labs/lab3s_github.html#learning-objectives",
    "title": "Lab S3 - “Connecting a Github repo site with a new RStudio project”",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nIn this lesson, you will learn:\n\nWhat computational reproducibility is and why it is useful\nHow version control can increase computational reproducibility\nHow to start a Github repo and Pages site\nto set up your own RStudio Project and sync with your GitHub repo\nHow to make a simple web page for your site"
  },
  {
    "objectID": "labs/lab3s_github.html#background",
    "href": "labs/lab3s_github.html#background",
    "title": "Lab S3 - “Connecting a Github repo site with a new RStudio project”",
    "section": "Background",
    "text": "Background\n\nReproducible Research\nReproducibility is the hallmark of science, which is based on empirical observations coupled with explanatory models. While reproducibility encompasses the full science lifecycle, and includes issues such as methodological consistency and treatment of bias, in this course we will focus on computational reproducibility: the ability to document data, analyses, and models sufficiently for other researchers to be able to understand and ideally re-execute the computations that led to scientific results and conclusions.\n\n\nWhat is needed for computational reproducibility?\nThe first step towards addressing these issues is to be able to evaluate the data, analyses, and models on which conclusions are drawn. Under current practice, this can be difficult because data are typically unavailable, the method sections of papers do not detail the computational approaches used, and analyses and models are often conducted in graphical programs, or, when scripted analyses are employed,the code is not available.\nAnd yet, this is easily remedied. Researchers can achieve computational reproducibility through open science approaches, including straightforward steps for archiving data and code openly along with the scientific workflows describing the provenance of scientific results (e.g., @hampton_tao_2015, @munafo_manifesto_2017).\n\n\nConceptualizing workflows\nScientific workflows encapsulate all of the steps from data acquisition, cleaning, transformation, integration, analysis, and visualization.\n\nWorkflows can range in detail from simple flowcharts to fully executable scripts. R scripts and python scripts are a textual form of a workflow, and when researchers publish specific versions of the scripts and data used in an analysis, it becomes far easier to repeat their computations and understand the provenance of their conclusions.\n\n\nThe problem with filenames\nEvery file in the scientific process changes. Manuscripts are edited. Figures get revised. Code gets fixed when problems are discovered. Data files get combined together, then errors are fixed, and then they are split and combined again. In the course of a single analysis, one can expect thousands of changes to files. And yet, all we use to track this are simplistic filenames. You might think there is a better way, and you’d be right: version control.\nVersion control systems help you track all of the changes to your files, without the spaghetti mess that ensues from simple file renaming. In version control systems like git, the system tracks not just the name of the file, but also its contents, so that when contents change, it can tell you which pieces went where. It tracks which version of a file a new version came from. So its easy to draw a graph showing all of the versions of a file, like this one:\n\nVersion control systems assign an identifier to every version of every file, and track their relationships. They also allow branches in those versions, and merging those branches back into the main line of work. They also support having multiple copies on multiple computers for backup, and for collaboration. And finally, they let you tag particular versions, such that it is easy to return to a set of files exactly as they were when you tagged them. For example, the exact versions of data, code, and narrative that were used when a manuscript was originallysubmitted might be eco-ms-1 in the graph above, and then when it was revised and resubmitted, it was done with tag eco-ms-2. A different paper was started and submitted with tag dens-ms-1, showing that you can be working on multiple manuscripts with closely related but not identical sets of code and data being used for each, and keep track of it all.\n\n\nVersion control and Collaboration using Git and GitHub\nFirst, just what are git and GitHub?\n\ngit: version control software used to track files in a folder (a repository)\n\ngit creates the versioned history of a repository\n\nGitHub: web site that allows users to store their git repositories and share them with others\n\n\n\nThe Git lifecycle\nAs a git user, you’ll need to understand the basic concepts associated with versioned sets of changes, and how they are stored and moved across repositories. Any given git repository can be cloned so that it exist both locally, and remotely. But each of these cloned repositories is simply a copy of all of the files and change history for those files, stored in git’s particular format. For our purposes, we can consider a git repository just a folder with a bunch of additional version-related metadata.\nIn a local git-enabled folder, the folder contains a workspace containing the current version of all files in the repository. These working files are linked to a hidden folder containing the ‘Local repository’, which contains all of the other changes made to the files, along with the version metadata.\nSo, when working with files using git, you can use git commands to indicate specifically which changes to the local working files should be staged for versioning (using the git add command), and when to record those changes as a version in the local repository (using the command git commit).\nThe remaining concepts are involved in synchronizing the changes in your local repository with changes in a remote repository. The git push command is used to send local changes up to a remote repository (possibly on GitHub), and the git pull command is used to fetch changes from a remote repository and merge them into the local repository.\n\n\ngit clone: to copy a whole remote repository to local\ngit add (stage): notify git to track particular changes\ngit commit: store those changes as a version\ngit pull: merge changes from a remote repository to our local repository\ngit push: copy changes from our local repository to a remote repository\ngit status: determine the state of all files in the local repository\ngit log: print the history of changes in a repository\n\nThose seven commands are the majority of what you need to successfully use git. But this is all super abstract, so let’s explore with some real examples."
  },
  {
    "objectID": "labs/lab3s_github.html#on-the-computer",
    "href": "labs/lab3s_github.html#on-the-computer",
    "title": "Lab S3 - “Connecting a Github repo site with a new RStudio project”",
    "section": "On the Computer",
    "text": "On the Computer\n\nOn the github website\n\nRegister for a github account on https://github.com/\nClick on the Repository link\nClick on the New Repository button to create a new repository.\nGive it a name, make it public, Add a readme file, Add R .gitignore file, Add Apache license.\nEnable a web page for the repo - Click of the settings wheel, in the left menu select pages then under branch select main and save. \nGo back to your main repo home page, in the right corner in the About section click the wheel. Select Use your GitHub Pages website. Save changes\nClick on the green code button and copy the https link. \n\n\n\nMake a local version of your github repo in Unity\n\nIn Your Home Directory click on File &gt; New Project thenNew Project from Git Repository`\nSelect Version Control\nSelect Git\nPaste in link your github site\nChoose the directory you want to use for the project\nPaste in the link to your Github repository (e.g https://github.com/jeffreyblanchard/pathogen-test.git) \n\n\n\nConfigure your local repo to connect with the github repo\n\nInstall the R package usethis using Tools &gt; Install Packages\nConfigure git with your username and email. This must be the username and email associated with your GitHub account.\n\n\n\nR code\nlibrary(usethis)\nuse_git_config(user.name = \"Jane Doe\", user.email = \"jane@example.org\")\n\n\n * Create a github token\n\n\nR code\nusethis::create_github_token()\n\n\nThis will open a web page on your github account. The recommended scopes will be pre-selected. This will be fine for now and you can change later if needed.\n\nClick “Generate token”.\nCopy the generated PAT (beginning with ghp)to your clipboard. Provide this PAT next time a Git operation asks for your password.\nTo link your PAT with your repo\n\n\n\nR code\ngitcreds::gitcreds_set() \n\n\nto get a prompt where you can paste your PAT: ghp_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n\n\nMake an index file as the homepage for your Github repo\n\nIn RStudio open a new Quarto markdown template\nSave it as index.qmd (IMPORTANT - make sure it is all lower case)\nUse the YAML block from your labs\nAdd an About Me, Image and a link to lab 7 (or all labs)\nRender it to make index.html\nUnder the git tab in the upper right corner, select commit the changes`\nAdd a description of your changes in the commit messeage\nClick on Commit\nClose the window\nClick on Push to copy the index files to your github repo \nThis will automatically replace your homepage README.md file with index.html (it takes about 5 minutes before the page updates)\nIt will take about 5 minutes before you can see it on your github repo page\nYou can quickly spice up your page by adding a theme to your YAML block of your index.qmd (available themes are “default”, “bootstrap”, “cerulean”, “cosmo”, “darkly”, “flatly”, “journal”, “lumen”, “paper”, “readable”, “sandstone”, “simplex”, “spacelab”, “united”, “yeti”)\nYou could also try [prettydoc](https://prettydoc.statr.me/0"
  },
  {
    "objectID": "labs/lab3s_github.html#linking-an-existing-r-project-with-a-new-github-repo",
    "href": "labs/lab3s_github.html#linking-an-existing-r-project-with-a-new-github-repo",
    "title": "Lab S3 - “Connecting a Github repo site with a new RStudio project”",
    "section": "Linking an existing R project with a new Github repo",
    "text": "Linking an existing R project with a new Github repo\n\nOn the github website\n\nCreate a new repo by clicking on the new repository button.\nGive it a name, make it public. Do not add readme, .gitignore or license files\nCopy the link to the site.\n\n\n\nEnable git in Rstudio\n\nOpen your project in Rstudio and navigate to Tools -&gt; Version Control -&gt; Project Setup\nClick SVN/Git tab and select git as the version control system. It will ask you to initialize a new git repo and restart Rstudio\nAfter Rstudio reopens, confirm that there is a Git tab in the environment pane\n\n\n\nIn the R Console (bottom left)\n\nIn the R Console Add your git credentials with the usethis package and your token begining with ghp...\n\n\n\nR code\nlibrary(usethis)\nuse_git_config(user.name = \"jeffreyblanchard\", user.email = \"jlb@umass.edu\")\ngitcreds::gitcreds_set() \n\n\nIf you have forgotten your token. Create a new token using\n\n\nR code\nlibrary(usethis)\nusethis::create_github_token()\n\n\n\n\nIn the Terminal Window (bottom left)\nNow in the Terminal window establish a connection to your github repo and make your first commit\n\n\nR code\necho \"# test-project\" &gt;&gt; README.md\ngit add README.md\ngit commit -m \"first commit\"\ngit branch -M main\ngit remote add origin https://github.com/jeffreyblanchard/test-project.git\ngit push -u origin main\n\n\nThis only pushes the readme to github. Now under the Git tab in RStudio (top right pane) check your files, commit and then push.\n\n\nTo enable a web page for your repo\n\nEnable a web page for the repo - Click of the settings wheel, in the left menu select pages then under branch select main and save. \nGo back to your main repo page, in the right corner in the About section click the wheel. Select Use your GitHub Pages website. Save changes\nClick on the green code button and copy the https link."
  }
]